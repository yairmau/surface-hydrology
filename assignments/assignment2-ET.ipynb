{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2 - Evapotranspiration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“’ instructions\n",
    "This is where learning happens, not during a lecture. You'll learn a ton of things by doing them yourself. Much success! ðŸ˜„\n",
    "\n",
    "Create a Jupyter Notebook called `assignment-02-IDNUMBER`, where `IDNUMBER` is your 9-digit ID. This is the file only file we will check.\n",
    "\n",
    "## ðŸ“Œ locations and data\n",
    "\n",
    "**Choose two stations with different climates.**\n",
    "\n",
    "Go to NOAA's [Climate Reference Network Data](https://www.ncdc.noaa.gov/crn/qcdatasets.html) website. The sub-hourly (5-min) data contains information on  \n",
    "\n",
    "* air temperature,\n",
    "* precipitation,\n",
    "* global solar radiation,\n",
    "* surface infrared temperature,\n",
    "* relative humidity,\n",
    "* soil moisture and temperature,\n",
    "* wetness, and\n",
    "* 1.5 meter wind speed.\n",
    "\n",
    "There is no data on air pressure, so one needs to use the stations coordinates (lat, lon) to find its height above sea level, and from that infer the air pressure. You can use Google Earth or any other means to find the station's height.\n",
    "\n",
    "In the Data Access link, choose a year and a station you would like to analyze. If you are not sure where the stations are, find them using the 2-letter state abbreviation and the station name.\n",
    "\n",
    "Download the following files:\n",
    "1. One full year of data for each station. Make sure important data we need to calculate Penman's ET estimation is available.\n",
    "2. The headers file\n",
    "3. The documentation file\n",
    "\n",
    "Make sure you understand what are the units provided for each measurement (see documentation).\n",
    "\n",
    "## ðŸ›  tasks\n",
    "\n",
    "Produce potential ET estimates using Thornthwaite's equation and Penman's equation.\n",
    "Produce plots of ET as a function of time for each station, comparing the two methods you used.\n",
    "Also, using Penman's ET estimates, compare the two stations and discuss about their differences/similarities.\n",
    "\n",
    "You might find interesting things in the data, such as periods of unusually high/low temperatures, radiation, etc. Discuss how these factors might have affected the ET estimates that you calculated.\n",
    "\n",
    "You will have **two weeks** to deliver your assignment. You should **not** hand in a dry document with only figures and code, I'm expecting text before and after each code/graph cell, explaining what you did, why you did it, and how it fits the story you are telling. Don't forget to put labels on your plot axes, title, legend, etc.  \n",
    "\n",
    "Your Jupyter Notebook should be **fully functional**: if we press `Kernel > Restart & Run All`, all the code must work without any errors.\n",
    "\n",
    "\n",
    "## ðŸšš importing the data\n",
    "\n",
    "Below you can find an example of how to import the data file provided by NOAA's Climate Reference Network Data website. You might have to make some adjustments to it.\n",
    "\n",
    "```python\n",
    "data_file = \"CRNS0101-05-2020-CO_Boulder_14_W.txt\"\n",
    "df = pd.read_csv(data_file,\n",
    "                 header=None,                      # no headers needed, we'll do that later\n",
    "                 delim_whitespace=True,            # blank spaces separate between columns\n",
    "                 na_values=[\"-99.000\", \"-9999.0\"]  # substitute these values for missing (NaN) values\n",
    "                )\n",
    "headers = pd.read_csv(\"HEADERS_sub_hourly.txt\",    # load headers file\n",
    "                      header=1,                    # skip the first [0] line\n",
    "                      delim_whitespace=True\n",
    "                     )\n",
    "df.columns = headers.columns                       # rename df columns with headers columns\n",
    "# LST = local standard time\n",
    "df[\"LST_TIME\"] = [f\"{x:04d}\" for x in df[\"LST_TIME\"]]  # time needs padding of zeros, then convert to string\n",
    "df['LST_DATE'] = df['LST_DATE'].astype(str)            # convert date into string\n",
    "df['datetime'] = df['LST_DATE'] + ' ' + df['LST_TIME'] # combine date+time into datetime\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])        # interpret datetime\n",
    "df = df.set_index('datetime')                          # make datetime the index\n",
    "df\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 08:50:36) \n[Clang 10.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "c1802537857defe7992544f25bae53dd19303308d5f945e12e7b8de650127286"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
