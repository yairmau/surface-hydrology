[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Surface Hydrology",
    "section": "",
    "text": "About\nWelcome to Surface Hydrology (71630) at the Hebrew University of Jerusalem. This is Yair Mau, your host for today. I am a senior lecturer at the Institute of Environmental Sciences, at the Faculty of Agriculture, Food and Environment, in Rehovot, Israel.\nThis website contains (almost) all the material youâ€™ll need for the course. If you find any mistakes, or have any comments, please email me."
  },
  {
    "objectID": "index.html#syllabus",
    "href": "index.html#syllabus",
    "title": "Surface Hydrology",
    "section": "Syllabus",
    "text": "Syllabus\n\nCourse description\nThis is an introductory course in Surface Hydrology, dealing with some of the major processes in the hydrologic cycle: precipitation, evaporation and transpiration, infiltration, runoff generation and streamflow. The different topics will be treated using mathematical models and practical programming exercises.\n\n\nCourse aims\nThe course aims at giving the students a quantitative understanding of the main processes in the hydrologic cycle. We will characterize the hydrologic cycle and its fluxes through mass balance equations. The random nature of the various processes will be studied with statistics, time series analysis, return periods, extreme value distributions, etc. We will take a â€œhands-on approachâ€, where students will actively engage with the material by analysing data and writing models using Python.\n\n\nLearning outcomes\nOn successful completion of this module, students should be able to:\n\nIdentify the various components of hydrologic budget and their interdependency.\nDescribe the various processes in hydrology (precipitation, infiltration, evaporation, etc) in a mathematical language.\nWrite computer code to analyze the statistics of hydrologic fluxes, and construct models of hydrological systems.\n\n\n\nBooks and other sources\n\nDingman, S. L. (2015). Physical hydrology (3rd edition). Waveland press.\nWard, A. D., & Trimble, S. W. (2003). Environmental hydrology. CRC Press.\nBrutsaert, W. (2005). Hydrology: An Introduction. Cambridge University Press.\n\n\n\nCourse evaluation\nThere will be some small projects during the semester, all worth 50% of the grade. A final and larger project (50% of the grade) will be due at the end of the semester. All projects will be done in Python (on Jupyter Notebooks)."
  },
  {
    "objectID": "introduction/introduction-lecture.html#how-much-water-is-there-where",
    "href": "introduction/introduction-lecture.html#how-much-water-is-there-where",
    "title": "1Â  Water Cycle: Fluxes and Storage",
    "section": "1.1 How much water is there? Where?",
    "text": "1.1 How much water is there? Where?\n\n\n\n\n\n\nSource: Water Science School (2019c)\n\n\n\n\n\nSource: Water Science School (2018)"
  },
  {
    "objectID": "introduction/introduction-lecture.html#the-natural-water-cycle-2019",
    "href": "introduction/introduction-lecture.html#the-natural-water-cycle-2019",
    "title": "1Â  Water Cycle: Fluxes and Storage",
    "section": "1.2 The natural water cycle (2019)",
    "text": "1.2 The natural water cycle (2019)\n\n\n\nSource: Water Science School (2019g)"
  },
  {
    "objectID": "introduction/introduction-lecture.html#the-new-water-cycle-2022",
    "href": "introduction/introduction-lecture.html#the-new-water-cycle-2022",
    "title": "1Â  Water Cycle: Fluxes and Storage",
    "section": "1.3 The new water cycle (2022)",
    "text": "1.3 The new water cycle (2022)\n\n\n\nSource: Water Science School (2022)\n\n\nInteractive chart: Pools and fluxes in the water cycle"
  },
  {
    "objectID": "introduction/introduction-lecture.html#global-water-distribution",
    "href": "introduction/introduction-lecture.html#global-water-distribution",
    "title": "1Â  Water Cycle: Fluxes and Storage",
    "section": "1.4 Global water distribution",
    "text": "1.4 Global water distribution\n\nSource: Water Science School (2018). (Percents are rounded, so will not add to 100)\n\n\n\n\n\n\n\n\nWater source\nVolume (km\\(^3\\))\n% of freshwater\n% of total water\n\n\n\n\nOceans, Seas, & Bays\n1,338,000,000\nâ€“\n96.54\n\n\nIce caps, Glaciers, & Permanent Snow\n24,064,000\n68.7\n1.74\n\n\nGroundwater\n23,400,000\nâ€“\n1.69\n\n\n\\(\\quad\\)Fresh\n10,530,000\n30.1\n0.76\n\n\n\\(\\quad\\)Saline\n12,870,000\nâ€“\n0.93\n\n\nSoil Moisture\n16,500\n0.05\n0.001\n\n\nGround Ice & Permafrost\n300,000\n0.86\n0.022\n\n\nLakes\n176,400\nâ€“\n0.013\n\n\n\\(\\quad\\)Fresh\n91,000\n0.26\n0.007\n\n\n\\(\\quad\\)Saline\n85,400\nâ€“\n0.006\n\n\nAtmosphere\n12,900\n0.04\n0.001\n\n\nSwamp Water\n11,470\n0.03\n0.0008\n\n\nRivers\n2,120\n0.006\n0.0002\n\n\nBiological Water\n1,120\n0.003\n0.0001"
  },
  {
    "objectID": "introduction/introduction-lecture.html#energy-drives-the-hydrologic-cycle",
    "href": "introduction/introduction-lecture.html#energy-drives-the-hydrologic-cycle",
    "title": "1Â  Water Cycle: Fluxes and Storage",
    "section": "1.5 Energy drives the hydrologic cycle",
    "text": "1.5 Energy drives the hydrologic cycle\nFrom Margulis (2019)\n\nA key aspect of the hydrologic cycle is the fact that it is driven by energy inputs (primarily from the sun). At the global scale, the system is essentially closed with respect to water; negligible water is entering or leaving the system. In other words, there is no external forcing in terms of a water flux. Systems with no external forcing will generally eventually come to an equilibrium state. So what makes the hydrologic cycle so dynamic? The solar radiative energy input, which is external to the system, drives the hydrologic cycle. Averaged over the globe, 342 W m\\(^{-2}\\) of solar radiative energy is being continuously input to the system at the top of the atmosphere. This energy input must be dissipated, and this is done, to a large extent, via the hydrologic cycle. Due to this fact, the study of hydrology is not isolated to the study of water storage and movement, but also must often include study of energy storage and movements."
  },
  {
    "objectID": "introduction/introduction-lecture.html#components-of-the-water-cycle",
    "href": "introduction/introduction-lecture.html#components-of-the-water-cycle",
    "title": "1Â  Water Cycle: Fluxes and Storage",
    "section": "1.6 Components of the water cycle",
    "text": "1.6 Components of the water cycle\n\n1.6.1 Water storage in oceans\n\n\n1.6.2 Evaporation / Sublimation\nEvaporation \\(\\longrightarrow\\) cooling\n\n\n\n  \n\n\n1.6.3 Evapotranspiration\n\n\n\n1.6.4 Water storage in the atmosphere\nCumulonimbus cloud over Africa \nPicture of cumulonimbus taken from the International Space Station, over western Africa near the Senegal-Mali border.\nIf all of the water in the atmosphere rained down at once, it would only cover the globe to a depth of 2.5 centimeters. \\[\n\\begin{align}\n\\text{amount of water in the atmosphere} & \\qquad V = 12\\, 900\\, \\text{km}^3 \\\\\n\\text{surface of Earth} & \\qquad S = 4 \\pi R^2;\\quad R=6371\\,\\text{km}\\\\\n& \\qquad V = S \\times h \\\\\n\\text{height} & \\qquad h = \\frac{V}{S} \\simeq 2.5\\,\\text{cm}\n\\end{align}\n\\]\nTry to calculate this yourself, and click on the button below to check how to do it.\n\n\nShow/hide the code\n# amount of water in the atmosphere\nV = 12900 # km^3\n# Earth's radius\nR = 6371 # km\n# surface of Earth = 4 pi RË†2\nS = 4 * 3.141592 * R**2\n# Volume: V = S * h, therefore\n# height\nh = V / S # in km\nh_cm = h * 1e5 # in cm\nprint(f\"The height would be ~ {h_cm:.1f} cm\")\n\n\nThe height would be ~ 2.5 cm\n\n\n\n\n1.6.5 Condensation\n\n\n1.6.6 Precipitation\n\n\n\nSource: Water Science School (2019f)\n\n\n\nSource: Water Science School (2019e)\n\n\n\n\n\n\n\n\n\n\nIntensity (cm/h)\nMedian diameter (mm)\nVelocity of fall (m/s)\nDrops s\\(^{-1}\\) m\\(^{-2}\\)\n\n\n\n\nFog\n0.013\n0.01\n0.003\n67,425,000\n\n\nMist\n0.005\n0.1\n0.21\n27,000\n\n\nDrizzle\n0.025\n0.96\n4.1\n151\n\n\nLight rain\n0.10\n1.24\n4.8\n280\n\n\nModerate rain\n0.38\n1.60\n5.7\n495\n\n\nHeavy rain\n1.52\n2.05\n6.7\n495\n\n\nExcessive rain\n4.06\n2.40\n7.3\n818\n\n\nCloudburst\n10.2\n2.85\n7.9\n1,220\n\n\n\n\n\n1.6.7 Water storage in ice and snow\n\n\n\nSource: Water Science School (2019d)\n\n\n\n\n\nSource: Water Science School (2019d)\n\n\n\n\n1.6.8 Snowmelt runoff to streams\n\n\n1.6.9 Surface runoff\n\n\n\nSource: ×—×“×©×•×ª ×¤×ª×— ×ª×§×•×•×” (2020)\n\n\n\n\n\n1.6.10 Streamflow\nThe Mississippi river basin is very large \nThe Amazon river basin is Huge \n\n\n\nSource: Yair Mau\n\n\n\n\n1.6.11 Lakes and rivers\n\n\n\nSource: dreamstime (2022)\n\n\nLake Malawi \n\n\n\nSource: Fiona Bruce (2015)\n\n\n\n\n1.6.12 Infiltration\n\n\n\nSource: Suma Groulx (2015)\n\n\n\n\n1.6.13 Groundwater storage\n\n\n\nSource: Water Science School (2019b)\n\n\n\n\n\nSource: (modernfarmer?)\n\n\n\n\n\nSource: (ogallala1?)\n\n\nCenter Pivot irrigation in Nebraska taps the Ogallala Aquifer. \n\n\n1.6.14 Groundwater flow and discharge\n\n\n\nSource: Water Science School (2019a)\n\n\n\n\n\nSource: Raymond, Lyle S. Jr. (1988)\n\n\n\n\n\nSource: ValentÃ­ Rodellas (1988)\n\n\n\n\n1.6.15 Spring\nEin Gedi \nThousand Springs, Idaho \n\n\n\n\nAmazon Waters. 2022. â€œAmazon Waters.â€ Amazon Waters. https://amazonwaters.org/basins.\n\n\ndreamstime. 2022. â€œWorld Map of AFRICA.â€ Dreamstime. https://www.dreamstime.com/world-map-africa-egypt-libya-ethiopia-arabia-mauritania-nigeria-somalia-namibia-tanzania-madagascar-geographic-xxl-chart-image154799901.\n\n\nFiona Bruce. 2015. â€œA Family Holiday in Lake Malawi: Zen and the Art of Paddleboarding.â€ The Telegraph. https://twitter.com/hallaboutafrica/status/1203419359303159809?s=20&t=SkH17UkWrNcXzIqRF0ic_A.\n\n\nJames Hall. 2019. â€œLake Malawi.â€ Twitter. https://twitter.com/hallaboutafrica/status/1203419359303159809?s=20&t=SkH17UkWrNcXzIqRF0ic_A.\n\n\nMargulis, Steve. 2019. â€œIntroduction to Hydrology. eBook.â€ https://margulis-group.github.io/textbook/.\n\n\nMarty Friedlander. 2015. â€œNatural Springs of Israel: Seven Cool Watering Holes to Visit This Summer.â€ Haaretz. https://www.haaretz.com/israel-news/travel/seven-cool-natural-springs-of-israel-1.5388627.\n\n\nNational Park Service. 2022. â€œMississippi River Facts.â€ National Park Service. https://www.nps.gov/miss/riverfacts.htm.\n\n\nRaymond, Lyle S. Jr. 1988. â€œWhat Is Groundwater?â€ Cornell eCommons. https://ecommons.cornell.edu/handle/1813/3408.\n\n\nSuma Groulx. 2015. â€œWater Infiltration.â€ Suma Groulx. http://sumagroulx.com/water-infiltration/.\n\n\nValentÃ­ Rodellas. 1988. â€œEvaluating Submarine Groundwater Discharge to the Mediterranean Sea by Using Radium Isotopes.â€ Research Gate. https://www.researchgate.net/figure/Principal-pathways-for-submarine-groundwater-discharge-to-the-coastal-ocean-including_fig1_274590439.\n\n\nWater Science School. 2016. â€œWater Flowing Underground Can Find Openings Back to the Land Surface.â€ U.S. Geological Survey. https://www.usgs.gov/media/images/water-flowing-underground-can-find-openings-back-land-surface.\n\n\nâ€”â€”â€”. 2018. â€œWhere Is Earthâ€™s Water?â€ U.S. Geological Survey. https://www.usgs.gov/special-topics/water-science-school/science/where-earths-water.\n\n\nâ€”â€”â€”. 2019a. â€œConceptual Groundwater-Flow Diagram.â€ U.S. Geological Survey. https://www.usgs.gov/media/images/conceptual-groundwater-flow-diagram.\n\n\nâ€”â€”â€”. 2019b. â€œGroundwater Is the Area Underground Where Openings Are Full of Water.â€ U.S. Geological Survey. https://www.usgs.gov/media/images/groundwater-area-underground-where-openings-are-full-water.\n\n\nâ€”â€”â€”. 2019c. â€œHow Much Water Is There on Earth?â€ U.S. Geological Survey. https://www.usgs.gov/special-topics/water-science-school/science/how-much-water-there-earth.\n\n\nâ€”â€”â€”. 2019d. â€œIce, Snow, and Glaciers and the Water Cycle.â€ U.S. Geological Survey. https://www.usgs.gov/special-topics/water-science-school/science/ice-snow-and-glaciers-and-water-cycle.\n\n\nâ€”â€”â€”. 2019e. â€œPrecipitation and the Water Cycle.â€ U.S. Geological Survey. https://www.usgs.gov/special-topics/water-science-school/science/precipitation-and-water-cycle.\n\n\nâ€”â€”â€”. 2019f. â€œRain and Precipitation.â€ U.S. Geological Survey. https://www.usgs.gov/special-topics/water-science-school/science/rain-and-precipitation.\n\n\nâ€”â€”â€”. 2019g. â€œThe Natural Water Cycle.â€ U.S. Geological Survey. https://www.usgs.gov/media/images/natural-water-cycle-jpg.\n\n\nâ€”â€”â€”. 2022. â€œThe Water Cycle.â€ U.S. Geological Survey. https://www.usgs.gov/media/images/water-cycle-png.\n\n\n×—×“×©×•×ª ×¤×ª×— ×ª×§×•×•×”. 2020. â€œ××•×‘×š ×•××¢×¨×›×ª ×’×©××™× ×›×‘×“×” × ×•×¡×¤×ª.â€ Melabes. https://www.melabes.co.il/news/51773."
  },
  {
    "objectID": "introduction/introduction-exercises.html",
    "href": "introduction/introduction-exercises.html",
    "title": "2Â  Exercises",
    "section": "",
    "text": "3 homework\nGo back to the weather station website, download one year of data from 01.01.2020 to 31.12.2020 (24h data). If you canâ€™t download the data, just click here. Make the following graph: - daily tmax and tmin - smoothed data for tmax and tmin\nIn order to smooth the data with a 30 day window, use the following function:\ndf['tmin'].rolling(30, center=True).mean()\nThis means that you will take the mean of 30 days, and put the result in the center of this 30-day window.\nPlay with this function, see what you can do with it. What happens when you change the size of the window? Why is the smoothed data shorter than the original data? See the documentation for rolling to find more options."
  },
  {
    "objectID": "introduction/introduction-exercises.html#download-the-data",
    "href": "introduction/introduction-exercises.html#download-the-data",
    "title": "2Â  Exercises",
    "section": "2.1 download the data",
    "text": "2.1 download the data\n\nGo to the Faculty of Agricultureâ€™s weather station.\nClick on ××©×™×›×ª × ×ª×•× ×™× and download data for 1 September 2020 to 28 February 2021, with a 24h interval. Call it data-sep2020-feb2021\nOpen the .csv file with Excel, see how it looks like\nIf you canâ€™t download the data, just click here."
  },
  {
    "objectID": "introduction/introduction-exercises.html#import-packages",
    "href": "introduction/introduction-exercises.html#import-packages",
    "title": "2Â  Exercises",
    "section": "2.2 import packages",
    "text": "2.2 import packages\nWe need to import this data into python. First we import useful packages. Type (donâ€™t copy and paste) the following lines in the code cell below.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"ticks\", font_scale=1.5)"
  },
  {
    "objectID": "introduction/introduction-exercises.html#import-data-with-pandas",
    "href": "introduction/introduction-exercises.html#import-data-with-pandas",
    "title": "2Â  Exercises",
    "section": "2.3 import data with pandas",
    "text": "2.3 import data with pandas\nImport data from csv and put it in a pandas dataframe (a table). Make line 5 the header (column names)\n\ndf = pd.read_csv(\"data-sep2020-feb2021.csv\", header=[4])\ndf\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      ï¿½C\n      ï¿½C.1\n      km/h\n      mm\n      mm.1\n    \n  \n  \n    \n      0\n      01/09/20\n      32.8\n      25.3\n      29.7\n      0.0\n      0.0\n    \n    \n      1\n      02/09/20\n      33.0\n      24.0\n      28.8\n      0.0\n      0.0\n    \n    \n      2\n      03/09/20\n      34.2\n      23.8\n      31.6\n      0.0\n      0.0\n    \n    \n      3\n      04/09/20\n      36.3\n      27.3\n      24.2\n      0.0\n      0.0\n    \n    \n      4\n      05/09/20\n      34.2\n      26.3\n      22.4\n      0.0\n      0.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      176\n      24/02/21\n      20.6\n      9.9\n      28.8\n      0.0\n      481.7\n    \n    \n      177\n      25/02/21\n      19.4\n      9.3\n      23.3\n      0.0\n      481.7\n    \n    \n      178\n      26/02/21\n      21.3\n      8.0\n      24.2\n      0.1\n      481.8\n    \n    \n      179\n      27/02/21\n      23.4\n      9.2\n      30.6\n      0.0\n      481.8\n    \n    \n      180\n      28/02/21\n      19.7\n      9.2\n      22.4\n      0.0\n      481.8\n    \n  \n\n181 rows Ã— 6 columns"
  },
  {
    "objectID": "introduction/introduction-exercises.html#rename-columns",
    "href": "introduction/introduction-exercises.html#rename-columns",
    "title": "2Â  Exercises",
    "section": "2.4 rename columns",
    "text": "2.4 rename columns\nrename the columns to:\ndate, tmax, tmin, wind, rain24h, rain_cumulative\n\ndf.columns = ['date', 'tmax', 'tmin', 'wind', 'rain24h', 'rain_cumulative']\ndf\n\n\n\n\n\n  \n    \n      \n      date\n      tmax\n      tmin\n      wind\n      rain24h\n      rain_cumulative\n    \n  \n  \n    \n      0\n      01/09/20\n      32.8\n      25.3\n      29.7\n      0.0\n      0.0\n    \n    \n      1\n      02/09/20\n      33.0\n      24.0\n      28.8\n      0.0\n      0.0\n    \n    \n      2\n      03/09/20\n      34.2\n      23.8\n      31.6\n      0.0\n      0.0\n    \n    \n      3\n      04/09/20\n      36.3\n      27.3\n      24.2\n      0.0\n      0.0\n    \n    \n      4\n      05/09/20\n      34.2\n      26.3\n      22.4\n      0.0\n      0.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      176\n      24/02/21\n      20.6\n      9.9\n      28.8\n      0.0\n      481.7\n    \n    \n      177\n      25/02/21\n      19.4\n      9.3\n      23.3\n      0.0\n      481.7\n    \n    \n      178\n      26/02/21\n      21.3\n      8.0\n      24.2\n      0.1\n      481.8\n    \n    \n      179\n      27/02/21\n      23.4\n      9.2\n      30.6\n      0.0\n      481.8\n    \n    \n      180\n      28/02/21\n      19.7\n      9.2\n      22.4\n      0.0\n      481.8\n    \n  \n\n181 rows Ã— 6 columns"
  },
  {
    "objectID": "introduction/introduction-exercises.html#a-first-plot",
    "href": "introduction/introduction-exercises.html#a-first-plot",
    "title": "2Â  Exercises",
    "section": "2.5 a first plot!",
    "text": "2.5 a first plot!\nplot the minimum temperature:\n\nplt.plot(df['tmin'])"
  },
  {
    "objectID": "introduction/introduction-exercises.html#how-to-deal-with-dates",
    "href": "introduction/introduction-exercises.html#how-to-deal-with-dates",
    "title": "2Â  Exercises",
    "section": "2.6 how to deal with dates",
    "text": "2.6 how to deal with dates\nWe want the dates to appear on the horizontal axis.\nInterpret â€˜dateâ€™ column as a pandas datetime, see how it looks different from before\nbefore: 01/09/20\nafter: 2020-09-01\n\ndf['date'] = pd.to_datetime(df['date'], dayfirst=True)\ndf\n\n\n\n\n\n  \n    \n      \n      date\n      tmax\n      tmin\n      wind\n      rain24h\n      rain_cumulative\n    \n  \n  \n    \n      0\n      2020-09-01\n      32.8\n      25.3\n      29.7\n      0.0\n      0.0\n    \n    \n      1\n      2020-09-02\n      33.0\n      24.0\n      28.8\n      0.0\n      0.0\n    \n    \n      2\n      2020-09-03\n      34.2\n      23.8\n      31.6\n      0.0\n      0.0\n    \n    \n      3\n      2020-09-04\n      36.3\n      27.3\n      24.2\n      0.0\n      0.0\n    \n    \n      4\n      2020-09-05\n      34.2\n      26.3\n      22.4\n      0.0\n      0.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      176\n      2021-02-24\n      20.6\n      9.9\n      28.8\n      0.0\n      481.7\n    \n    \n      177\n      2021-02-25\n      19.4\n      9.3\n      23.3\n      0.0\n      481.7\n    \n    \n      178\n      2021-02-26\n      21.3\n      8.0\n      24.2\n      0.1\n      481.8\n    \n    \n      179\n      2021-02-27\n      23.4\n      9.2\n      30.6\n      0.0\n      481.8\n    \n    \n      180\n      2021-02-28\n      19.7\n      9.2\n      22.4\n      0.0\n      481.8\n    \n  \n\n181 rows Ã— 6 columns\n\n\n\n\n2.6.1 date as dataframe index\nMake â€˜dateâ€™ the dataframeâ€™s index (leftmost column, but not really a column!)\n\ndf = df.set_index('date')\ndf\n\n\n\n\n\n  \n    \n      \n      tmax\n      tmin\n      wind\n      rain24h\n      rain_cumulative\n    \n    \n      date\n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2020-09-01\n      32.8\n      25.3\n      29.7\n      0.0\n      0.0\n    \n    \n      2020-09-02\n      33.0\n      24.0\n      28.8\n      0.0\n      0.0\n    \n    \n      2020-09-03\n      34.2\n      23.8\n      31.6\n      0.0\n      0.0\n    \n    \n      2020-09-04\n      36.3\n      27.3\n      24.2\n      0.0\n      0.0\n    \n    \n      2020-09-05\n      34.2\n      26.3\n      22.4\n      0.0\n      0.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2021-02-24\n      20.6\n      9.9\n      28.8\n      0.0\n      481.7\n    \n    \n      2021-02-25\n      19.4\n      9.3\n      23.3\n      0.0\n      481.7\n    \n    \n      2021-02-26\n      21.3\n      8.0\n      24.2\n      0.1\n      481.8\n    \n    \n      2021-02-27\n      23.4\n      9.2\n      30.6\n      0.0\n      481.8\n    \n    \n      2021-02-28\n      19.7\n      9.2\n      22.4\n      0.0\n      481.8\n    \n  \n\n181 rows Ã— 5 columns"
  },
  {
    "objectID": "introduction/introduction-exercises.html#plot-again-now-with-dates",
    "href": "introduction/introduction-exercises.html#plot-again-now-with-dates",
    "title": "2Â  Exercises",
    "section": "2.7 plot again, now with dates",
    "text": "2.7 plot again, now with dates\nPlot minimum temperature, now we have dates on the horizontal axis\n\nplt.plot(df['tmin'])"
  },
  {
    "objectID": "introduction/introduction-exercises.html#were-getting-there-the-graph-could-look-better",
    "href": "introduction/introduction-exercises.html#were-getting-there-the-graph-could-look-better",
    "title": "2Â  Exercises",
    "section": "2.8 weâ€™re getting there! the graph could look better",
    "text": "2.8 weâ€™re getting there! the graph could look better\nLetâ€™s make the graph look better: labels, title, slanted dates, etc\n\n# creates figure (the canvas) and the axis (rectangle where the plot sits)\nfig, ax = plt.subplots(1, figsize=(10,7))\n# two line plots\nax.plot(df['tmin'], color=\"red\", label=\"Temp (min)\")\nax.plot(df['tmax'], color=\"blue\", label=\"Temp (max)\")\n# axes labels and figure title\nax.set_xlabel('date')\nax.set_ylabel('temperature (Â°C)')\nax.set_title('maximum and minimum temperatures')\n# some ticks adjustments\nax.set_yticks([10,15,20,25])  # we can choose where to put ticks\nax.grid(axis='y')         # makes horizontal lines\nplt.gcf().autofmt_xdate()  # makes slated dates\n# legend\nax.legend(loc='upper right')\n# save png figure\nplt.savefig(\"temp_max_min.png\")"
  },
  {
    "objectID": "introduction/introduction-exercises.html#make-the-following-figure",
    "href": "introduction/introduction-exercises.html#make-the-following-figure",
    "title": "2Â  Exercises",
    "section": "2.9 make the following figure",
    "text": "2.9 make the following figure\nUse the following function to plot bars for daily rainfall\nax.bar(x_array, y_array)\nCan you write yourself some lines of code that calculate the cumulative rainfall from the daily rainfall?\n\n#collapse-hide\n\n# creates figure (the canvas) and the axis (rectangle where the plot sits)\nfig, ax = plt.subplots(1, figsize=(10,7))\n\n# line and bar plots\nax.bar(df.index, df['rain24h'], color=\"blue\", label=\"daily rainfall\")\n\n# there are many ways of calculating the cumulative rain\n\n# method 1, use a for loop:\n# rain = df['rain24h'].to_numpy()\n# cumulative = rain * 0\n# for i in range(len(rain)):\n#     cumulative[i] = np.sum(rain[:i])\n# df['cumulative1'] = cumulative\n\n# method 2, use list comprehension:\n# rain = df['rain24h'].to_numpy()\n# cumulative = [np.sum(rain[:i]) for i in range(len(rain))]\n# df['cumulative2'] = cumulative\n\n# method 3, use existing functions:\ndf['cumulative3'] = np.cumsum(df['rain24h'])\n\nax.plot(df['cumulative3'], color=\"red\", label=\"cumulative rainfall\")\n# compare our cumulative rainfall with the downloaded data\n# ax.plot(df['rain_cumulative'], 'x')\n# axes labels and figure title\nax.set_xlabel('date')\nax.set_ylabel('rainfall (mm)')\nax.set_title('daily and cumulative rainfall')\nax.set_xlim(['2020-11-01','2021-02-28'])\n# some ticks adjustments\nplt.gcf().autofmt_xdate()  # makes slated dates\n# legend\nax.legend(loc='upper left')\n# save png figure\nplt.savefig(\"cumulative_rainfall.png\")"
  },
  {
    "objectID": "introduction/introduction-exercises.html#make-another-figure",
    "href": "introduction/introduction-exercises.html#make-another-figure",
    "title": "2Â  Exercises",
    "section": "2.10 make another figure",
    "text": "2.10 make another figure\nIn order to choose just a part of the time series, you can use the following:\nstart_date = '2021-01-01'\nend_date = '2021-01-31'\njanuary = df[start_date:end_date]\n\n#collapse-hide\n\n# creates figure (the canvas) and the axis (rectangle where the plot sits)\nfig, ax = plt.subplots(1, figsize=(10,7))\n# define date range\nstart_date = '2021-01-01'\nend_date = '2021-01-31'\njanuary = df[start_date:end_date]['tmax']\n# plots\nax.plot(january, color=\"red\", label=\"daily max\")\nax.plot(january*0 + january.mean(), color=\"purple\", linestyle=\"--\", label=\"average daily max\")\n# axes labels and figure title\nax.set_xlabel('date')\nax.set_ylabel('temperature (Â°C)')\nax.set_title('average daily maximum temperature for January 2021')\n# some ticks adjustments\nplt.gcf().autofmt_xdate()  # makes slated dates\n# legend\nax.legend(loc='lower left')\n# save png figure\nplt.savefig(\"average_max_temp.png\")"
  },
  {
    "objectID": "introduction/introduction-exercises.html#one-last-figure-for-today",
    "href": "introduction/introduction-exercises.html#one-last-figure-for-today",
    "title": "2Â  Exercises",
    "section": "2.11 one last figure for today",
    "text": "2.11 one last figure for today\nUse the following code to create histograms with user-defined bins:\nb = np.arange(0, 56, 5)  # bins from 0 to 55, width = 5\nax.hist(df['wind'], bins=b, density=True)\nPlay with the bins, see what happens. What does density=True do?\n\n# creates figure (the canvas) and the axis (rectangle where the plot sits)\nfig, ax = plt.subplots(1, figsize=(10,7))\n# histogram\nb = np.arange(0, 56, 5)  # bins from 0 to 55, width = 5\nax.hist(df['wind'], bins=b, density=True)\n# axes labels and figure title\nax.set_xlabel('max wind speed (km/h)')\nax.set_ylabel('frequency')\nax.set_title('frequency of maximum wind speed')\n# save png figure\nplt.savefig(\"wind-histogram.png\")"
  },
  {
    "objectID": "precipitation/precipitation.html",
    "href": "precipitation/precipitation.html",
    "title": "Precipitation",
    "section": "",
    "text": "Here are some of the files weâ€™ll use in this module, in case you canâ€™t download them from their original repositories.\n\nBEN_GURION_monthly.csv\nBEER_SHEVA_monthly.csv\nEilat_daily.csv"
  },
  {
    "objectID": "precipitation/interannual-lecture.html#hydrological-year",
    "href": "precipitation/interannual-lecture.html#hydrological-year",
    "title": "3Â  Interannual variability of precipitation",
    "section": "3.1 hydrological year",
    "text": "3.1 hydrological year\nA time period of 12 months for which precipitation totals are measured. The hydrological year is designated by the calendar year in which it ends.\nLetâ€™s define the hydrological year for Tel Aviv from 1 October to 30 September.\n×”×× ××§×œ×™× ×”×’×©× ×©×œ× ×• ××©×ª× ×”"
  },
  {
    "objectID": "precipitation/interannual-lecture.html#coefficient-of-variation",
    "href": "precipitation/interannual-lecture.html#coefficient-of-variation",
    "title": "3Â  Interannual variability of precipitation",
    "section": "3.2 coefficient of variation",
    "text": "3.2 coefficient of variation\n\\(\\langle{P}\\rangle=\\) average precipitation\n\\(\\sigma=\\) standard deviation\n\\[CV = \\frac{\\sigma}{\\langle{P}\\rangle}\\]\nAssuming that the inter-annual distribution is a gaussian: 67% of the time, rainfall will vary +/- 30% from its long term average in Tel Aviv.\nPrecipitation averages are usually calculated for time intervals of 30 years.\n\n\n\n\nShow/hide the code\nimport altair as alt\nimport pandas as pd\n\ndf = pd.read_csv(\"TEL_AVIV_READING_monthly.csv\", sep=\",\")\n# make 'DATE' the dataframe index\ndf['DATE'] = pd.to_datetime(df['DATE'])\ndf = df.set_index('DATE')\n\ndf_year_all = df['PRCP'].resample('A-SEP').sum().to_frame()  # annual frequency, anchored end of September\ndf_year_all.columns = ['rain (mm)'] # rename 'PRCP' column to 'rain (mm)'\ndf_year = df_year_all.iloc[:-1]  # exclude last row\n\n# Altair only recognizes column data; it ignores index values.\n# You can plot the index data by first resetting the index\n# I know that I've just made 'DATE' the index, but I want to have this here nonetheless so I can refer to this in the future\nsource = df_year.reset_index()\nbrush = alt.selection(type='interval', encodings=['x'])\n\n# T: temporal, a time or date value\n# Q: quantitative, a continuous real-valued quantity\n# https://altair-viz.github.io/user_guide/encoding.html#encoding-data-types\nbars = alt.Chart().mark_bar().encode(\n    x=alt.X('DATE:T', axis=alt.Axis(title='date')),\n    y=alt.Y('rain (mm):Q',  axis=alt.Axis(title='annual precipitation (mm) and average')),\n    opacity=alt.condition(brush, alt.OpacityValue(1), alt.OpacityValue(0.2)),\n).add_selection(\n    brush\n).properties(\n    title='Select year range and drag for rolling average of annual precipitation in Tel Aviv'\n).properties(\n    width=600,\n    height=400\n)\n\nline = alt.Chart().mark_rule(color='orange').encode(\n    y='mean(rain (mm)):Q',\n    size=alt.SizeValue(3)\n).transform_filter(\n    brush\n)\n\nalt.layer(bars, line, data=source)"
  },
  {
    "objectID": "precipitation/interannual-exercises.html#homework",
    "href": "precipitation/interannual-exercises.html#homework",
    "title": "4Â  Exercises",
    "section": "4.1 homework",
    "text": "4.1 homework\n\nDownload both daily and monthly data for London (LONDON HEATHROW, ID: UKM00003772). You should be aware that â€˜PRCPâ€™ for monthly data is in millimeters, while â€˜PRCPâ€™ for daily data is in tens of millimiters.\nAggregate daily data into monthly intervals using resample(â€˜MSâ€™).sum(). â€˜MSâ€™ means that the sum of all days in the month will be stored in the first day of the month. Supposedly both datasets are equal now.\nCalculate the average annual rainfall, using each of these datasets.\nWhy is there such a big difference?"
  },
  {
    "objectID": "precipitation/intra-annual-lecture.html#seasonality-index",
    "href": "precipitation/intra-annual-lecture.html#seasonality-index",
    "title": "5Â  Intra-annual variability of precipitation",
    "section": "5.1 Seasonality Index",
    "text": "5.1 Seasonality Index\nSources: leddris (2010), Walsh and Lawler (1981)\n\\(R=\\) mean annual precipitation\n\\(m_i=\\) precipitation mean for month \\(i\\)\n\\[ SI = \\displaystyle \\frac{1}{R} \\sum_{n=1}^{n=12} \\left| m_i - \\frac{R}{12} \\right| \\]\n\n\n\n\n\n\n\n\\(SI\\)\nPrecipitation Regime\n\n\n\n\n<0.19\nPrecipitation spread throughout the year\n\n\n0.20-0.39\nPrecipitation spread throughout the year, but with a definite wetter season\n\n\n0.40-0.59\nRather seasonal with a short dry season\n\n\n0.60-0.79\nSeasonal\n\n\n0.80-0.99\nMarked seasonal with a long dry season\n\n\n1.00-1.19\nMost precipitation in <3 months\n\n\n\nLetâ€™s write some code to calculate the SI for Tel Aviv and London.\n\n\nShow/hide the code\n# import packages\nimport numpy as np\nimport pandas as pd\nfrom calendar import month_abbr\n\n# load data\nmonth_numbers = np.arange(1,13)\nmonth_names = [month_abbr[i] for i in month_numbers]\ndef monthly_mean(station_name, freq):\n    # import daily data\n    df = pd.read_csv(station_name + '_' + freq + '.csv', sep=\",\")\n    # make 'DATE' the dataframe index\n    df['DATE'] = pd.to_datetime(df['DATE'])\n    df = df.set_index('DATE')\n    # print(df.index[0], df.index[-1])\n    if freq == 'daily':\n        # resample data by month\n        df_month = df['PRCP'].resample('M').sum()  # sum is labeled at the last day of the month \n        df_month = df_month/10                     # PRCP is given in tens of mm (see readme)\n    if freq == 'monthly':\n        df_month = df['PRCP']\n    # calculate monthly mean\n    monthly_mean = np.array([])  # empty array\n    for m in month_numbers:      # cycle over months (1, 2, 3, etc)\n        this_month_all_indices = (df_month.index.month == m)       # indices in df_month belonging to month m\n        this_month_mean = df_month[this_month_all_indices].mean()  # this is the monthly mean\n        monthly_mean = np.append(monthly_mean, this_month_mean)    # append\n    # make new df and return it\n    df_return = pd.DataFrame({'monthly rainfall (mm)':monthly_mean,\n                              'month names':month_names,\n                              'month number':month_numbers\n                            })\n    return df_return\n\n# load monthly mean\ndf_london = monthly_mean(\"LONDON_HEATHROW\", 'monthly')\ndf_telaviv = monthly_mean(\"TEL_AVIV_READING\", 'monthly')\n\n\n\n\nShow/hide the code\ndef walsh_index(df):\n    m = df[\"monthly rainfall (mm)\"]\n    R = df[\"monthly rainfall (mm)\"].sum()\n    SI = np.sum(np.abs(m-R/12)) / R\n    return SI\n\nlondon_index = walsh_index(df_london)\ntelaviv_index = walsh_index(df_telaviv)\nprint(\"Seasonality index (Walsh and Lawler, 1981)\")\nprint(f\"London: {london_index:.2f}\")\nprint(f\"Tel Aviv: {telaviv_index:.2f}\")\n\n\nSeasonality index (Walsh and Lawler, 1981)\nLondon: 0.13\nTel Aviv: 1.00\n\n\n\n\n\n\nleddris. 2010. â€œRainfall Seasonality.â€ Land and Ecosystem Degradation and Desertification Response Information System. http://leddris.aegean.gr/ses-parameters/293-rainfall-seasonality.html#:~:text=Rainfall%20seasonality%20index%20is%20a,in%20relation%20to%20water%20availability.\n\n\nWalsh, RPD, and DM Lawler. 1981. â€œRainfall Seasonality: Description, Spatial Patterns and Change Through Time.â€ Weather 36 (7): 201â€“8. https://doi.org/10.1002/j.1477-8696.1981.tb05400.x."
  },
  {
    "objectID": "precipitation/intra-annual-exercises.html#intra-annual-variability",
    "href": "precipitation/intra-annual-exercises.html#intra-annual-variability",
    "title": "6Â  Exercises",
    "section": "6.1 intra-annual variability",
    "text": "6.1 intra-annual variability\nGo to NOAAâ€™s National Centers for Environmental Information (NCEI)\nClimate Data Online: Dataset Discovery\nFind station codes in this map. On the left, click on the little wrench (ğŸ”§) next to â€œGlobal Summary of the Monthâ€, then click on â€œidentifyâ€ on the panel that just opened, and click on a station (purple circle). You will see the stationâ€™s name, itâ€™s ID, and the period of record. For example, for Ben-Gurionâ€™s Airport in Israel:\nBEN GURION, IS\nSTATION ID: ISM00040180\nPeriod of Record: 1951-01-01 to 2020-03-01\nYou can download daily or monthly data for each station. Use the function below to download this data to your computer.\n\ndef download_data(station_name, station_code):\n    url_daily = 'https://www.ncei.noaa.gov/data/global-historical-climatology-network-daily/access/'\n    url_monthly = 'https://www.ncei.noaa.gov/data/gsom/access/'\n    # download daily data - uncomment the next 2 lines to make this work\n    # urllib.request.urlretrieve(url_daily + station_code + '.csv',\n    #                            station_name + '_daily.csv')\n    # download monthly data\n    urllib.request.urlretrieve(url_monthly + station_code + '.csv',\n                               station_name + '_monthly.csv')\n\nNow, choose any station with a period of record longer than 30 years, and download its data:\ndownload_data('BEN_GURION', 'ISM00040180')\nLoad the data into a datafram, and before you continue with the analysis, plot the rainfall data, to see how it looks like.\n\ndownload_data('BEN_GURION', 'ISM00040180')\ndf = pd.read_csv('BEN_GURION_monthly.csv', sep=\",\")\n# make 'DATE' the dataframe index\ndf['DATE'] = pd.to_datetime(df['DATE'])\ndf = df.set_index('DATE')\nplt.plot(df['PRCP'])\n\n\n\n\nIt doesnâ€™t look great for Ben-Gurion airport, lots of missing data! You might need to choose another stationâ€¦ Download data for Beer Sheva, ID IS000051690.\n\ndownload_data('BEER_SHEVA', 'IS000051690')\ndf = pd.read_csv('BEER_SHEVA_monthly.csv', sep=\",\")\n# make 'DATE' the dataframe index\ndf['DATE'] = pd.to_datetime(df['DATE'])\ndf = df.set_index('DATE')\nplt.plot(df['PRCP'])\n\n\n\n\nThatâ€™s much better! We need to aggregate all data from each month, so we can calculate monthly averages. How to do that?\n\n# choose only the precipitation column\ndf_month = df['PRCP']\n# calculate monthly mean\nmonthly_mean = np.array([])  # empty array\nmonth_numbers = np.arange(1,13)\nmonth_names = [month_abbr[i] for i in month_numbers]\n\nfor m in month_numbers:      # cycle over months (1, 2, 3, etc)\n    this_month_all_indices = (df_month.index.month == m)       # indices in df_month belonging to month m\n    this_month_mean = df_month[this_month_all_indices].mean()  # this is the monthly mean\n    monthly_mean = np.append(monthly_mean, this_month_mean)    # append\n\nNow it is time to create a new dataframe with the monthly means.\n\ndf_beersheva = pd.DataFrame({'monthly rainfall (mm)':monthly_mean,\n                             'month names':month_names,\n                             'month number':month_numbers\n                            })\ndf_beersheva\n\n\n\n\n\n  \n    \n      \n      monthly rainfall (mm)\n      month names\n      month number\n    \n  \n  \n    \n      0\n      48.743158\n      Jan\n      1\n    \n    \n      1\n      37.347368\n      Feb\n      2\n    \n    \n      2\n      26.551579\n      Mar\n      3\n    \n    \n      3\n      9.038947\n      Apr\n      4\n    \n    \n      4\n      2.735789\n      May\n      5\n    \n    \n      5\n      0.013830\n      Jun\n      6\n    \n    \n      6\n      0.000000\n      Jul\n      7\n    \n    \n      7\n      0.002128\n      Aug\n      8\n    \n    \n      8\n      0.271277\n      Sep\n      9\n    \n    \n      9\n      6.669474\n      Oct\n      10\n    \n    \n      10\n      21.850526\n      Nov\n      11\n    \n    \n      11\n      41.786316\n      Dec\n      12\n    \n  \n\n\n\n\nPlot the data and see if it makes sense. Try to get a figure like this one.\n\nfig, ax = plt.subplots(figsize=(10,7))\nax.bar(df_beersheva['month number'], df_beersheva['monthly rainfall (mm)'])\nax.set(xlabel=\"months\",\n       ylabel=\"monthly average (mm)\",\n       title=\"Beer Sheva\",\n       xticks=df_beersheva['month number'],\n       xticklabels=df_beersheva['month names']);\nplt.savefig(\"hydrology_figures/beersheva_monthly_average.png\")\n\n\n\n\nLetâ€™s calculate now the Walsh and Lawler Seasonality Index (leddris (2010), Walsh and Lawler (1981)) Write a function that receives a dataframe like the one we have just created, and returns the seasonality index.\n\\(R=\\) mean annual precipitation\n\\(m_i\\) precipitation mean for month \\(i\\)\n\\[ SI = \\displaystyle \\frac{1}{R} \\sum_{n=1}^{n=12} \\left| m_i - \\frac{R}{12} \\right| \\]\n\n\n\n\n\n\n\nSI\nPrecipitation Regime\n\n\n\n\n<0.19\nPrecipitation spread throughout the year\n\n\n0.20-0.39\nPrecipitation spread throughout the year, but with a definite wetter season\n\n\n0.40-0.59\nRather seasonal with a short dry season\n\n\n0.60-0.79\nSeasonal\n\n\n0.80-0.99\nMarked seasonal with a long dry season\n\n\n1.00-1.19\nMost precipitation in < 3 months\n\n\n\n\ndef walsh_index(df):\n    mi = df[\"monthly rainfall (mm)\"]\n    R = df[\"monthly rainfall (mm)\"].sum()\n    SI = np.sum(np.abs(mi - R/12)) / R\n    return SI\nbeersheva_SI = walsh_index(df_beersheva)\nprint(f\"Beer Sheva, SI = {beersheva_SI:.2f}\")\n\nBeer Sheva, SI = 0.97\n\n\n\n\n\n\nleddris. 2010. â€œRainfall Seasonality.â€ Land and Ecosystem Degradation and Desertification Response Information System. http://leddris.aegean.gr/ses-parameters/293-rainfall-seasonality.html#:~:text=Rainfall%20seasonality%20index%20is%20a,in%20relation%20to%20water%20availability.\n\n\nWalsh, RPD, and DM Lawler. 1981. â€œRainfall Seasonality: Description, Spatial Patterns and Change Through Time.â€ Weather 36 (7): 201â€“8. https://doi.org/10.1002/j.1477-8696.1981.tb05400.x."
  },
  {
    "objectID": "precipitation/return-period-lecture.html#bilbao-spain",
    "href": "precipitation/return-period-lecture.html#bilbao-spain",
    "title": "7Â  Return Period",
    "section": "7.1 Bilbao, Spain",
    "text": "7.1 Bilbao, Spain"
  },
  {
    "objectID": "precipitation/return-period-lecture.html#today",
    "href": "precipitation/return-period-lecture.html#today",
    "title": "7Â  Return Period",
    "section": "7.2 Today",
    "text": "7.2 Today"
  },
  {
    "objectID": "precipitation/return-period-lecture.html#august-1983",
    "href": "precipitation/return-period-lecture.html#august-1983",
    "title": "7Â  Return Period",
    "section": "7.3 August 1983",
    "text": "7.3 August 1983\n\nOn Friday, August 26, 1983, Bilbao was celebrating its Aste Nagusia or Great Week, the main annual festivity in the city, when it and other municipalities of the Basque Country, Burgos, and Cantabria suffered devastating flooding due to heavy rains. In 24 hours, the volume of water registered 600 liters per square meter. Across all the affected areas, the weather service recorded 1.5 billion tons of water. In areas of Bilbao, the water reached a height of 5 meters (15 feet). Transportation, electricity and gas services, drinking water, food, telephone, and many other basic services were severely affected. 32 people died in Biscay, 4 people died in Cantabria, 2 people died in Alava, and 2 people died Burgos. 5 more people went missing."
  },
  {
    "objectID": "precipitation/return-period-lecture.html#how-often-will-such-rainfall-happen",
    "href": "precipitation/return-period-lecture.html#how-often-will-such-rainfall-happen",
    "title": "7Â  Return Period",
    "section": "7.4 How often will such rainfall happen?",
    "text": "7.4 How often will such rainfall happen?\nHow often does it rain 50 mm in 1 day? What about 100 mm in 1 day? How big is a â€œonce-in-a-century eventâ€?\nLetâ€™s examine Bilbaoâ€™s daily rainfall (mm), between 1947 to 2021\n\nOn the week of 22-28 August 1983, Bilbaoâ€™s weather station measured 45 cm of rainfall!\n\nLetâ€™s analyze this data and find out how rare such events are. First we need to find the annual maximum for each hydrological year.\n\n\nShow/hide the code\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\ndf = pd.read_csv('BILBAO_daily.csv', sep=\",\")\ndf['DATE'] = pd.to_datetime(df['DATE'])\ndf = df.set_index('DATE')\n# IMPORTANT!! daily precipitation data is in tenths of mm, divide by 10 to get it in mm.\ndf['PRCP'] = df['PRCP'] / 10\n\nimport altair as alt\nalt.data_transformers.disable_max_rows()\n\n# Altair only recognizes column data; it ignores index values.\n# You can plot the index data by first resetting the index\n# I know that I've just made 'DATE' the index, but I want to have this here nonetheless so I can refer to this in the future\ndf_new = df.reset_index()#.replace({0.0:np.nan})\nsource = df_new[['DATE', 'PRCP']]\n\nbrush = alt.selection(type='interval', encodings=['x'])\n\nbase = alt.Chart(source).mark_line().encode(\n    x = 'DATE:T',\n    y = 'PRCP:Q'\n).properties(\n    width=600,\n    height=200\n)\n\nupper = base.encode(\n    alt.X('DATE:T', scale=alt.Scale(domain=brush)),\n    alt.Y('PRCP:Q', scale=alt.Scale(domain=(0,100)))\n)\n\nlower = base.properties(\n    height=60\n).add_selection(brush)\n\nalt.vconcat(upper, lower)\n\n\n\n\n\n\n\nWe will consider a hydrological year starting on 1 August. \n\nTop: Histogram of annual daily precipitation maximum events.\n\nBottom: The cumulative answers the question: â€œHow many events can be found below a given threshold?â€\n\n\n\nTop: We can normalize the histogram such that the total area is 1. Now the histogram is called probability density function (pdf). The probability is NOT the pdf, but the area between two thresholds.\nBottom: The cumulative now becomes a probability between 0 and 1. It is now called cumulative density function (cdf). The cdf answers the question: â€œWhat is the probability to choose an event below a given threshold?â€\n\n\nWe are interested in extreme events, and we want to estimate how many years, on average, do we have to wait to get an annual maximum above a given threshold?\nThis question is very similar to what we asked regarding the cdf. ğŸ¤”\nWe switched the word â€œbelowâ€ for â€œaboveâ€. The complementary of the cumulative is called the exceedance (or survival) probability:\n\\[\n\\text{exceedance, survival} = 1 - \\text{cdf}\n\\]\n\n\n\n\n\nNow everything together in one gif:"
  },
  {
    "objectID": "precipitation/return-period-lecture.html#return-period",
    "href": "precipitation/return-period-lecture.html#return-period",
    "title": "7Â  Return Period",
    "section": "7.5 Return Period",
    "text": "7.5 Return Period\nWe will follow Brutsaert (2005), page 513. He defines quantities a little different from what we did above.\n\\(F(x)\\) is the CDF of the PDF \\(f(x)\\). \\(F(x)\\) indicates the non-exceedance probability, i.e., the probability that a certain event above \\(x\\) has not occurred (or that an event below \\(x\\) has occurred, same thing). Modifying the graph shown above, we have\n\n\\(1-F(x)\\) is the probability that a certain event above \\(x\\) has occurred. Itâ€™s reciprocal is the return period:\n\\[\nT_r(x) = \\frac{1}{1-F(x)}\n\\]\nThis return period is the expected number of observations required until \\(x\\) is exceeded once. In our case, we can ask the question: how many years will pass (on average) until we see a rainfall event greater that that of 26 August 1983?\nLetâ€™s call \\(p=F(x)\\) the probability that we measured once and that an event greater than \\(x\\) has not occurred. What is the probability that a rainfall above \\(x\\) will occur only on year number \\(k\\)?\n\nit hasnâ€™t occurred on year 1 (probability p)\nit hasnâ€™t occurred on year 2 (probability p)\nit hasnâ€™t occurred on year 3 (probability p)\nâ€¦\nit has occurred on year k (probability 1-p)\n\n\\(P\\{k \\text{ trials until }X>x\\} = p^{k-1}(1-p)\\)\nEvery time the number \\(k\\) will be different. What will be \\(k\\) on average?\n\\[\\bar{k} = \\displaystyle\\sum_{k=1}^{\\infty} k P(k) = \\displaystyle\\sum_{k=1}^{\\infty} k p^{k-1}(1-p)\\]\nLetâ€™s open that up:\n\\[\n\\begin{align}\n\\bar{k} &= 1-p + 2p(1-p) + 3p^2(1-p) + 4p^3(1-p)+ \\cdots\\\\\n\\bar{k} &= 1-p + 2p - 2p^2 + 3p^2 - 3p^4 + 4p^3 - 4p^4+ \\cdots \\\\\n\\bar{k} &= 1 + p + p^2 + p^3 + p^4 + \\cdots\n\\end{align}\n\\]\nFor \\(p<1\\), the series converges to \\[\n1 + p + p^2 + p^3 + p^4 + \\cdots = \\frac{1}{1-p},\n\\] therefore \\[\n\\bar{k} = \\frac{1}{1-p}.\n\\]\nWe conclude that if we know the exceedance probability, we immediately can say what the return times are. We now need a way of estimating this exceedance probability."
  },
  {
    "objectID": "precipitation/return-period-lecture.html#generalized-extreme-value-distribution",
    "href": "precipitation/return-period-lecture.html#generalized-extreme-value-distribution",
    "title": "7Â  Return Period",
    "section": "7.6 Generalized extreme value distribution",
    "text": "7.6 Generalized extreme value distribution\nThis part of the lecture was heavily inspired by Alexandre Martinezâ€™s excellent blog post.\nThe Generalized Extreme Value (GEV) distribution is the limit distribution of properly normalized maxima of a sequence of independent and identically distributed random variables (from Wikipedia).\nIt has three parameters: shape, location and scale. We can fit Bilbaoâ€™s annual daily maxima with a GEV distribution, yielding:\n\n\n\n(shape=-0.18, location=52, shape=16)\n\n\nWe will use the fitted parameters to plot the cdf, and then we will find the return periods. How can we calculate the cdf numerically form the data?\n\n7.6.1 cdf from data\nHere is a plot of annual daily precipitation maxima for Bilbao.\n\nThere are 74 points here. Letâ€™s order them from small to large:\n\n\nNow, instead of having the order of the event on the horizontal axis, letâ€™s make it a fraction from 0 to 1.\n\nWe are getting there! We can interpret this fraction as the probability of randomly choosing a point in the graph below the threshold.\n\nNow we just need to flip the vertical and horizontal axes, and weâ€™re done! We have our cdf!\n\nNow that we have the cdf from data, we can plot on top of it the GEV cdf with the parameters we found before.\n\nThe highest data point in this graph goes only to 252 mm, corresponding to the highest event recorded in 74 years. We can use the GEV cdf to calculate return times for any desired levels, simply by converting the vertical axis (cdf) to return period, using the equation we found earlier. \\[\nT_r(x) = \\frac{1}{1-F(x)},\n\\]\nwhere \\(T_r\\) is the return period (in years), and \\(F\\) is the cdf.\n\nThe information contained in the last two graphs is exactly the same, but somehow this last graph looks much worse! Why is this so? Acording to the GEV distribution we got, the return time for a 252 mm event is about 700 years!"
  },
  {
    "objectID": "precipitation/return-period-lecture.html#extra-k-s-test",
    "href": "precipitation/return-period-lecture.html#extra-k-s-test",
    "title": "7Â  Return Period",
    "section": "7.7 Extra: K-S test",
    "text": "7.7 Extra: K-S test\nto be completedâ€¦"
  },
  {
    "objectID": "precipitation/return-period-lecture.html#extra-confidence-interval",
    "href": "precipitation/return-period-lecture.html#extra-confidence-interval",
    "title": "7Â  Return Period",
    "section": "7.8 Extra: confidence interval",
    "text": "7.8 Extra: confidence interval\nto be completedâ€¦\n\n\n\n\n\n\nBrutsaert, Wilfried. 2005. Hydrology: An Introduction. Cambridge University Press."
  },
  {
    "objectID": "precipitation/return-period-exercises.html",
    "href": "precipitation/return-period-exercises.html",
    "title": "8Â  Exercises",
    "section": "",
    "text": "Import relevant packages\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n# from functools import reduce\nimport seaborn as sns\nsns.set(style=\"ticks\", font_scale=1.5)\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\nimport urllib.request\nfrom scipy.stats import genextreme\nfrom scipy.optimize import curve_fit\n\nGo to NOAAâ€™s National Centers for Environmental Information (NCEI)\nClimate Data Online: Dataset Discovery\nFind station codes in this map. On the left, click on the little wrench next to â€œGlobal Summary of the Monthâ€, then click on â€œidentifyâ€ on the panel that just opened, and click on a station (purple circle). You will see the stationâ€™s name, itâ€™s ID, and the period of record. For example, for Ben-Gurionâ€™s Airport in Israel:\nBEN GURION, IS\nSTATION ID: ISM00040180\nPeriod of Record: 1951-01-01 to 2020-03-01\nYou can download daily or monthly data for each station. Use the function below to download this data to your computer. station_name can be whatever you want, station_code is the station ID.\n\ndef download_data(station_name, station_code):\n    url_daily = 'https://www.ncei.noaa.gov/data/global-historical-climatology-network-daily/access/'\n    url_monthly = 'https://www.ncei.noaa.gov/data/gsom/access/'\n    # download daily data - uncomment the following 2 lines to make this work\n    urllib.request.urlretrieve(url_daily + station_code + '.csv',\n                              station_name + '_daily.csv')\n    # download monthly data\n    urllib.request.urlretrieve(url_monthly + station_code + '.csv',\n                               station_name + '_monthly.csv')\n\nDownload daily rainfall data for Eilat, Israel. ID: IS000009972\n\ndownload_data('Eilat', 'IS000009972')\n\nThen load the data into a dataframe.\nIMPORTANT!! daily precipitation data is in tenths of mm, divide by 10 to get it in mm.\n\ndf = pd.read_csv('Eilat_daily.csv', sep=\",\")\n# make 'DATE' the dataframe index\ndf['DATE'] = pd.to_datetime(df['DATE'])\ndf = df.set_index('DATE')\n# IMPORTANT!! daily precipitation data is in tenths of mm, divide by 10 to get it in mm.\ndf['PRCP'] = df['PRCP'] / 10\ndf\n\n\n\n\n\n  \n    \n      \n      STATION\n      LATITUDE\n      LONGITUDE\n      ELEVATION\n      NAME\n      PRCP\n      PRCP_ATTRIBUTES\n      TMAX\n      TMAX_ATTRIBUTES\n      TMIN\n      TMIN_ATTRIBUTES\n      TAVG\n      TAVG_ATTRIBUTES\n    \n    \n      DATE\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      1949-11-30\n      IS000009972\n      29.55\n      34.95\n      12.0\n      ELAT, IS\n      0.0\n      ,,E\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      1949-12-01\n      IS000009972\n      29.55\n      34.95\n      12.0\n      ELAT, IS\n      0.0\n      ,,E\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      1949-12-02\n      IS000009972\n      29.55\n      34.95\n      12.0\n      ELAT, IS\n      0.0\n      ,,E\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      1949-12-03\n      IS000009972\n      29.55\n      34.95\n      12.0\n      ELAT, IS\n      0.0\n      ,,E\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      1949-12-04\n      IS000009972\n      29.55\n      34.95\n      12.0\n      ELAT, IS\n      0.0\n      ,,E\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2023-04-22\n      IS000009972\n      29.55\n      34.95\n      12.0\n      ELAT, IS\n      NaN\n      NaN\n      303.0\n      ,,S\n      177.0\n      ,,S\n      246.0\n      H,,S\n    \n    \n      2023-04-23\n      IS000009972\n      29.55\n      34.95\n      12.0\n      ELAT, IS\n      0.0\n      ,,S\n      294.0\n      ,,S\n      211.0\n      ,,S\n      260.0\n      H,,S\n    \n    \n      2023-04-24\n      IS000009972\n      29.55\n      34.95\n      12.0\n      ELAT, IS\n      NaN\n      NaN\n      328.0\n      ,,S\n      199.0\n      ,,S\n      265.0\n      H,,S\n    \n    \n      2023-04-25\n      IS000009972\n      29.55\n      34.95\n      12.0\n      ELAT, IS\n      NaN\n      NaN\n      319.0\n      ,,S\n      190.0\n      ,,S\n      253.0\n      H,,S\n    \n    \n      2023-04-26\n      IS000009972\n      29.55\n      34.95\n      12.0\n      ELAT, IS\n      NaN\n      NaN\n      334.0\n      ,,S\n      179.0\n      ,,S\n      267.0\n      H,,S\n    \n  \n\n26803 rows Ã— 13 columns\n\n\n\nPlot precipitation data (â€˜PRCPâ€™ column) and see if everything is all right.\n\nfig, ax = plt.subplots(figsize=(10,7))\nax.plot(df['PRCP'])\nax.set_xlabel(\"date\")\nax.set_ylabel(\"daily rainfall (mm)\")\nax.set_title(\"Eilat, 1949â€“2021\")\n\nText(0.5, 1.0, 'Eilat, 1949â€“2021')\n\n\n\n\n\nBased on what you see, you might want to exclude certain periods, e.g.:\n\nlast_date = '2018-08-01'\nfirst_date = '1950-08-01'\ndf = df[((df.index < last_date) & (df.index > first_date))]\ndf\n\n\n\n\n\n  \n    \n      \n      STATION\n      LATITUDE\n      LONGITUDE\n      ELEVATION\n      NAME\n      PRCP\n      PRCP_ATTRIBUTES\n      TMAX\n      TMAX_ATTRIBUTES\n      TMIN\n      TMIN_ATTRIBUTES\n      TAVG\n      TAVG_ATTRIBUTES\n    \n    \n      DATE\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      1950-08-02\n      IS000009972\n      29.55\n      34.95\n      12.0\n      ELAT, IS\n      0.0\n      ,,E\n      400.0\n      ,,G\n      240.0\n      ,,G\n      NaN\n      NaN\n    \n    \n      1950-08-03\n      IS000009972\n      29.55\n      34.95\n      12.0\n      ELAT, IS\n      0.0\n      ,,E\n      410.0\n      ,,G\n      260.0\n      ,,G\n      NaN\n      NaN\n    \n    \n      1950-08-04\n      IS000009972\n      29.55\n      34.95\n      12.0\n      ELAT, IS\n      0.0\n      ,,E\n      400.0\n      ,,G\n      260.0\n      ,,G\n      NaN\n      NaN\n    \n    \n      1950-08-05\n      IS000009972\n      29.55\n      34.95\n      12.0\n      ELAT, IS\n      0.0\n      ,,E\n      NaN\n      NaN\n      240.0\n      ,,G\n      NaN\n      NaN\n    \n    \n      1950-08-06\n      IS000009972\n      29.55\n      34.95\n      12.0\n      ELAT, IS\n      0.0\n      ,,E\n      370.0\n      ,,G\n      240.0\n      ,,G\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2018-07-27\n      IS000009972\n      29.55\n      34.95\n      12.0\n      ELAT, IS\n      0.0\n      ,,S\n      414.0\n      ,,S\n      NaN\n      NaN\n      359.0\n      H,,S\n    \n    \n      2018-07-28\n      IS000009972\n      29.55\n      34.95\n      12.0\n      ELAT, IS\n      0.0\n      ,,S\n      386.0\n      ,,S\n      NaN\n      NaN\n      329.0\n      H,,S\n    \n    \n      2018-07-29\n      IS000009972\n      29.55\n      34.95\n      12.0\n      ELAT, IS\n      0.0\n      ,,S\n      NaN\n      NaN\n      268.0\n      ,,S\n      334.0\n      H,,S\n    \n    \n      2018-07-30\n      IS000009972\n      29.55\n      34.95\n      12.0\n      ELAT, IS\n      0.0\n      ,,S\n      375.0\n      ,,S\n      277.0\n      ,,S\n      327.0\n      H,,S\n    \n    \n      2018-07-31\n      IS000009972\n      29.55\n      34.95\n      12.0\n      ELAT, IS\n      0.0\n      ,,S\n      390.0\n      ,,S\n      NaN\n      NaN\n      336.0\n      H,,S\n    \n  \n\n24836 rows Ã— 13 columns\n\n\n\nThe rainfall data for Eilat is VERY seasonal, itâ€™s easy to see that there is no rainfall at all during the summer. We can assume a hydrological year starting on 1 August. If youâ€™re not sure, you can plot the monthly means (see last weekâ€™s lecture) and find what date makes sense best.\n\ndf_month = df['PRCP'].resample('M').sum().to_frame()\nmonth_numbers = np.arange(1,13)\nmonthly_mean = np.array([])  # empty array\nfor m in month_numbers:      # cycle over months (1, 2, 3, etc)\n    this_month_mean = df_month[df_month.index.month == m].mean()  # this is the monthly mean\n    monthly_mean = np.append(monthly_mean, this_month_mean)    # append\n    # make new df and return it\ndf_month = pd.DataFrame({'monthly rainfall (mm)':monthly_mean,\n                          'month number':month_numbers\n                         })\nfig, ax = plt.subplots(figsize=(10,7))\nax.bar(df_month['month number'], df_month['monthly rainfall (mm)'])\nax.set(xlabel=\"month\",\n       ylabel=\"monthly rainfall (mm)\",\n       title=\"Monthly average, Eilat, 1949--2018\",\n       xticks=np.arange(1,13));\n\n\n\n\nLetâ€™s resample the data according to the hydrological year (1 August), and weâ€™ll keep the maximum value:\n\nmax_annual = (df['PRCP'].resample('A-JUL')\n                        .max()\n                        .to_frame()\n             )\nmax_annual\n\n\n\n\n\n  \n    \n      \n      PRCP\n    \n    \n      DATE\n      \n    \n  \n  \n    \n      1951-07-31\n      10.8\n    \n    \n      1952-07-31\n      15.0\n    \n    \n      1953-07-31\n      34.4\n    \n    \n      1954-07-31\n      24.3\n    \n    \n      1955-07-31\n      19.0\n    \n    \n      ...\n      ...\n    \n    \n      2014-07-31\n      11.5\n    \n    \n      2015-07-31\n      2.4\n    \n    \n      2016-07-31\n      8.5\n    \n    \n      2017-07-31\n      34.5\n    \n    \n      2018-07-31\n      11.7\n    \n  \n\n68 rows Ã— 1 columns\n\n\n\nMake two graphs: a) the histogram for the annual maximum (pdf) b) the cumulative probability (cdf)\n\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,8))\n\nh=max_annual['PRCP'].values\nax1.hist(h, bins=np.arange(0,100,10), density=True)\nax2.hist(h, bins=np.arange(0,100,10), cumulative=1, density=True)\n\nax1.set(ylabel=\"pdf\")\nax2.set(xlabel=\"annual daily precipitation maxima (mm)\",\n        ylabel=\"cdf\",\n        );\n\n\n\n\nHow to make a cdf by yourself?\n\n# sort the annual daily precipitation maxima, from lowest to highest\nmax_annual['max_sorted'] = np.sort(max_annual['PRCP'])\n# let's give it a name, h\nh = max_annual['max_sorted'].values\n# make an array \"order\" of size N=len(h), from 0 to N-1\nN = len(h)\norder = np.arange(N)\n# make a new array, \"fraction\"\nfraction = order / N\n\nPlot it next to the cdf that pandasâ€™ hist makes for you. What do you see?\n\nfig, ax = plt.subplots(1, 1)\nax.hist(h, bins=np.arange(0,100,10), cumulative=1, density=True, label=\"from 'hist'\")\nax.plot(h, fraction, color=\"tab:orange\", linewidth=3, label=\"our cdf\")\nax.set_ylabel(\"cdf\")\nax.set_xlabel(\"annual daily precipitation maxima (mm)\")\nax.set_title(\"Eilat\")\nax.legend()\n\n<matplotlib.legend.Legend at 0x7faf946b35b0>\n\n\n\n\n\nThe generalized extreme value distribution has 3 parameters: shape, location, scale.\nLetâ€™s get a â€œbest fitâ€ estimate of these parameters for Eilatâ€™s rainfall statistics.\n\nparams = genextreme.fit(h)\nprint(\"Best fit:\")\nprint(f\"shape = {params[0]:.2f}\\nlocation = {params[1]:.2f}\\nscale = {params[2]:.2f}\")\n\nBest fit:\nshape = -0.44\nlocation = 6.17\nscale = 5.58\n\n\nLetâ€™s see the GEV distribution for these parameters\n\nfig, ax = plt.subplots(1, 1)\nax.hist(h, bins=np.arange(0,100,10), density=True, label=\"from 'hist'\")\nrain = np.arange(0,80)\npdf_rain = genextreme(c=params[0], loc=params[1], scale=params[2]).pdf(rain)\nax.plot(rain, pdf_rain, color=\"tab:orange\", lw=3, label=\"gev fit\")\nax.set_ylabel(\"pdf\")\nax.set_xlabel(\"annual daily precipitation maxima (mm)\")\nax.set_title(\"Eilat\")\nax.legend()\n\n<matplotlib.legend.Legend at 0x7faf96631f40>\n\n\n\n\n\nWe can do the same for the cdfâ€¦\n\nfig, ax = plt.subplots(1, 1)\nax.plot(h, fraction, color=\"tab:blue\", linewidth=3, label=\"our cdf\")\nrain = np.arange(0,80)\ncdf_rain = genextreme(c=params[0], loc=params[1], scale=params[2]).cdf(rain)\nax.plot(rain, cdf_rain, color=\"tab:orange\", lw=3, label=\"gev fit\")\nax.set_ylabel(\"cdf\")\nax.set_xlabel(\"annual daily precipitation maxima (mm)\")\nax.set_title(\"Eilat\")\nax.legend()\n\n<matplotlib.legend.Legend at 0x7faf8caaabb0>\n\n\n\n\n\nWe are almost there! Remember that the return time are given by:\n\\[\nT_r(x) = \\frac{1}{1-F(x)},\n\\]\nwhere \\(F\\) is the cdf.\nSurvival \\(= 1-F\\)\nThe package that we are using, scipy.stats.genextreme has a method called isf, or inverse survival function, which is exactly what we want! In order to use it, you have to feed it a â€œquantileâ€ q or probability. Suppose you want to know how strong is a 1 in a 100 year event, then your return period is 100 (years), and the probability is simply its inverse, 1/100.\n\n# Compute the return levels for several return periods.\nreturn_periods = np.array([5, 10, 20, 50, 100, 500])\nreturn_levels = genextreme.isf(1/return_periods, *params)\n\nprint(\"Return levels:\")\nprint()\nprint(\"Period    Level\")\nprint(\"(years)   (mm)\")\n\nfor period, level in zip(return_periods, return_levels):\n    print(f'{period:4.0f}  {level:9.2f}')\n\nReturn levels:\n\nPeriod    Level\n(years)   (mm)\n   5      18.03\n  10      27.64\n  20      40.38\n  50      64.17\n 100      89.63\n 500     189.22\n\n\nYou might want to do the opposite: given a list of critical daily max levels, what are the return periods for them? In this case you can use the sf method, â€œsurvival functionâ€.\n\nlevels_mm = np.array([20, 50, 100, 200, 300])\nreturn_per = 1/genextreme.sf(levels_mm, *params)\n\nprint(\"Return levels:\")\nprint()\nprint(\"Level       Period\")\nprint(\"(mm)       (years)\")\n\nfor level,period in zip(levels_mm, return_per):\n    print(f'{level:9.2f}  {period:4.0f}')\n\nReturn levels:\n\nLevel       Period\n(mm)       (years)\n    20.00     6\n    50.00    30\n   100.00   126\n   200.00   565\n   300.00  1383"
  },
  {
    "objectID": "evapotranspiration/evapotranspiration-lecture.html",
    "href": "evapotranspiration/evapotranspiration-lecture.html",
    "title": "9Â  Evapotranspiration",
    "section": "",
    "text": "10 Meaning of â€œpotentialâ€ evapotranspiration"
  },
  {
    "objectID": "evapotranspiration/evapotranspiration-lecture.html#review-of-methods",
    "href": "evapotranspiration/evapotranspiration-lecture.html#review-of-methods",
    "title": "9Â  Evapotranspiration",
    "section": "9.1 Review of methods",
    "text": "9.1 Review of methods\nThere are a variety of ways to estimate evaporative flux in nature. The following table categorizes each method based on the data that must be acquired to apply it:\n\nThese methods also vary in the timescales in which they are relevant, typically in correlation with the variety of data needed: - Thornthwaite and SCS Blaney-Criddle: monthly or seasonal estimations (minimal data) - Jensen-Haise: 5-day estimates (good enough timescale and data for irrigation scheduling) - Penman: daily estimates - Penman-Monteith: hourly estimates (requires a lot of data)"
  },
  {
    "objectID": "evapotranspiration/evapotranspiration-lecture.html#thornthwaite",
    "href": "evapotranspiration/evapotranspiration-lecture.html#thornthwaite",
    "title": "9Â  Evapotranspiration",
    "section": "9.2 Thornthwaite",
    "text": "9.2 Thornthwaite\nSource: Ward & Trimble, â€œEnvironmental Hydrologyâ€, 2nd Edition, pages 107-108.\nThornthwaite (1948) developed an equation to predict monthly evapotranspiration from mean monthly tempera- ture and latitude data (Equation 4.27). The small amount of data needed is attractive because often ET needs to be predicted for sites where few weather data are available. Based on what we know about ET, we should be skeptical about the general applicability of such a simple equation. Thornthwaite (1948) was not satisfied with the proposed approach: â€œThe mathematical development is far from satisfactory. It is empirical. â€¦ The chief obstacle at present to the development of a rational equation is the lack of understanding of why potential ET corresponding to a given temperature is not the same everywhere.â€\nTaylor and Ashcroft (1972), as cited in Skaggs (1980), provided insight into the answer to Thornthwaiteâ€™s ques- tion. They said:\n> This equation, being based entirely upon a temperature relationship, has the disadvantage of a rather flimsy phys- ical basis and has only weak theoretical justification. Since temperature and vapor pressure gradients are mod- ified by the movement of air and by the heating of the soil and surroundings, the formula is not generally valid, but must be tested empirically whenever the climate is appreciably different from areas in which it has been tested. â€¦ In spite of these shortcomings, the method has been widely used. Because it is based entirely on temper- ature data that are available in a large number of localities, it can be applied in situations where the basic data of the Penman method are not available.\nM.E. Jensen et al.Â (1990) warn that Thornthwaiteâ€™s method is generally only applicable to areas that have climates similar to that of the east central U.S., and it is not applicable to arid and semiarid regions.\nThornthwaite (1948) found that evapotranspiration could be predicted from an equation of the form\n\\[\n\\begin{equation}\nE = 16\\left[ \\frac{10\\,T^\\text{monthly mean}}{I} \\right]^a,\n\\end{equation}\n\\] where \\[\n\\begin{equation}\nI = \\sum_{i=1}^{12} \\left[ \\frac{T_i^\\text{monthly mean}}{5} \\right]^{1.514},\n\\end{equation}\n\\] and \\[\n\\begin{align}\na &= 6.75\\times 10^{-7}I^3 \\\\\n   &- 7.71\\times 10^{-5}I^2 \\nonumber\\\\\n   &+ 1.792\\times 10^{-2}I \\nonumber\\\\\n   &+ 0.49239 \\nonumber\n\\end{align}\n\\]\n\n\\(E\\) is the monthly potential ET (mm)\n\\(T_\\text{monthly mean}\\) is the mean monthly temperature in Â°C\n\\(I\\) is a heat index\n\\(a\\) is a location-dependent coefficient"
  },
  {
    "objectID": "evapotranspiration/evapotranspiration-lecture.html#penman",
    "href": "evapotranspiration/evapotranspiration-lecture.html#penman",
    "title": "9Â  Evapotranspiration",
    "section": "9.3 Penman",
    "text": "9.3 Penman\nSources:\nBrutsaert, â€œHydrology: An Introductionâ€, pages 123-127.\nWard & Trimble, â€œEnvironmental Hydrologyâ€, 2nd Edition, subsections 4.5.2, 4.5.3, 4.5.5, 4.6.6.\nAllen et al.Â (1998), â€œCrop evapotranspiration - Guidelines for computing crop water requirements - FAO Irrigation and drainage paper 56â€\nThe Penman model is almost entirely a theory-based formula for predicting evaporative flux. It can run on a much finer timescale, and requires a much wider variety of data than most models. In addition to temperature, the Penman functions on measurements of radiation, wind speed, elevation above sea level, vapor-pressure deficit, and heat flux density to the ground. The potential ET (in mm d\\(^{-1}\\)) is given by:\n\\[\n\\begin{equation}\nE = \\frac{1}{\\lambda}\\left[ \\frac{\\Delta}{\\Delta+\\gamma}Q_{ne}+ \\frac{\\gamma}{\\Delta+\\gamma}E_A \\right],\n\\end{equation}\n\\]\nwhere \\(Q_n\\) is the available energy flux density\n\\[\n\\begin{equation}\nQ_n = R_n - G,\n\\end{equation}\n\\]\nand \\(E_A\\) is the drying power of the air\n\\[\n\\begin{equation}\nE_A = 6.43\\cdot f(u)\\cdot\\text{VPD}.\n\\end{equation}\n\\]\nThe constituents of the equations above are\n\n\\(E\\): potential evapotranspiration (mm d\\(^{-1}\\))\n\\(\\Delta\\): slope of the saturation water vapor pressure curve (kPa Â°C\\(^{-1}\\))\n\\(\\gamma\\): psychrometric constant (kPA Â°C\\(^{-1}\\))\n\\(\\lambda\\): latent heat of vaporization (MJ kg\\(^{-1}\\))\n\\(R_n\\): net radiation (MJ m\\(^{-2} d^{-1}\\))\n\\(G\\): heat flux density to the ground (MJ m\\(^{-2} d^{-1}\\))\n\\(f(u)\\): wind function (dimensionless)\nVPD: vapor pressure deficit (kPa)\n\nand the number 6.43 adjusts the units of \\(E_A\\) so it is in MJ m\\(^{-2} d^{-1}\\). In what follows, we will further discuss these constituents.\n\n9.3.1 Psychrometric Constant\nThe psychrometric constant \\(\\gamma\\) (kPA Â°C\\(^{-1}\\)) relates the partial pressure of water in air to the air temperature:\n\\[\n  \\begin{equation}\n    \\gamma = \\frac{c_p\\, P}{\\lambda\\cdot MW_\\text{ratio}}\n  \\end{equation}\n\\]\n\\[\n  \\begin{equation}\n    P = 101.3-0.01055 H\n  \\end{equation}\n  \\]\n\\[\n  \\begin{equation}\n    \\lambda = 2.501 - 2.361\\times 10^{-3}\\,T\n  \\end{equation}\n  \\]\n\n\\(MW_\\text{ratio}=0.622\\): ratio molecular weight of water vapor/dry air\n\\(P\\): atmospheric pressure (kPa). Can be either measured or inferred from station height above sea level (m).\n\\(\\lambda\\): latent heat of water vaporization (MJ kg\\(^{-1}\\))\n\\(c_p=0.001013\\): specific heat capacity of moist air (MJ kg\\(^{-1}\\) Â°C\\(^{-1}\\))\n\n\n\n9.3.2 Net Radiation\nSource: Ward & Trimble, â€œEnvironmental Hydrologyâ€, 2nd Edition, page 99.\n\\(R_n\\) (MJ m\\(^{-2} d^{-1}\\)) is net radiation, the balance between net short wave \\(R_s\\) and the long wave \\(R_b\\) components of the radiation:\n\\[R_n = (1-\\alpha)R_s\\!\\! \\downarrow -R_b \\!\\! \\uparrow,\\]\nwhere \\(\\alpha\\) (dimensionless) is the albedo. The net outgoing thermal radiation \\(R_b\\) is given by\n\\[R_b = \\left( a\\frac{R_s}{R_{so}+b} \\right)R_{bo},\\]\nwhere \\(R_{so}\\) is the solar radiation on a cloudless day, and it depends on latitude and day of the year. \\(R_{bo}\\) is given by\n\\[R_{bo} = \\epsilon\\, \\sigma\\, T^4_{Kelvin},\\]\nwhere \\(\\sigma=4.903\\times 10^{-9}\\) MJ m\\(^{-2}\\) d\\(^{-1}\\) K\\(^{-4}\\), and \\(\\epsilon\\) is net net emissivity:\n\\[\\epsilon=-0.02+0.261 \\exp\\left(-7.77\\times10^{-4}T_{Celcius}^2\\right).\\]\nThe parameters \\(a\\) and \\(b\\) are determined for the climate of the area:\n\n\\(a=1.0\\), \\(b=0.0\\) for humid areas,\n\\(a=1.2\\), \\(b=-0.2\\) for arid areas,\n\\(a=1.1\\), \\(b=-0.1\\) for semihumid areas.\n\nWe can find below a table for \\(R_{so}\\), from Ward & Trimble, â€œEnvironmental Hydrologyâ€, 2nd Edition, page 100. \n\n\n9.3.3 Heat Flux Density to the Ground\nThe heat flux density to the ground \\(G\\) (MJ m\\(^{-2} d^{-1}\\)) can be calculated using\n\\[\n  \\begin{equation}\n    G = 4.2\\frac{T_{i+1}-T_{i-1}}{\\Delta t},\n  \\end{equation}\n\\]\nwhere \\(\\Delta t\\) is the time in days between midpoints of time periods \\(i+1\\) and \\(iâˆ’1\\), and \\(T\\) is the air temperature (Â°C).\nThis expression is really a finite differences implementation of a time derivative:\n\\[\n\\displaystyle \\frac{\\text{d}T}{\\text{d}t} = \\lim_{\\Delta t\\rightarrow 0}\\frac{T(t+\\Delta t) - T(t-\\Delta t)}{2\\Delta t}.\n\\]\nLater on, we will take advantage of numpyâ€™s gradient function to calculate \\(G\\).\n\n\n9.3.4 Vapor Pressure\nfrom: Ward & Trimble, â€œEnvironmental Hydrologyâ€, 2nd Edition, page 95.\nThe Vapor Pressure Deficit (VPD, in kPa) is the difference between saturation vapor pressure \\(e_s\\) and actual vapor pressure \\(e_d\\):\n\\[\\text{VPD} = e_s - e_d.\\]\nFor temperatures ranging from 0 to 50 Â°C, the saturation vapor pressure can be calculated with\n\\[\n  \\begin{equation}\n    e_s = \\exp \\left[ \\frac{16.78\\, T -116.9}{T+237.3} \\right],\n  \\end{equation}\n\\]\nand the actual vapor pressure is given by\n\\[\n  \\begin{equation}\n    e_d = e_s \\frac{RH}{100},\n  \\end{equation}\n\\]\nwhere \\(RH\\) is the relative humidity (%), and the temperature \\(T\\) in the equations above is in degrees Celcius.\nWe can see below a graph of \\(e_s(T)\\) (Ward & Trimble, â€œEnvironmental Hydrologyâ€, 2nd Edition, page 96)\n\nThe factor \\(\\Delta\\) is the slope of \\(e_s(T)\\). See the figure below from Brutsaert, where the saturation vapor pressure is called \\(e^*\\) (Brutsaert, â€œHydrology: An Introductionâ€, page 28)):\n\nThere are a few ways of defining the function for \\(\\Delta(T)\\) (kPa Â°C\\(^{-1}\\)). Ward & Trimble give the following:\n\\[\n  \\begin{equation}\n    \\Delta = 0.200 \\cdot (0.00738\\,T + 0.8072)^7 - 0.000116,\n  \\end{equation}\n\\]\nwhile differentiating the exponential expression given before yields:\n\\[\n  \\begin{equation}\n    \\Delta = \\frac{\\text{d} e_s}{\\text{d}T} = e_s(T)\\cdot \\frac{4098.79}{(T+237.3)^2}.\n  \\end{equation}\n\\]\n\n\n9.3.5 Wind Function\nSource: (Ward & Trimble, â€œEnvironmental Hydrologyâ€, 2nd Edition, page 108)\n\\[\n  \\begin{equation}\n    f(u) = 0.26(1.0 + 0.54\\, u_2)\n  \\end{equation}\n\\]"
  },
  {
    "objectID": "evapotranspiration/evapotranspiration-lecture.html#pitfalls",
    "href": "evapotranspiration/evapotranspiration-lecture.html#pitfalls",
    "title": "9Â  Evapotranspiration",
    "section": "10.1 Pitfalls",
    "text": "10.1 Pitfalls\nDifferent books and papers will present slightly different versions of the Penman equation. Basically, they differ in the units they use for the various components, and one should be vary aware of what inputs any given equation is expecting to get."
  },
  {
    "objectID": "evapotranspiration/evapotranspiration-exercises.html#download-data-from-the-ims",
    "href": "evapotranspiration/evapotranspiration-exercises.html#download-data-from-the-ims",
    "title": "10Â  Exercises",
    "section": "10.1 Download data from the IMS",
    "text": "10.1 Download data from the IMS\nPlease follow the instructions below exactly as they are written. Go to the Israel Meteorological Service website, and download the following data:\n\n10-min data\n\n\nOn the navigation bar on the left, choose â€œ10 Minutes Observationsâ€\nClock: Local time winter (UTC +2)\nChoose the following date range: 01/01/2020 00:00 to 01/01/2021 00:00\nChoose station Bet Dagan\nSelect units: Celcius, m/s, KJ/m\\(^2\\)\nUnder â€œSelect parametersâ€, choose â€œCheck Allâ€\nChoose option â€œby stationâ€, then â€œSubmitâ€\nâ€œDownload Result asâ€ CSV, call it bet-dagan-10min.csv\n\n\nradiation data\n\n\nOn the navigation bar on the left, choose â€œHourly Radiationâ€\nClock: Local time winter (UTC +2)\nChoose the following date range: 01/01/2020 00:00 to 01/01/2021 00:00\nSelect hours: Check all hours\nChoose station Bet Dagan\nSelect units: KJ/m\\(^2\\)\nUnder â€œSelect parametersâ€, choose â€œCheck Allâ€\nâ€œDownload Result asâ€ CSV, call it bet-dagan-radiation.csv\n\n\npan evaporation data\n\n\nOn the navigation bar on the left, choose â€œDaily Observationsâ€\nChoose the following date range: 01/01/2020 00:00 to 01/01/2021 00:00\nChoose station Bet Dagan Man\nSelect units: Celcius\nUnder â€œSelect parametersâ€, choose â€œCheck Allâ€\nâ€œDownload Result asâ€ CSV, call it bet-dagan-pan.csv"
  },
  {
    "objectID": "evapotranspiration/evapotranspiration-exercises.html#install-and-import-relevant-packages",
    "href": "evapotranspiration/evapotranspiration-exercises.html#install-and-import-relevant-packages",
    "title": "10Â  Exercises",
    "section": "10.2 Install and import relevant packages",
    "text": "10.2 Install and import relevant packages\nWe will need to use two new packages:\n\npyet: Estimation of Potential Evapotranspiration\nnoaa_ftp: Download data from NOAA\n\nIf you donâ€™t have them installed yet, run this:\n\n!pip install pyet\n!pip install noaa_ftp\n\nOnce they are installed, import all the necessary packages for todayâ€™s exercises.\n\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport numpy as np\nimport pandas as pd\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()  # datetime converter for a matplotlib\nimport seaborn as sns\nsns.set(style=\"ticks\", font_scale=1.5)\nimport pyet\nfrom noaa_ftp import NOAA"
  },
  {
    "objectID": "evapotranspiration/evapotranspiration-exercises.html#import-10-minute-data",
    "href": "evapotranspiration/evapotranspiration-exercises.html#import-10-minute-data",
    "title": "10Â  Exercises",
    "section": "10.3 import 10-minute data",
    "text": "10.3 import 10-minute data\n\ndf = pd.read_csv('bet-dagan-10min.csv',\n                #  encoding = \"ISO-8859-8\",  # this shows hebrew characters properly\n                 na_values=[\"-\"]           # substitute \"-\" for NaN\n                 )\ndf['timestamp'] = pd.to_datetime(df['Date & Time (Winter)'], dayfirst=True)\ndf = df.set_index('timestamp')\n# resample to daily data according to \"mean\"\ndf = df.resample('D').mean()\n# convert hecto pascals (hPa) to kilo pascals (kPa)\ndf[\"Pressure (kPa)\"] = df[\"Pressure at station level (hPa)\"] / 10.0\ndf\n\n/var/folders/c3/7hp0d36n6vv8jc9hm2440__00000gn/T/ipykernel_16976/111106941.py:8: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n  df = df.resample('D').mean()\n\n\n\n\n\n\n  \n    \n      \n      Pressure at station level (hPa)\n      Relative humidity (%)\n      Temperature (Â°C)\n      Maximum temperature (Â°C)\n      Minimum temperature (Â°C)\n      Grass temperature (Â°C)\n      Wind direction (Â°)\n      Gust wind direction (Â°)\n      Wind speed (m/s)\n      Maximum 1 minute wind speed (m/s)\n      Maximum 10 minutes wind speed (m/s)\n      Gust wind speed (m/s)\n      Standard deviation wind direction (Â°)\n      Rainfall (mm)\n      Pressure (kPa)\n    \n    \n      timestamp\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2020-01-01\n      1013.263889\n      80.590278\n      12.375000\n      12.486806\n      12.268750\n      13.061111\n      166.069444\n      166.673611\n      1.552083\n      2.013889\n      1.706250\n      2.325694\n      12.588194\n      0.000000\n      101.326389\n    \n    \n      2020-01-02\n      1011.922917\n      85.631944\n      12.020833\n      12.104861\n      11.921528\n      11.669444\n      149.333333\n      150.062500\n      2.207639\n      2.877083\n      2.438194\n      3.423611\n      12.726389\n      0.140278\n      101.192292\n    \n    \n      2020-01-03\n      1013.757639\n      60.756944\n      12.962500\n      13.086111\n      12.838889\n      13.389583\n      190.513889\n      191.277778\n      4.763194\n      5.940278\n      4.995139\n      7.355556\n      10.436111\n      0.000000\n      101.375764\n    \n    \n      2020-01-04\n      1011.581250\n      76.909722\n      10.849306\n      10.938194\n      10.772222\n      10.311806\n      163.958333\n      164.118056\n      5.439583\n      6.996528\n      5.829167\n      8.632639\n      14.309028\n      0.317361\n      101.158125\n    \n    \n      2020-01-05\n      1012.361806\n      79.583333\n      12.956250\n      13.053472\n      12.864583\n      13.135417\n      195.784722\n      197.326389\n      4.765278\n      6.120833\n      5.097917\n      7.763889\n      12.976389\n      0.112500\n      101.236181\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2020-12-28\n      1014.429861\n      58.729167\n      14.797917\n      14.915972\n      14.659722\n      14.653472\n      93.375887\n      96.758865\n      2.631915\n      3.440426\n      2.842553\n      4.218440\n      11.494326\n      0.000000\n      101.442986\n    \n    \n      2020-12-29\n      1015.031944\n      71.215278\n      14.146528\n      14.315278\n      13.986111\n      14.176389\n      97.777778\n      94.631944\n      1.493750\n      1.951389\n      1.630556\n      2.277083\n      14.328472\n      0.000000\n      101.503194\n    \n    \n      2020-12-30\n      1013.234028\n      68.923611\n      14.186806\n      14.336111\n      14.047222\n      14.187500\n      63.916667\n      63.722222\n      1.776389\n      2.275000\n      1.936111\n      2.646528\n      9.754861\n      0.000000\n      101.323403\n    \n    \n      2020-12-31\n      1011.840972\n      75.465278\n      14.915278\n      15.068056\n      14.763194\n      15.154167\n      165.895833\n      165.062500\n      1.395833\n      1.803472\n      1.546528\n      2.054861\n      10.363194\n      0.000000\n      101.184097\n    \n    \n      2021-01-01\n      1012.748760\n      85.115702\n      14.980992\n      15.133884\n      14.817355\n      15.890083\n      182.247934\n      178.190083\n      1.242975\n      1.691736\n      1.396694\n      1.938843\n      15.280992\n      0.000000\n      101.274876\n    \n  \n\n367 rows Ã— 15 columns"
  },
  {
    "objectID": "evapotranspiration/evapotranspiration-exercises.html#import-radiation-data",
    "href": "evapotranspiration/evapotranspiration-exercises.html#import-radiation-data",
    "title": "10Â  Exercises",
    "section": "10.4 import radiation data",
    "text": "10.4 import radiation data\n\ndf_rad = pd.read_csv('bet-dagan-radiation.csv',\n                     na_values=[\"-\"]\n                     )\ndf_rad['Date'] = pd.to_datetime(df_rad['Date'], dayfirst=True)\ndf_rad = df_rad.set_index('Date')\ndf_rad\n\n\n\n\n\n  \n    \n      \n      Station\n      Radiation type\n      Hourly radiation 05-06 (KJ/m^2)\n      Hourly radiation 06-07 (KJ/m^2)\n      Hourly radiation 07-08 (KJ/m^2)\n      Hourly radiation 08-09 (KJ/m^2)\n      Hourly radiation 09-10 (KJ/m^2)\n      Hourly radiation 10-11 (KJ/m^2)\n      Hourly radiation 11-12 (KJ/m^2)\n      Hourly radiation 12-13 (KJ/m^2)\n      Hourly radiation 13-14 (KJ/m^2)\n      Hourly radiation 14-15 (KJ/m^2)\n      Hourly radiation 15-16 (KJ/m^2)\n      Hourly radiation 16-17 (KJ/m^2)\n      Hourly radiation 17-18 (KJ/m^2)\n      Hourly radiation 18-19 (KJ/m^2)\n    \n    \n      Date\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2020-01-01\n      Bet Dagan Rad 01/1991-04/2023\n      Global\n      0.0\n      10.8\n      270.0\n      594.0\n      1252.8\n      1407.6\n      1800.0\n      1587.6\n      1443.6\n      1123.2\n      482.4\n      57.6\n      0.0\n      0.0\n    \n    \n      2020-01-01\n      Bet Dagan Rad 01/1991-04/2023\n      Direct\n      0.0\n      3.6\n      72.0\n      428.4\n      1393.2\n      1281.6\n      1911.6\n      1414.8\n      1112.4\n      1083.6\n      752.4\n      0.0\n      0.0\n      0.0\n    \n    \n      2020-01-01\n      Bet Dagan Rad 01/1991-04/2023\n      Diffused\n      0.0\n      10.8\n      216.0\n      403.2\n      543.6\n      586.8\n      590.4\n      684.0\n      770.4\n      637.2\n      252.0\n      57.6\n      0.0\n      0.0\n    \n    \n      2020-01-02\n      Bet Dagan Rad 01/1991-04/2023\n      Global\n      0.0\n      10.8\n      241.2\n      518.4\n      1018.8\n      93.6\n      129.6\n      345.6\n      720.0\n      673.2\n      478.8\n      82.8\n      0.0\n      0.0\n    \n    \n      2020-01-02\n      Bet Dagan Rad 01/1991-04/2023\n      Direct\n      0.0\n      3.6\n      57.6\n      100.8\n      471.6\n      0.0\n      0.0\n      32.4\n      140.4\n      334.8\n      680.4\n      79.2\n      0.0\n      0.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2020-12-31\n      Bet Dagan Rad 01/1991-04/2023\n      Direct\n      0.0\n      0.0\n      892.8\n      1998.0\n      2455.2\n      2696.4\n      2710.8\n      2545.2\n      2386.8\n      2066.4\n      1328.4\n      169.2\n      0.0\n      0.0\n    \n    \n      2020-12-31\n      Bet Dagan Rad 01/1991-04/2023\n      Diffused\n      0.0\n      14.4\n      158.4\n      270.0\n      320.4\n      360.0\n      388.8\n      403.2\n      378.0\n      316.8\n      219.6\n      54.0\n      0.0\n      0.0\n    \n    \n      2021-01-01\n      Bet Dagan Rad 01/1991-04/2023\n      Global\n      0.0\n      14.4\n      302.4\n      882.0\n      1432.8\n      1814.4\n      1962.0\n      1897.2\n      1602.0\n      1170.0\n      572.4\n      75.6\n      0.0\n      0.0\n    \n    \n      2021-01-01\n      Bet Dagan Rad 01/1991-04/2023\n      Direct\n      0.0\n      0.0\n      662.4\n      1576.8\n      2181.6\n      2412.0\n      2422.8\n      2343.6\n      2188.8\n      1980.0\n      1350.0\n      126.0\n      0.0\n      0.0\n    \n    \n      2021-01-01\n      Bet Dagan Rad 01/1991-04/2023\n      Diffused\n      0.0\n      14.4\n      172.8\n      352.8\n      421.2\n      478.8\n      525.6\n      540.0\n      478.8\n      381.6\n      237.6\n      57.6\n      0.0\n      0.0\n    \n  \n\n1098 rows Ã— 16 columns\n\n\n\nChoose only â€œGlobalâ€ radiation. Then sum all hours of the day, and convert from kJ to MJ.\n\ndf_rad = df_rad[df_rad[\"Radiation type\"] == \"Global \"]\ndf_rad['daily_radiation_MJ_per_m2_per_day'] = (df_rad.iloc[:, 3:]    # take all rows, columns 3 to end\n                                                           .sum(axis=1) /  # sum all columns\n                                                           1000            # divide by 1000 to convert from kJ to MJ\n                                                    )\ndf_rad\n\n/var/folders/c3/7hp0d36n6vv8jc9hm2440__00000gn/T/ipykernel_16976/3934990453.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_rad['daily_radiation_MJ_per_m2_per_day'] = (df_rad.iloc[:, 3:]    # take all rows, columns 3 to end\n\n\n\n\n\n\n  \n    \n      \n      Station\n      Radiation type\n      Hourly radiation 05-06 (KJ/m^2)\n      Hourly radiation 06-07 (KJ/m^2)\n      Hourly radiation 07-08 (KJ/m^2)\n      Hourly radiation 08-09 (KJ/m^2)\n      Hourly radiation 09-10 (KJ/m^2)\n      Hourly radiation 10-11 (KJ/m^2)\n      Hourly radiation 11-12 (KJ/m^2)\n      Hourly radiation 12-13 (KJ/m^2)\n      Hourly radiation 13-14 (KJ/m^2)\n      Hourly radiation 14-15 (KJ/m^2)\n      Hourly radiation 15-16 (KJ/m^2)\n      Hourly radiation 16-17 (KJ/m^2)\n      Hourly radiation 17-18 (KJ/m^2)\n      Hourly radiation 18-19 (KJ/m^2)\n      daily_radiation_MJ_per_m2_per_day\n    \n    \n      Date\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2020-01-01\n      Bet Dagan Rad 01/1991-04/2023\n      Global\n      0.0\n      10.8\n      270.0\n      594.0\n      1252.8\n      1407.6\n      1800.0\n      1587.6\n      1443.6\n      1123.2\n      482.4\n      57.6\n      0.0\n      0.0\n      10.0296\n    \n    \n      2020-01-02\n      Bet Dagan Rad 01/1991-04/2023\n      Global\n      0.0\n      10.8\n      241.2\n      518.4\n      1018.8\n      93.6\n      129.6\n      345.6\n      720.0\n      673.2\n      478.8\n      82.8\n      0.0\n      0.0\n      4.3128\n    \n    \n      2020-01-03\n      Bet Dagan Rad 01/1991-04/2023\n      Global\n      0.0\n      10.8\n      334.8\n      1040.4\n      1612.8\n      1846.8\n      1904.4\n      1947.6\n      1296.0\n      964.8\n      669.6\n      46.8\n      0.0\n      0.0\n      11.6748\n    \n    \n      2020-01-04\n      Bet Dagan Rad 01/1991-04/2023\n      Global\n      0.0\n      3.6\n      97.2\n      237.6\n      208.8\n      208.8\n      93.6\n      79.2\n      352.8\n      144.0\n      183.6\n      36.0\n      0.0\n      0.0\n      1.6452\n    \n    \n      2020-01-05\n      Bet Dagan Rad 01/1991-04/2023\n      Global\n      0.0\n      7.2\n      118.8\n      226.8\n      421.2\n      882.0\n      1296.0\n      1090.8\n      1242.0\n      1101.6\n      388.8\n      79.2\n      0.0\n      0.0\n      6.8544\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2020-12-28\n      Bet Dagan Rad 01/1991-04/2023\n      Global\n      0.0\n      14.4\n      349.2\n      1000.8\n      1551.6\n      1810.8\n      2048.4\n      1796.4\n      1627.2\n      993.6\n      482.4\n      68.4\n      0.0\n      0.0\n      11.7432\n    \n    \n      2020-12-29\n      Bet Dagan Rad 01/1991-04/2023\n      Global\n      0.0\n      14.4\n      342.0\n      936.0\n      1530.0\n      1926.0\n      2088.0\n      1994.4\n      1702.8\n      1216.8\n      604.8\n      64.8\n      0.0\n      0.0\n      12.4200\n    \n    \n      2020-12-30\n      Bet Dagan Rad 01/1991-04/2023\n      Global\n      0.0\n      21.6\n      302.4\n      986.4\n      1526.4\n      1922.4\n      2080.8\n      2019.6\n      1720.8\n      1238.4\n      612.0\n      68.4\n      0.0\n      0.0\n      12.4992\n    \n    \n      2020-12-31\n      Bet Dagan Rad 01/1991-04/2023\n      Global\n      0.0\n      14.4\n      324.0\n      954.0\n      1476.0\n      1861.2\n      2012.4\n      1908.0\n      1627.2\n      1159.2\n      565.2\n      72.0\n      0.0\n      0.0\n      11.9736\n    \n    \n      2021-01-01\n      Bet Dagan Rad 01/1991-04/2023\n      Global\n      0.0\n      14.4\n      302.4\n      882.0\n      1432.8\n      1814.4\n      1962.0\n      1897.2\n      1602.0\n      1170.0\n      572.4\n      75.6\n      0.0\n      0.0\n      11.7252\n    \n  \n\n366 rows Ã— 17 columns"
  },
  {
    "objectID": "evapotranspiration/evapotranspiration-exercises.html#import-pan-evaporation-data",
    "href": "evapotranspiration/evapotranspiration-exercises.html#import-pan-evaporation-data",
    "title": "10Â  Exercises",
    "section": "10.5 import pan evaporation data",
    "text": "10.5 import pan evaporation data\n\ndf_pan = pd.read_csv('bet-dagan-pan.csv',\n                     na_values=[\"-\"]           # substitute \"-\" for NaN\n                    )\ndf_pan['Date'] = pd.to_datetime(df_pan['Date'], dayfirst=True)\ndf_pan = df_pan.set_index('Date')\ndf_pan\n\n\n\n\n\n  \n    \n      \n      Station\n      Maximum Temperature (Â°C)\n      Minimum Temperature (Â°C)\n      Grass Temperature (Â°C)\n      Hail\n      Frost\n      Snow\n      Fog\n      Mist\n      Dew\n      Thunder\n      Lightening\n      Sand storm\n      Gale\n      Accumulated 6 hr evaporation (mm)\n      Accumulated 12 hr evaporation (mm)\n      Daily evaporation type A (mm)\n      Daily evaporation type A code (code)\n      Sunshine duration (minutes)\n    \n    \n      Date\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2020-01-01\n      Bet Dagan Man 01/1964-03/2023\n      NaN\n      NaN\n      NaN\n      0\n      NaN\n      0\n      0\n      NaN\n      NaN\n      0\n      0\n      0\n      NaN\n      NaN\n      NaN\n      0.8\n      0.0\n      NaN\n    \n    \n      2020-01-02\n      Bet Dagan Man 01/1964-03/2023\n      NaN\n      NaN\n      NaN\n      0\n      NaN\n      0\n      0\n      NaN\n      NaN\n      1\n      0\n      0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      2020-01-03\n      Bet Dagan Man 01/1964-03/2023\n      NaN\n      NaN\n      NaN\n      0\n      NaN\n      0\n      0\n      NaN\n      NaN\n      0\n      0\n      0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      2020-01-04\n      Bet Dagan Man 01/1964-03/2023\n      NaN\n      NaN\n      NaN\n      0\n      NaN\n      0\n      0\n      NaN\n      NaN\n      1\n      0\n      0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      2020-01-05\n      Bet Dagan Man 01/1964-03/2023\n      NaN\n      NaN\n      NaN\n      0\n      NaN\n      0\n      0\n      NaN\n      NaN\n      1\n      0\n      0\n      NaN\n      NaN\n      NaN\n      2.4\n      0.0\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2020-12-28\n      Bet Dagan Man 01/1964-03/2023\n      NaN\n      NaN\n      NaN\n      0\n      NaN\n      0\n      0\n      NaN\n      NaN\n      0\n      0\n      0\n      NaN\n      NaN\n      NaN\n      3.0\n      0.0\n      NaN\n    \n    \n      2020-12-29\n      Bet Dagan Man 01/1964-03/2023\n      NaN\n      NaN\n      NaN\n      0\n      NaN\n      0\n      0\n      NaN\n      NaN\n      0\n      0\n      0\n      NaN\n      NaN\n      NaN\n      1.8\n      0.0\n      NaN\n    \n    \n      2020-12-30\n      Bet Dagan Man 01/1964-03/2023\n      NaN\n      NaN\n      NaN\n      0\n      NaN\n      0\n      0\n      NaN\n      NaN\n      0\n      0\n      0\n      NaN\n      NaN\n      NaN\n      2.4\n      0.0\n      NaN\n    \n    \n      2020-12-31\n      Bet Dagan Man 01/1964-03/2023\n      NaN\n      NaN\n      NaN\n      0\n      NaN\n      0\n      0\n      NaN\n      NaN\n      0\n      0\n      0\n      NaN\n      NaN\n      NaN\n      1.7\n      0.0\n      NaN\n    \n    \n      2021-01-01\n      Bet Dagan Man 01/1964-03/2023\n      NaN\n      NaN\n      NaN\n      0\n      NaN\n      0\n      0\n      NaN\n      NaN\n      0\n      0\n      0\n      NaN\n      NaN\n      NaN\n      1.5\n      0.0\n      NaN\n    \n  \n\n367 rows Ã— 19 columns"
  },
  {
    "objectID": "evapotranspiration/evapotranspiration-exercises.html#calculate-penman",
    "href": "evapotranspiration/evapotranspiration-exercises.html#calculate-penman",
    "title": "10Â  Exercises",
    "section": "10.6 calculate penman",
    "text": "10.6 calculate penman\nWe need some data about the Bet Dagan Station. See here.\n\nLatitude: 32.0073Â°\nElevation: 31 m\n\n\n# average day temperature [Â°C]\ntmean = df[\"Temperature (Â°C)\"]\n# mean day wind speed [m/s]\nwind = df[\"Wind speed (m/s)\"]\n# mean daily relative humidity [%]\nrh = df[\"Relative humidity (%)\"]\n# incoming solar radiation [MJ m-2 d-1]\nrs = df_rad[\"daily_radiation_MJ_per_m2_per_day\"]\n# atmospheric pressure [kPa]\npressure = df[\"Pressure (kPa)\"]\n# the site elevation [m]\nelevation = 31.0\n# the site latitude [rad]\nlatitude = pyet.deg_to_rad(32.0073)\npenm = pyet.combination.penman(tmean=tmean,\n                               wind=wind,\n                               pressure=pressure,\n                               elevation=elevation,\n                               rh=rh,\n                               rs=rs,\n                               lat=latitude,\n                              )\n\n\nfig, ax = plt.subplots(1)\nax.plot(penm, label=\"penman\")\nax.plot(df_pan[\"Daily evaporation type A (mm)\"], label=\"pan\")\nax.legend()\nplt.gcf().autofmt_xdate()  # makes slated dates\nax.set_ylabel(\"ET (mm)\")\n\nText(0, 0.5, 'ET (mm)')"
  },
  {
    "objectID": "evapotranspiration/evapotranspiration-exercises.html#thornthwaite",
    "href": "evapotranspiration/evapotranspiration-exercises.html#thornthwaite",
    "title": "10Â  Exercises",
    "section": "10.7 Thornthwaite",
    "text": "10.7 Thornthwaite\n\\[\nE = 16\\left[ \\frac{10\\,T^\\text{monthly mean}}{I} \\right]^a,\n\\]\nwhere\n\\[\nI = \\sum_{i=1}^{12} \\left[ \\frac{T_i^\\text{monthly mean}}{5} \\right]^{1.514},\n\\]\nand\n\\[\n\\begin{align}\na &= 6.75\\times 10^{-7}I^3 \\\\\n   &- 7.71\\times 10^{-5}I^2 \\nonumber\\\\\n   &+ 1.792\\times 10^{-2}I \\nonumber\\\\\n   &+ 0.49239 \\nonumber\n\\end{align}\n\\]\n\n\\(E\\) is the monthly potential ET (mm)\n\\(T_\\text{monthly mean}\\) is the mean monthly temperature in Â°C\n\\(I\\) is a heat index\n\\(a\\) is a location-dependent coefficient\n\nFrom df, make a new dataframe, df_th, that stores monthly temperatures means. Use resample function.\n\n# monthly data\ndf_th = (df['Temperature (Â°C)'].resample('MS')  # MS assigns mean to first day in the month\n                               .mean()\n                               .to_frame()\n        )\n        \n# we now add 14 days to the index, so that all monthly data is in the middle of the month\n# not really necessary, makes plot look better\ndf_th.index = df_th.index + pd.DateOffset(days=14)\ndf_th\n\n\n\n\n\n  \n    \n      \n      Temperature (Â°C)\n    \n    \n      timestamp\n      \n    \n  \n  \n    \n      2020-01-15\n      12.484812\n    \n    \n      2020-02-15\n      14.044349\n    \n    \n      2020-03-15\n      16.371381\n    \n    \n      2020-04-15\n      18.476339\n    \n    \n      2020-05-15\n      23.177769\n    \n    \n      2020-06-15\n      24.666423\n    \n    \n      2020-07-15\n      27.380466\n    \n    \n      2020-08-15\n      28.099328\n    \n    \n      2020-09-15\n      28.421644\n    \n    \n      2020-10-15\n      25.058944\n    \n    \n      2020-11-15\n      19.266082\n    \n    \n      2020-12-15\n      15.915031\n    \n    \n      2021-01-15\n      14.980992\n    \n  \n\n\n\n\nCalculate \\(I\\), then \\(a\\), and finally \\(E_p\\). Add \\(E_p\\) as a new column in df_th.\n\n# Preparing \"I\" for the Thornthwaite equation\nI = np.sum(\n             (\n               df_th['Temperature (Â°C)'] / 5\n             ) ** (1.514)\n          )\n\n# Preparing \"a\" for the Thornthwaite equation\na = (+6.75e-7 * I**3 \n     -7.71e-5 * I**2\n     +1.792e-2 * I\n     + 0.49239)\n\n# The final Thornthwaite model for monthly potential ET (mm)\ndf_th['Ep (mm/month)'] = 16*(\n                               (\n                                  10 * df_th['Temperature (Â°C)'] / I\n                               ) ** a\n                            )\ndf_th\n\n\n\n\n\n  \n    \n      \n      Temperature (Â°C)\n      Ep (mm/month)\n    \n    \n      timestamp\n      \n      \n    \n  \n  \n    \n      2020-01-15\n      12.484812\n      20.018337\n    \n    \n      2020-02-15\n      14.044349\n      26.999656\n    \n    \n      2020-03-15\n      16.371381\n      39.865158\n    \n    \n      2020-04-15\n      18.476339\n      54.213825\n    \n    \n      2020-05-15\n      23.177769\n      96.461505\n    \n    \n      2020-06-15\n      24.666423\n      112.997152\n    \n    \n      2020-07-15\n      27.380466\n      147.331024\n    \n    \n      2020-08-15\n      28.099328\n      157.362480\n    \n    \n      2020-09-15\n      28.421644\n      161.990981\n    \n    \n      2020-10-15\n      25.058944\n      117.623700\n    \n    \n      2020-11-15\n      19.266082\n      60.299205\n    \n    \n      2020-12-15\n      15.915031\n      37.101123\n    \n    \n      2021-01-15\n      14.980992\n      31.814464\n    \n  \n\n\n\n\n\nfig, ax = plt.subplots(1)\nax.plot(penm, label=\"penman\")\nax.plot(df_pan[\"Daily evaporation type A (mm)\"], label=\"pan\")\nax.plot(df_th['Ep (mm/month)']/30, label=\"thornthwaite\")\n\nax.legend()\nplt.gcf().autofmt_xdate()  # makes slated dates\nax.set_ylabel(\"ET (mm/day)\")\n\nText(0, 0.5, 'ET (mm/day)')"
  },
  {
    "objectID": "evapotranspiration/evapotranspiration-exercises.html#data-from-noaa",
    "href": "evapotranspiration/evapotranspiration-exercises.html#data-from-noaa",
    "title": "10Â  Exercises",
    "section": "10.8 Data from NOAA",
    "text": "10.8 Data from NOAA\nLetâ€™s download data from a different repository. More specifically, we will retrieve sub-hourly data from the U.S. Climate Reference Network. We can see all the sites in this map. Besides the sub-hourly data, we can find other datasets (monthly, daily, etc).\nAs an example, we will choose the statin in Austin, Texas. In order to download, we will access the data from the FTP client using the python package noaa_ftp.\nThe dir command list everything in the folder:\n\nnoaa_dir = NOAA(\"ftp.ncdc.noaa.gov\", 'pub/data/uscrn/products/subhourly01').dir()\n\ndrwxrwsr-x   2 ftp      ftp          8192 Oct  7  2020 2006\ndrwxrwsr-x   2 ftp      ftp          8192 Nov 10  2021 2007\ndrwxrwsr-x   2 ftp      ftp          8192 Dec  1  2020 2008\ndrwxrwsr-x   2 ftp      ftp         12288 May 25  2021 2009\ndrwxrwsr-x   2 ftp      ftp         12288 Nov 10  2021 2010\ndrwxrwsr-x   2 ftp      ftp         12288 Nov 12  2021 2011\ndrwxrwsr-x   2 ftp      ftp         12288 Nov 12  2021 2012\ndrwxrwsr-x   2 ftp      ftp         12288 Nov 15  2021 2013\ndrwxrwsr-x   2 ftp      ftp         12288 Nov 15  2021 2014\ndrwxrwsr-x   2 ftp      ftp         12288 Nov 12  2021 2015\ndrwxrwsr-x   2 ftp      ftp         12288 Nov 12  2021 2016\ndrwxrwsr-x   2 ftp      ftp         12288 Nov 15  2021 2017\ndrwxrwsr-x   2 ftp      ftp         12288 Nov 12  2021 2018\ndrwxrwsr-x   2 ftp      ftp         12288 Nov 24  2021 2019\ndrwxrwsr-x   2 ftp      ftp         12288 Nov 30  2021 2020\ndrwxrwsr-x   2 ftp      ftp         12288 Jan 29  2022 2021\ndrwxrwsr-x   2 ftp      ftp         12288 Aug 23  2022 2022\ndrwxrwsr-x   2 ftp      ftp         12288 Feb  2 16:55 2023\n-rw-rw-r--   1 ftp      ftp          2157 Feb 18  2022 headers.txt\n-rw-rw-r--   1 ftp      ftp           456 Oct  7  2020 HEADERS.txt\n-rw-rw-r--   1 ftp      ftp         14892 Feb 18  2022 readme.txt\n-rw-rw-r--   1 ftp      ftp         14936 Sep 21  2021 README.txt\ndrwxrwsr-x   2 ftp      ftp          4096 Apr 24 01:50 snapshots\n\n\nLetâ€™s download two files: * sub-hourly data for the year 2022 for Austin, TX. * the HEADERS.txt contains the names of the columns in the csv.\n\nnoaa = NOAA(\"ftp.ncdc.noaa.gov\", 'pub/data/uscrn/products/subhourly01').download('HEADERS.txt')\nnoaa = NOAA(\"ftp.ncdc.noaa.gov\", 'pub/data/uscrn/products/subhourly01/2022').download('CRNS0101-05-2022-TX_Austin_33_NW.txt')\n\nDownloading:   0% [                                  ] ETA:  --:--:--   0.0 s/B\nDownloading: 100% [##################################] ETA:  00:00:00 505.2 B/s\nDownloading:   0% [                                  ] ETA:  --:--:--   0.0 s/B\nDownloading:   0% [                                ] ETA:   0:32:21   7.1 KiB/s\nDownloading:   0% [                                ] ETA:   0:22:44  10.1 KiB/s\nDownloading:   0% [                                ] ETA:   0:10:06  22.8 KiB/s\nDownloading:   0% [                                ] ETA:   0:08:11  28.1 KiB/s\nDownloading:   0% [                                ] ETA:   0:07:16  31.6 KiB/s\nDownloading:   0% [                                ] ETA:   0:06:41  34.2 KiB/s\nDownloading:   0% [                                ] ETA:   0:06:27  35.5 KiB/s\nDownloading:   1% [                                ] ETA:   0:06:10  37.1 KiB/s\nDownloading:   1% [                                ] ETA:   0:06:17  36.3 KiB/s\nDownloading:   1% [                                ] ETA:   0:06:14  36.5 KiB/s\nDownloading:   1% [                                ] ETA:   0:06:05  37.5 KiB/s\nDownloading:   1% [                                ] ETA:   0:06:03  37.6 KiB/s\nDownloading:   1% [                                ] ETA:   0:05:45  39.5 KiB/s\nDownloading:   1% [                                ] ETA:   0:05:34  40.8 KiB/s\nDownloading:   1% [                                ] ETA:   0:05:24  42.0 KiB/s\nDownloading:   1% [                                ] ETA:   0:05:17  42.9 KiB/s\nDownloading:   1% [                                ] ETA:   0:05:13  43.3 KiB/s\nDownloading:   2% [                                ] ETA:   0:05:00  45.2 KiB/s\nDownloading:   2% [                                ] ETA:   0:05:02  44.9 KiB/s\nDownloading:   2% [                                ] ETA:   0:04:52  46.3 KiB/s\nDownloading:   2% [                                ] ETA:   0:04:53  46.2 KiB/s\nDownloading:   2% [                                ] ETA:   0:04:44  47.6 KiB/s\nDownloading:   2% [                                ] ETA:   0:04:43  47.8 KiB/s\nDownloading:   2% [                                ] ETA:   0:04:35  49.1 KiB/s\nDownloading:   2% [                                ] ETA:   0:04:28  50.2 KiB/s\nDownloading:   2% [                                ] ETA:   0:04:29  50.2 KiB/s\nDownloading:   2% [                                ] ETA:   0:04:20  51.7 KiB/s\nDownloading:   2% [                                ] ETA:   0:04:13  53.0 KiB/s\nDownloading:   3% [                                ] ETA:   0:04:07  54.2 KiB/s\nDownloading:   3% [#                               ] ETA:   0:03:57  56.4 KiB/s\nDownloading:   3% [#                               ] ETA:   0:03:52  57.5 KiB/s\nDownloading:   3% [#                               ] ETA:   0:03:43  59.6 KiB/s\nDownloading:   3% [#                               ] ETA:   0:03:36  61.6 KiB/s\nDownloading:   3% [#                               ] ETA:   0:03:36  61.6 KiB/s\nDownloading:   4% [#                               ] ETA:   0:03:26  64.3 KiB/s\nDownloading:   4% [#                               ] ETA:   0:03:23  65.2 KiB/s\nDownloading:   4% [#                               ] ETA:   0:03:17  67.1 KiB/s\nDownloading:   4% [#                               ] ETA:   0:03:16  67.2 KiB/s\nDownloading:   4% [#                               ] ETA:   0:03:08  70.0 KiB/s\nDownloading:   5% [#                               ] ETA:   0:02:59  73.4 KiB/s\nDownloading:   5% [#                               ] ETA:   0:02:59  73.3 KiB/s\nDownloading:   5% [#                               ] ETA:   0:02:49  77.2 KiB/s\nDownloading:   5% [#                               ] ETA:   0:02:49  77.2 KiB/s\nDownloading:   5% [#                               ] ETA:   0:02:39  81.5 KiB/s\nDownloading:   6% [#                               ] ETA:   0:02:39  81.6 KiB/s\nDownloading:   6% [##                              ] ETA:   0:02:31  85.8 KiB/s\nDownloading:   6% [##                              ] ETA:   0:02:30  86.2 KiB/s\nDownloading:   6% [##                              ] ETA:   0:02:22  90.5 KiB/s\nDownloading:   7% [##                              ] ETA:   0:02:21  91.0 KiB/s\nDownloading:   7% [##                              ] ETA:   0:02:14  95.7 KiB/s\nDownloading:   7% [##                              ] ETA:   0:02:13  96.2 KiB/s\nDownloading:   7% [##                              ] ETA:   0:02:06 100.8 KiB/s\nDownloading:   8% [##                              ] ETA:   0:02:05 101.4 KiB/s\nDownloading:   8% [##                              ] ETA:   0:01:59 106.1 KiB/s\nDownloading:   8% [##                              ] ETA:   0:01:58 106.8 KiB/s\nDownloading:   9% [##                              ] ETA:   0:01:53 111.3 KiB/s\nDownloading:   9% [##                              ] ETA:   0:01:52 111.4 KiB/s\nDownloading:   9% [###                             ] ETA:   0:01:46 117.3 KiB/s\nDownloading:  10% [###                             ] ETA:   0:01:45 117.8 KiB/s\nDownloading:  10% [###                             ] ETA:   0:01:39 124.0 KiB/s\nDownloading:  10% [###                             ] ETA:   0:01:38 124.9 KiB/s\nDownloading:  11% [###                             ] ETA:   0:01:33 131.3 KiB/s\nDownloading:  11% [###                             ] ETA:   0:01:32 131.9 KiB/s\nDownloading:  12% [###                             ] ETA:   0:01:27 139.0 KiB/s\nDownloading:  12% [####                            ] ETA:   0:01:26 139.7 KiB/s\nDownloading:  13% [####                            ] ETA:   0:01:21 146.7 KiB/s\nDownloading:  13% [####                            ] ETA:   0:01:18 152.7 KiB/s\nDownloading:  14% [####                            ] ETA:   0:01:16 154.5 KiB/s\nDownloading:  15% [####                            ] ETA:   0:01:11 163.5 KiB/s\nDownloading:  15% [####                            ] ETA:   0:01:12 162.6 KiB/s\nDownloading:  16% [#####                           ] ETA:   0:01:07 170.8 KiB/s\nDownloading:  17% [#####                           ] ETA:   0:01:03 180.1 KiB/s\nDownloading:  18% [######                          ] ETA:   0:00:59 189.5 KiB/s\nDownloading:  19% [######                          ] ETA:   0:00:58 192.1 KiB/s\nDownloading:  20% [######                          ] ETA:   0:00:55 198.7 KiB/s\nDownloading:  20% [######                          ] ETA:   0:00:55 199.5 KiB/s\nDownloading:  21% [######                          ] ETA:   0:00:52 207.9 KiB/s\nDownloading:  21% [######                          ] ETA:   0:00:52 208.0 KiB/s\nDownloading:  22% [#######                         ] ETA:   0:00:48 218.6 KiB/s\nDownloading:  22% [#######                         ] ETA:   0:00:49 215.6 KiB/s\nDownloading:  24% [#######                         ] ETA:   0:00:46 224.9 KiB/s\nDownloading:  25% [########                        ] ETA:   0:00:44 233.9 KiB/s\nDownloading:  26% [########                        ] ETA:   0:00:41 242.9 KiB/s\nDownloading:  28% [#########                       ] ETA:   0:00:39 250.9 KiB/s\nDownloading:  29% [#########                       ] ETA:   0:00:37 259.9 KiB/s\nDownloading:  31% [#########                       ] ETA:   0:00:35 268.5 KiB/s\nDownloading:  32% [##########                      ] ETA:   0:00:33 277.3 KiB/s\nDownloading:  34% [##########                      ] ETA:   0:00:31 286.4 KiB/s\nDownloading:  35% [###########                     ] ETA:   0:00:30 295.8 KiB/s\nDownloading:  35% [###########                     ] ETA:   0:00:30 295.4 KiB/s\nDownloading:  36% [###########                     ] ETA:   0:00:29 298.8 KiB/s\nDownloading:  37% [############                    ] ETA:   0:00:28 305.8 KiB/s\nDownloading:  38% [############                    ] ETA:   0:00:27 308.5 KiB/s\nDownloading:  39% [############                    ] ETA:   0:00:26 315.9 KiB/s\nDownloading:  39% [############                    ] ETA:   0:00:26 318.1 KiB/s\nDownloading:  41% [#############                   ] ETA:   0:00:25 325.2 KiB/s\nDownloading:  41% [#############                   ] ETA:   0:00:24 328.1 KiB/s\nDownloading:  42% [#############                   ] ETA:   0:00:23 333.2 KiB/s\nDownloading:  43% [#############                   ] ETA:   0:00:23 336.6 KiB/s\nDownloading:  45% [##############                  ] ETA:   0:00:21 347.1 KiB/s\nDownloading:  46% [##############                  ] ETA:   0:00:20 355.8 KiB/s\nDownloading:  47% [###############                 ] ETA:   0:00:20 357.9 KiB/s\nDownloading:  49% [###############                 ] ETA:   0:00:18 370.3 KiB/s\nDownloading:  49% [###############                 ] ETA:   0:00:18 369.1 KiB/s\nDownloading:  51% [################                ] ETA:   0:00:17 380.5 KiB/s\nDownloading:  53% [#################               ] ETA:   0:00:16 389.4 KiB/s\nDownloading:  53% [#################               ] ETA:   0:00:16 392.2 KiB/s\nDownloading:  55% [#################               ] ETA:   0:00:15 403.1 KiB/s\nDownloading:  56% [#################               ] ETA:   0:00:15 403.9 KiB/s\nDownloading:  56% [##################              ] ETA:   0:00:14 408.3 KiB/s\nDownloading:  58% [##################              ] ETA:   0:00:13 416.2 KiB/s\nDownloading:  59% [###################             ] ETA:   0:00:13 421.4 KiB/s\nDownloading:  61% [###################             ] ETA:   0:00:12 429.2 KiB/s\nDownloading:  62% [###################             ] ETA:   0:00:12 434.6 KiB/s\nDownloading:  63% [####################            ] ETA:   0:00:11 442.5 KiB/s\nDownloading:  64% [####################            ] ETA:   0:00:10 447.5 KiB/s\nDownloading:  66% [#####################           ] ETA:   0:00:10 456.3 KiB/s\nDownloading:  67% [#####################           ] ETA:   0:00:09 459.6 KiB/s\nDownloading:  69% [######################          ] ETA:   0:00:09 469.8 KiB/s\nDownloading:  69% [######################          ] ETA:   0:00:08 471.9 KiB/s\nDownloading:  71% [#######################         ] ETA:   0:00:08 484.1 KiB/s\nDownloading:  72% [#######################         ] ETA:   0:00:07 484.3 KiB/s\nDownloading:  74% [#######################         ] ETA:   0:00:07 499.3 KiB/s\nDownloading:  75% [########################        ] ETA:   0:00:06 498.8 KiB/s\nDownloading:  75% [########################        ] ETA:   0:00:06 503.6 KiB/s\nDownloading:  78% [#########################       ] ETA:   0:00:05 514.8 KiB/s\nDownloading:  78% [#########################       ] ETA:   0:00:05 515.7 KiB/s\nDownloading:  79% [#########################       ] ETA:   0:00:05 522.2 KiB/s\nDownloading:  81% [##########################      ] ETA:   0:00:04 529.8 KiB/s\nDownloading:  83% [##########################      ] ETA:   0:00:04 541.1 KiB/s\nDownloading:  84% [###########################     ] ETA:   0:00:03 547.3 KiB/s\nDownloading:  86% [###########################     ] ETA:   0:00:03 552.2 KiB/s\nDownloading:  87% [###########################     ] ETA:   0:00:03 559.2 KiB/s\nDownloading:  88% [############################    ] ETA:   0:00:02 563.3 KiB/s\nDownloading:  89% [############################    ] ETA:   0:00:02 570.2 KiB/s\nDownloading:  92% [#############################   ] ETA:   0:00:01 580.3 KiB/s\nDownloading:  93% [#############################   ] ETA:   0:00:01 588.3 KiB/s\nDownloading:  95% [##############################  ] ETA:   0:00:00 598.3 KiB/s\nDownloading:  97% [############################### ] ETA:   0:00:00 604.1 KiB/s\nDownloading:  99% [############################### ] ETA:   0:00:00 616.4 KiB/s\n\n\n\n# Read column names from another file\ncolumn_names = pd.read_csv('HEADERS.txt',\n                           header=None,\n                           delim_whitespace=True,\n                           )\n# Read CSV file using column names from another file\ndf = pd.read_csv(\"CRNS0101-05-2022-TX_Austin_33_NW.txt\",  # file to read\n                 delim_whitespace=True,  # use (any number of) white spaces as delimiter between columns\n                 names=column_names.iloc[1],  # column names from row i=1 of \"column_names\"\n                 na_values=[-99, -9999, -99999],  # substitute these values by NaN\n                 )\n# make integer column LST_DATE as string\ndf['LST_DATE'] = df['LST_DATE'].astype(str)#.apply(lambda x: f'{x:0>4}')\n# make integer column LST_DATE as string\n# pad numbers with 0 from the left, such that 15 becomes 0015\ndf['LST_TIME'] = df['LST_TIME'].apply(lambda x: f'{x:0>4}')\n# combine both DATE and TIME \ndf['datetime'] = pd.to_datetime(df['LST_DATE'] + df['LST_TIME'], format='%Y%m%d%H%M')\ndf = df.set_index('datetime')\ndf\n\n\n\n\n\n  \n    \n      \n      WBANNO\n      UTC_DATE\n      UTC_TIME\n      LST_DATE\n      LST_TIME\n      CRX_VN\n      LONGITUDE\n      LATITUDE\n      AIR_TEMPERATURE\n      PRECIPITATION\n      ...\n      ST_TYPE\n      ST_FLAG\n      RELATIVE_HUMIDITY\n      RH_FLAG\n      SOIL_MOISTURE_5\n      SOIL_TEMPERATURE_5\n      WETNESS\n      WET_FLAG\n      WIND_1_5\n      WIND_FLAG\n    \n    \n      datetime\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2021-12-31 18:05:00\n      23907\n      20220101\n      5\n      20211231\n      1805\n      2.623\n      -98.08\n      30.62\n      23.3\n      0.0\n      ...\n      C\n      0\n      66.0\n      0\n      NaN\n      NaN\n      964.0\n      0\n      1.48\n      0\n    \n    \n      2021-12-31 18:10:00\n      23907\n      20220101\n      10\n      20211231\n      1810\n      2.623\n      -98.08\n      30.62\n      23.3\n      0.0\n      ...\n      C\n      0\n      66.0\n      0\n      NaN\n      NaN\n      964.0\n      0\n      1.48\n      0\n    \n    \n      2021-12-31 18:15:00\n      23907\n      20220101\n      15\n      20211231\n      1815\n      2.623\n      -98.08\n      30.62\n      23.2\n      0.0\n      ...\n      C\n      0\n      66.0\n      0\n      NaN\n      NaN\n      964.0\n      0\n      1.01\n      0\n    \n    \n      2021-12-31 18:20:00\n      23907\n      20220101\n      20\n      20211231\n      1820\n      2.623\n      -98.08\n      30.62\n      23.1\n      0.0\n      ...\n      C\n      0\n      66.0\n      0\n      NaN\n      NaN\n      964.0\n      0\n      0.51\n      0\n    \n    \n      2021-12-31 18:25:00\n      23907\n      20220101\n      25\n      20211231\n      1825\n      2.623\n      -98.08\n      30.62\n      22.7\n      0.0\n      ...\n      C\n      0\n      68.0\n      0\n      NaN\n      NaN\n      964.0\n      0\n      0.67\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2022-12-31 17:40:00\n      23907\n      20221231\n      2340\n      20221231\n      1740\n      2.623\n      -98.08\n      30.62\n      20.8\n      0.0\n      ...\n      C\n      0\n      37.0\n      0\n      NaN\n      NaN\n      964.0\n      0\n      2.92\n      0\n    \n    \n      2022-12-31 17:45:00\n      23907\n      20221231\n      2345\n      20221231\n      1745\n      2.623\n      -98.08\n      30.62\n      20.7\n      0.0\n      ...\n      C\n      0\n      37.0\n      0\n      NaN\n      NaN\n      963.0\n      0\n      2.94\n      0\n    \n    \n      2022-12-31 17:50:00\n      23907\n      20221231\n      2350\n      20221231\n      1750\n      2.623\n      -98.08\n      30.62\n      20.6\n      0.0\n      ...\n      C\n      0\n      37.0\n      0\n      NaN\n      NaN\n      962.0\n      0\n      3.61\n      0\n    \n    \n      2022-12-31 17:55:00\n      23907\n      20221231\n      2355\n      20221231\n      1755\n      2.623\n      -98.08\n      30.62\n      20.4\n      0.0\n      ...\n      C\n      0\n      38.0\n      0\n      NaN\n      NaN\n      962.0\n      0\n      3.03\n      0\n    \n    \n      2022-12-31 18:00:00\n      23907\n      20230101\n      0\n      20221231\n      1800\n      2.623\n      -98.08\n      30.62\n      20.1\n      0.0\n      ...\n      C\n      0\n      39.0\n      0\n      NaN\n      NaN\n      961.0\n      0\n      2.32\n      0\n    \n  \n\n105120 rows Ã— 23 columns\n\n\n\nThe provided data is not the same as what is provided by the IMS.\n\nNow we donâ€™t have air pressure values, so we need to provide elevation.\nWe do have \\(R_n\\) (net radiation), so there is no need to provide latitude.\n\n\ntmean = df[\"AIR_TEMPERATURE\"]\nwind = df[\"WIND_1_5\"]\nrh = df[\"RELATIVE_HUMIDITY\"]\nrn = df[\"SOLAR_RADIATION\"] / 1e6\nelevation = 358\npenm2 = pyet.combination.penman(tmean=tmean,\n                                wind=wind,\n                                elevation=elevation,\n                                rh=rh,\n                                rn=rn,\n                                )\n\n\nfig, ax = plt.subplots(1)\nax.plot(penm2, label=\"penman\")\n# ax.legend()\nplt.gcf().autofmt_xdate()  # makes slated dates\nax.set_ylabel(\"ET (mm/day)\")\n\nText(0, 0.5, 'ET (mm/day)')"
  },
  {
    "objectID": "infiltration/infiltration-lecture.html#definitions",
    "href": "infiltration/infiltration-lecture.html#definitions",
    "title": "11Â  Infiltration",
    "section": "11.1 Definitions",
    "text": "11.1 Definitions\nHillel, Introduction to Environmental Soil Physics, figure 14.6 \nDingman, figure 8.13 \nDingman, figure 8.14 \nHillel, Introduction to Soil Physics, figure 12.3 \nSource: Dingman, â€œPhysical Hydrologyâ€, 3rd edition, page 355\n\nThe water-input rate, \\(w(t)\\) [L T\\(^{-1}\\)], is the rate at which water arrives at the surface due to rain, snowmelt, or irrigation. A water-input event begins at time \\(t=0\\) and ends at \\(t=T_w\\).\nThe infiltration rate, \\(f(t)\\) [L T\\(^{-1}\\)], is the rate at which water enters the soil from the surface.\nThe infiltrability, also called infiltration capacity, \\(f^*(t)\\) [L T\\(^{-1}\\)], is the maximum rate at which infiltration could occur at any time; note that this changes during the infiltration event.\nThe depth of ponding, \\(H(t)\\) [L], is the depth of water standing on the surface.\n\nSource: Ward & Trimble, â€œEnvironmantal Hydrologyâ€, 2nd edition, page 63, 64\nInfiltration capacity of absorbent paper is low, there is much runoff \nInfiltration capacity of sponge is high, there is little runoff \nInfiltration capacity of the sponge is limited by the overlying layer with low permeability \nInfiltration capacity of the sponge is limited by the underlying layer \n\nyoutube: https://youtu.be/ego2FkuQwxc\n\nWard & Trimble, â€œEnvironmantal Hydrologyâ€, 2nd edition, page 65"
  },
  {
    "objectID": "infiltration/infiltration-lecture.html#darcy",
    "href": "infiltration/infiltration-lecture.html#darcy",
    "title": "11Â  Infiltration",
    "section": "11.2 Darcy",
    "text": "11.2 Darcy\nDarcyâ€™s equation for vertical flow \\[\nq = -K \\frac{\\partial H_\\text{total}}{\\partial z}\n\\]\nwhere the total head \\(H_\\text{total}=-H_\\text{suction}-z_\\text{depth}\\), and * \\(H_\\text{suction}\\) is the suction head (negative pressure head) * \\(z_\\text{depth}\\) is the depth, points downward.\nSubstituting:\n\\[\nq = K \\frac{\\partial H_\\text{suction}}{\\partial z} + K\n\\]\nSubstituting the above into the continuity equation\n\\[\n\\frac{\\partial \\theta}{\\partial t} = \\frac{\\partial q}{\\partial z}\n\\]\nyields the Richards equation."
  },
  {
    "objectID": "infiltration/infiltration-lecture.html#richards",
    "href": "infiltration/infiltration-lecture.html#richards",
    "title": "11Â  Infiltration",
    "section": "11.3 Richards",
    "text": "11.3 Richards\nRichards equation:\n\\[\n\\frac{\\partial \\theta}{\\partial t} = \\frac{\\partial}{\\partial z}\n\\left[\nK(\\theta)\n\\frac{\\partial H_\\text{total}}{\\partial z}\n\\right]\n\\]\nSubstituting \\(H_\\text{total}=-H_\\text{suction}-z_\\text{depth}\\) yields:\n\\[\n\\frac{\\partial \\theta}{\\partial t} = \\frac{\\partial}{\\partial z}\n\\left[\nK(\\theta)\n\\left(\n\\frac{\\partial(-H_\\text{suction} - z)}{\\partial z}\n\\right)\n\\right]\n\\]\n\\[\n\\frac{\\partial \\theta}{\\partial t} =\n-\n\\underbrace{\n\\frac{\\partial}{\\partial z}\n\\left(\nK(\\theta)\n\\frac{\\partial H_\\text{suction}}{\\partial z}\n\\right)\n}\n_{\\text{matric}}\n-\n\\underbrace{\n\\frac{\\partial K(\\theta)}{\\partial z}\n}\n_{\\text{gravitational}}\n\\]\n\n11.3.1 short times\nAs the water starts to enter the relatively dry soil, the pressure differences in the water at the surface and in the soil are quite large and, as a result, the second term on the right is practically negligible compared to the first one.\n\\[\n\\frac{\\partial \\theta}{\\partial t} =\n-\n\\frac{\\partial}{\\partial z}\n\\left(\nK(\\theta)\n\\frac{\\partial H}{\\partial z}\n\\right)\n\\]\n\n\n11.3.2 long times\nAs illustrated in the figure below (Davidson et al., 1963), after longer times of infiltration, the water content profile near the surface gradually becomes more uniform and it eventually assumes the satiation value, or \\(\\theta\\rightarrow \\theta_0\\); similarly, the pressure in the upper layers of the soil becomes gradually atmospheric, or \\(H \\rightarrow 0\\). Hence, their vertical gradients \n\\[\n\\frac{\\partial\\theta}{\\partial z} \\text{ and } \\frac{\\partial H_\\text{suction}}{\\partial z} \\longrightarrow 0\n\\]\nFrom Darcyâ€™s equation we have that\n\\[\nq = K(\\theta_0) = K_\\text{sat}\n\\]\n\n\n\n11.3.3 Rainfall infiltration\nInfiltration rate is equal to rainfal rate, at least at first. If rainfall rate \\(w\\) is lower than \\(K_\\text{sat}\\), than everything enters the soil, i.e., \\(f=K_\\text{sat}\\). However, if \\(w>K_\\text{sat}\\), water content \\(\\theta\\) will increase at the surface, until it reaches \\(\\theta_0\\), and at that moment, called ponding time \\(t_p\\), water will begin to accumulate at the surface.\nHillel, Introduction to Environmental Soil Physics, figure 12.1 \nHillel, Introduction to Environmental Soil Physics, figure 12.2"
  },
  {
    "objectID": "infiltration/infiltration-lecture.html#horton-equation",
    "href": "infiltration/infiltration-lecture.html#horton-equation",
    "title": "11Â  Infiltration",
    "section": "11.4 Horton equation",
    "text": "11.4 Horton equation\nOne of the most widely used models, developed by R.E. Horton (1939), considered to be the father of modern hydrology.\n\\[\nf = f_c+(f_0-f_c)e^{-\\beta t}\n\\]\n\n\\(f\\): infiltration rate\n\\(f_c\\): infiltration capacity at large \\(t\\)\n\\(f_0\\): initial infiltration capacity\n\\(\\beta\\): best fit empirical parameter\n\nAdvantages\n\nSimple equation\nUsually gives good fit to measured data because it is dependent on three parameters\n\nDisadvantages\n\nThis method has no physical significance, it is not based on any water transport mechanism\nDoes not describe infiltration prior to ponding"
  },
  {
    "objectID": "infiltration/infiltration-lecture.html#green-ampt",
    "href": "infiltration/infiltration-lecture.html#green-ampt",
    "title": "11Â  Infiltration",
    "section": "11.5 Green & Ampt",
    "text": "11.5 Green & Ampt\nDingman, figure 8.11 \nAssumptions: * homogeneous soil, infinite depth (no water table) * horizontal surface * constant water head equal to zero is maintained at the surface * uniform water content prior to wetting, \\(\\theta(t=0,z)=\\theta_0\\) * moving front is characterized by a constant matric suction, \\(\\psi_f\\)\nSource: Dingman, page 370\nThis equation was developed under the scenario of constant rainfall or irrigation on an initially dry soil as a sharp wetting front (such as piston flow). Water penetrates a dry soil with a certain initial moisture content, and wets the layer to a saturated moisture content as it traverses deeper. The connection between soil moisture and infiltration rate is modeled in the Green-Ampt equation:\n\\[\nf(t) = K_\\text{sat}\n\\left[\n1 + \\frac{|\\psi_f|\\cdot \\left( \\phi - \\theta_0 \\right)}{F(t)}\n\\right]\n\\]\n\n\\(f(t)\\): infiltration rate\n\\(F(t)\\): cumulative infiltration rate, \\(F=\\int\\! f \\text{ d}t\\)\n\\(\\psi_f\\): effective wetting-front suction\n\\(\\phi\\): soil porosity\n\\(\\theta_0\\): initial soil water content\n\nThe same equation can be simply be rewritten as\n\\[f = \\frac{A}{F} + B\\]\nwhere * \\(A = K_\\text{sat}\\cdot|\\psi_f|\\cdot \\left( \\phi - \\theta_0 \\right)\\) * \\(B= K_\\text{sat}\\)\nThe porosity \\(\\phi\\) and the saturated hydraulic conductivity \\(K_\\text{sat}\\) can be estimated from the soil texture. The wetting-front suction \\(\\psi_f\\) can be estimated using the Brooks-Corey parameters: \n\\[\n|\\psi_f| = \\frac{2b+3}{2b+6}\\cdot |\\psi_{ae}|,\n\\]\nwhere \\(\\psi_{ae}\\) is the air-entry pressure head. Values for the parameters above can be found in this table:"
  },
  {
    "objectID": "infiltration/infiltration-lecture.html#best-fit-least-squares-method",
    "href": "infiltration/infiltration-lecture.html#best-fit-least-squares-method",
    "title": "11Â  Infiltration",
    "section": "11.6 Best Fit, Least Squares Method",
    "text": "11.6 Best Fit, Least Squares Method"
  },
  {
    "objectID": "infiltration/infiltration-exercises.html#tasks",
    "href": "infiltration/infiltration-exercises.html#tasks",
    "title": "12Â  Exercises",
    "section": "12.1 Tasks",
    "text": "12.1 Tasks\n\nGoogle the following: web plot digitizer\nLoad image â€œnassif-16percent-slope.pngâ€ (see below)\nCreate four csv files, one for each data set. Call them whatever you want. Legend: white circle = 312 mm/h, triangle = 234 mm/h, x = 156 mm/h, black circle = 78 mm/h.\n\nThe image is the second panel of Fig. 8, from > Nassif, S. H., and E. M. Wilson, 1975, â€œTHE INFLUENCE OF SLOPE AND RAIN INTENSITY ON RUNOFF AND INFILTRATIONâ€, Hydrological Sciences Journal. download here\n\nImport relevant packages\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"ticks\", font_scale=1.5)\nfrom scipy.optimize import curve_fit\nimport matplotlib.patches as patches\n\nLoad all four files you created. Use numpyâ€™s function loadtxt. Make sure that the first point in each table corresponds to the appropriate rainfall rate. You can normalize the data if it is not.\n\nd1 = np.loadtxt(\"input_rate_078mm_per_h_16percent_slope.csv\", delimiter=',')\nd2 = np.loadtxt(\"input_rate_156mm_per_h_16percent_slope.csv\", delimiter=',')\nd3 = np.loadtxt(\"input_rate_234mm_per_h_16percent_slope.csv\", delimiter=',')\nd4 = np.loadtxt(\"input_rate_312mm_per_h_16percent_slope.csv\", delimiter=',')\nd1[:,1] = 78  * d1[:,1] / d1[:,1].max()\nd2[:,1] = 156 * d2[:,1] / d2[:,1].max()\nd3[:,1] = 234 * d3[:,1] / d3[:,1].max()\nd4[:,1] = 312 * d4[:,1] / d4[:,1].max()\n\nReproduce the original figure, make it look good, something like this:\n\n\nfig, ax = plt.subplots(figsize=(10,7))\nax.plot(d4[:,0], d4[:,1], 'o', markerfacecolor=\"None\", label=r\"water input = 312 mm h$^{-1}$\")\nax.plot(d3[:,0], d3[:,1], '^', label=r\"water input = 234 mm h$^{-1}$\")\nax.plot(d2[:,0], d2[:,1], 'x', label=r\"water input = 156 mm h$^{-1}$\")\nax.plot(d1[:,0], d1[:,1], 'o', label=r\"water input = 78 mm h$^{-1}$\")\nax.set(xlabel=\"Time (min)\",\n       ylabel=r\"Infiltration rate (mm h$^{-1}$)\")\nax.legend(loc=\"upper right\");"
  },
  {
    "objectID": "infiltration/infiltration-exercises.html#hortons-equation",
    "href": "infiltration/infiltration-exercises.html#hortons-equation",
    "title": "12Â  Exercises",
    "section": "12.2 Hortonâ€™s equation",
    "text": "12.2 Hortonâ€™s equation\n\\[\nf = f_c+(f_0-f_c)e^{-\\beta t}\n\\]\n\n\\(f\\): infiltration rate\n\\(f_c\\): infiltration capacity at large \\(t\\)\n\\(f_0\\): initial infiltration capacity\n\\(\\beta\\): best fit empirical parameter\n\nWrite a function called horton, that receives time t and the three parameters, and returns the right-hand side of the equation above. Plot one of the data sets, together with a guess of the parameters that should roughly fit the data.\n\ndef horton(t, fc, f0, beta):\n    return fc + (f0 - fc)*np.exp(-beta*t)\n\nfig, ax = plt.subplots(figsize=(10,7))\nt = d1[:,0]\nt = t - t[0]\nf = d1[:,1]\nax.plot(t, f, 'o', label=\"data\")\nax.plot(t, horton(t, 35, 80, 0.5), '-', label=\"horton\")\nax.set(xlabel=\"time (min)\",\n       ylabel=\"infiltration rate (mm/h)\")\nax.legend(loc=\"upper right\");\n\n\n\n\nFind the best fit for the parameters \\(f_c, f_0, \\beta\\). Calculate the \\(R^2\\) for each data set.\nFor the best fit, use scipyâ€™s curve_fit. Write a function to compute the R-squared of your fit.\n\ndef horton(t, fc, f0, beta):\n    return fc + (f0 - fc)*np.exp(-beta*t)\n\ndef best_fit(data):\n    t = data[:,0]\n    t0 = t[0]\n    t = t - t0\n    f = data[:,1]\n    # best fit\n    popt, pcov = curve_fit(f=horton,             # model function\n                           xdata=t,              # x data\n                           ydata=f,              # y data\n                           p0=(130, 800, 0.5),   # initial guess of the parameters\n                          )\n    return [popt, pcov]\n\ndef calculate_r_squared(data, popt):\n    t = data[:,0]\n    t = t - t[0]\n    f = data[:,1]\n    # Calculate residuals\n    residuals = f - horton(t, *popt)\n    # You can get the residual sum of squares (ss_res) with\n    ss_res = np.sum(residuals**2)\n    # You can get the total sum of squares (ss_tot) with\n    ss_tot = np.sum((f - np.mean(f))**2)\n    # And finally, the r_squared-value with,\n    r_squared = 1 - (ss_res / ss_tot)\n    return r_squared\n\ndef plot_best_fit(data, axis, marker, markercolor):\n    # calculate best fit parameters\n    popt, pcov = best_fit(data)\n    t = data[:,0]\n    f = data[:,1]\n    # plot data points\n    ax.plot(t, f, marker, markerfacecolor=markercolor, markeredgecolor=\"black\")\n    # plot best fit line\n    r_squared = calculate_r_squared(data, popt)\n    labeltext = r\"$f_c=$ {:.2f}, $f_0=$ {:.2f}, $\\beta=$ {:.2f}, $R^2=$ {:.2f}\".format(popt[0],popt[1],popt[2], r_squared)\n    ax.plot(t, horton(t-t[0], *popt), color=markercolor, label=labeltext)    \n\nfig, ax = plt.subplots(figsize=(10,7))\nplot_best_fit(d1, ax, 'o', \"tab:red\")\nplot_best_fit(d2, ax, 'x', \"tab:blue\")\nplot_best_fit(d3, ax, '^', \"tab:orange\")\nplot_best_fit(d4, ax, 'd', \"tab:green\")\nax.set(xlabel=\"time (min)\",\n       ylabel=\"infiltration rate (mm/h)\")\nax.legend();\n\n\n\n\nMake a graph of the infiltration rate and of the runoff, as a function of time. Use any of the four data sets you have.\n\nfig, ax = plt.subplots(figsize=(10,7))\ndata = d4\nt = data[:, 0]\nf = data[:, 1]\nt = np.concatenate([ [0], t])\nf = np.concatenate([ [f[0]], f])\nrunoff = f[0] - f\nax.plot(t, f*0 + f[0], ls=\"--\", color=\"black\", label=\"rainfall\")\nax.plot(t, f, color=\"tab:blue\", lw=3, label=r\"infiltration\")\nax.plot(t, runoff, color=\"tab:orange\", lw=3, label=r\"runoff\")\nax.set(xlabel=\"Time (min)\",\n       ylabel=r\"Rate (mm h$^{-1}$)\")\nax.legend(loc=\"lower right\");"
  },
  {
    "objectID": "infiltration/infiltration-exercises.html#green-ampt",
    "href": "infiltration/infiltration-exercises.html#green-ampt",
    "title": "12Â  Exercises",
    "section": "12.3 Green & Ampt",
    "text": "12.3 Green & Ampt\n\\[f = \\frac{A}{F} + B\\]\nwhere * \\(A = K_\\text{sat}\\cdot|\\psi_f|\\cdot \\left( \\phi - \\theta_0 \\right)\\) * \\(B= K_\\text{sat}\\)\nWrite a function that calculates the cumulative of the infiltration rate.\n\\[\nF(t) = \\int_0^t f(t) \\text{ d}t\n\\]\nUse numpyâ€™s trapz function, that implements the â€œtrapezoidal ruleâ€\n\n\ndef cumulative_F(t, f):\n    F = np.array([0])\n    t = t/60 # convert minute to hour\n    for i in np.arange(2,len(t)+1):\n        area = np.trapz(f[:i], t[:i])\n        F = np.concatenate([F, [area]])\n    return F\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,7))\nt, f = d1[:,0], d1[:,1]\nF = cumulative_F(t, f)\nax1.plot(t, f, label=\"f, rate\")\nax2.plot(t, F, label=\"F, cumulative\")\nax1.set(xlabel=\"t (min)\",\n        ylabel=\"f (mm/h)\")\nax2.set(xlabel=\"t (min)\",\n        ylabel=\"F (mm)\")\nax2.yaxis.set_label_position(\"right\")\n\n\n\n\nPlot \\(f\\) as a function of \\(F\\). Try to guess \\(A\\) and \\(B\\) that give reasonable results.\n\nfig, ax = plt.subplots(figsize=(10,7))\nt, f = d1[:,0], d1[:,1]\nF = cumulative_F(t, f)\nax.plot(F, f)\nA=50; B=30;\nax.plot(F, A/F + B, 'o')\nax.set(xlabel=\"F\",\n       ylabel=\"f\")\n\n/Users/yairmau/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in true_divide\n  \n\n\n[Text(0.5, 0, 'F'), Text(0, 0.5, 'f')]\n\n\n\n\n\nUse the curve_fit to find the optimal values for \\(A\\) and \\(B\\).\n\ndef G_and_A(F, A, B):\n    return A/F + B\n\npopt, pcov = curve_fit(f=G_and_A,     # model function\n                       xdata=F[1:],       # x data\n                       ydata=f[1:],       # y data\n                       p0=(50, 30),   # initial guess of the parameters\n                      )\n\n# popt, pcov = curve_fit(G_and_A, F[1:], f[1:], p0=(50, 30))  # p0 = initial guess\nprint(popt)\n\nfig, ax = plt.subplots(figsize=(10,7))\nax.plot(F, f)\nax.plot(F[1:], popt[0]/F[1:] + popt[1], 'o')\nax.set(xlabel=\"F\",\n       ylabel=\"f\")\n\n[24.12368526 36.34242813]\n\n\n[Text(0.5, 0, 'F'), Text(0, 0.5, 'f')]"
  },
  {
    "objectID": "infiltration/infiltration-exercises.html#homework",
    "href": "infiltration/infiltration-exercises.html#homework",
    "title": "12Â  Exercises",
    "section": "12.4 Homework",
    "text": "12.4 Homework\nGo to Soil Texture Calculator, estimate the texture of â€œstandard soilâ€ in Nassif & Wilson, 1975."
  },
  {
    "objectID": "streamflow/streamflow-lecture.html#watershed---××’×Ÿ-×”×™×§×•×•×ª",
    "href": "streamflow/streamflow-lecture.html#watershed---××’×Ÿ-×”×™×§×•×•×ª",
    "title": "13Â  Streamflow",
    "section": "13.1 Watershed - ××’×Ÿ ×”×™×§×•×•×ª",
    "text": "13.1 Watershed - ××’×Ÿ ×”×™×§×•×•×ª\n  \nWatershed response:\n\nThe volume of water appearing in the appar- ent response hydrograph for a given event is usually only a fraction (often a very small frac- tion) of the total input. The remainder of the water input ultimately leaves the watershed as: (1) evapotranspiration; (2) streamflow that oc- curs so long after the event that it cannot be associated with that event; or (3) ground-water outflow from the watershed.\nThe water identified as the response to a given event may originate on only a fraction of the watershed; this fraction is called the contrib- uting area.\nThe extent of the contributing area may vary from event to event and during an event.\nAt least some of the water identified as the re- sponse to a given event may be â€œold waterâ€ that entered the watershed in a previous event."
  },
  {
    "objectID": "streamflow/streamflow-lecture.html#base-flow-separation",
    "href": "streamflow/streamflow-lecture.html#base-flow-separation",
    "title": "13Â  Streamflow",
    "section": "13.2 base flow separation",
    "text": "13.2 base flow separation\n\n\n13.2.1 Base flow\nBase flow is the portion of streamflow that is presumed to have entered the watershed in previous events and to be derived from persistent, slowly varying sources. (Ground water is usually assumed to be the main, if not the only, such source.) ### Event flow Event flow (also called direct runoff, storm runoff, quick flow, or storm flow) is considered to be the direct response to a given water-input event.\n\n\n13.2.2 Total flow\nTotal flow rate at any instant \\(q(t)\\) is the sum of event-flow rate \\(q^*(t)\\) and base-flow rate \\(q_{BF}\\)(t):\n\\[\nq(t) = q^*(t) + q_{BF}(t)\n\\]\n\n\n13.2.3 Attention!\nGraphical flow separation techniques are heuristic and have no direct scientific basis."
  },
  {
    "objectID": "streamflow/streamflow-lecture.html#urbana-il",
    "href": "streamflow/streamflow-lecture.html#urbana-il",
    "title": "13Â  Streamflow",
    "section": "13.3 Urbana, IL",
    "text": "13.3 Urbana, IL\n\n\n13.3.1 hyetograph, hydrograph\n\n\n\n13.3.2 notation\n\n\n\n13.3.3 base flow separation\n\n\n\n13.3.4 effective precipitation = effective discharge\n\\[\nP^* = Q^*\n\\]\n \n\n\n13.3.5 time lags\n  \nIt is commonly assumed that \\(T_{LPC} \\simeq 0.60 \\cdot T_c\\), where \\(T_c\\) is the time of concentration, i.e., the time it takes water to travel from the hydraulically most distant part of the contributing area to the outlet.\n\nThe centroid is a weighted-average time, each time instant is multiplied by the amount of flow in that instant.\nTime of precipitation centroid:\n\\[\nt_{pc} = \\frac{\\displaystyle \\sum_{i=1}^n p_i^* \\cdot t_i}{P^*}\n\\]\nTime of streamflow centroid:\n\\[\nt_{qc} = \\frac{\\displaystyle \\sum_{i=1}^n q_i^* \\cdot t_i}{Q^*}\n\\]"
  },
  {
    "objectID": "streamflow/streamflow-exercises.html",
    "href": "streamflow/streamflow-exercises.html",
    "title": "14Â  Exercises",
    "section": "",
    "text": "Import relevant packages\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport seaborn as sns\nsns.set(style=\"ticks\", font_scale=1.5)\nfrom ipywidgets import *\n\nImport streamflow data from USGSâ€™s National Water Information System. We will be using data from Urbana, IL.\n\n# Drainage area: 4.78 square miles   \ndata_file = \"USGS 03337100 BONEYARD CREEK AT LINCOLN AVE AT URBANA, IL.dat\"\ndf_q_2020 = pd.read_csv(data_file,\n                        header=31,                      # no headers needed, we'll do that later\n                        delim_whitespace=True,            # blank spaces separate between columns\n                        na_values=[\"Bkw\"]  # substitute these values for missing (NaN) values\n                )\ndf_q_2020.columns = ['agency_cd', 'site_no','datetime','tz_cd','EDT','discharge','code']                       # rename df columns with headers columns\ndf_q_2020['date_and_time'] = df_q_2020['datetime'] + ' ' + df_q_2020['tz_cd'] # combine date+time into datetime\ndf_q_2020['date_and_time'] = pd.to_datetime(df_q_2020['date_and_time'])        # interpret datetime\ndf_q_2020 = df_q_2020.set_index('date_and_time')                          # make datetime the index\ndf_q_2020['discharge'] = df_q_2020['discharge'].astype(float)\ndf_q_2020['discharge'] = df_q_2020['discharge'] * 0.0283168 # convert cubic feet to m3\n\nfig, ax = plt.subplots(figsize=(10,7))\nax.plot(df_q_2020['discharge'], '-o')\nplt.gcf().autofmt_xdate()\nax.set(xlabel=\"date\",\n       ylabel=r\"discharge (m$^3$/5min)\");\n\n\n\n\nImport sub-hourly (5-min) rainfall data from NOAAâ€™s Climate Reference Network Data website\n\ndata_file = \"Champaign - IL.txt\"\ndf_p_2020 = pd.read_csv(data_file,\n                        header=None,                      # no headers needed, we'll do that later\n                        delim_whitespace=True,            # blank spaces separate between columns\n                        na_values=[\"-99.000\", \"-9999.0\"]  # substitute these values for missing (NaN) values\n                       )\nheaders = pd.read_csv(\"HEADERS_sub_hourly.txt\",    # load headers file\n                      header=1,                    # skip the first [0] line\n                      delim_whitespace=True\n                     )\ndf_p_2020.columns = headers.columns                       # rename df columns with headers columns\n# LST = local standard time\ndf_p_2020[\"LST_TIME\"] = [f\"{x:04d}\" for x in df_p_2020[\"LST_TIME\"]]  # time needs padding of zeros, then convert to string\ndf_p_2020['LST_DATE'] = df_p_2020['LST_DATE'].astype(str)            # convert date into string\ndf_p_2020['datetime'] = df_p_2020['LST_DATE'] + ' ' + df_p_2020['LST_TIME'] # combine date+time into datetime\ndf_p_2020['datetime'] = pd.to_datetime(df_p_2020['datetime'])        # interpret datetime\ndf_p_2020 = df_p_2020.set_index('datetime')                          # make datetime the index\n\nPlot rainfall and streamflow. Does this makes sense?\n\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,7))\nfig.subplots_adjust(hspace=0.05)\n\nstart = \"2020-10-18\"\nend = \"2020-10-25\"\nax1.plot(df_p_2020[start:end]['PRECIPITATION'])\nax2.plot(df_q_2020[start:end]['discharge'], color=\"tab:blue\", lw=2)\n\nax1.set(xticks=[],\n        ylabel=r\"precipitation (mm)\")\nax2.set(xlabel=\"date\",\n        ylabel=r\"discharge (m$^3$/5min)\")\n\nplt.gcf().autofmt_xdate()  # makes slated dates\n\n\n\n\nDefine smaller dataframes for \\(p(t)\\) and \\(q(t)\\), between the dates:\nstart = \"2020-10-20 14:00:00\"\nend = \"2020-10-21 04:00:00\"\nDonâ€™t forget to convert the units to SI!\nCalculate total rainfall \\(P^*\\) and total discharge \\(Q^*\\), in m\\(^3\\).\n\n# Drainage area: 4.78 square miles\narea = 4.78 / 0.00000038610  # squared miles to squared meters\nstart = \"2020-10-20 14:00:00\"\nend = \"2020-10-21 04:00:00\"\n\ndf_p = df_p_2020.loc[start:end]['PRECIPITATION'].to_frame()\ndf_p_mm = df_p_2020.loc[start:end]['PRECIPITATION'].to_frame()\ndf_q = df_q_2020.loc[start:end]['discharge'].to_frame()\n\ndf_p['PRECIPITATION'] = df_p['PRECIPITATION'].values * area / 1000  # mm to m3 in the whole watershed\ndf_p['PRECIPITATION'] = df_p['PRECIPITATION'] / 60 / 5 # convert m3 per 5 min to m3/s\n\nP = df_p['PRECIPITATION'].sum() * 60 * 5\nQ = df_q['discharge'].sum() * 60 * 5\n\nprint(\"total precipitation during event: Pstar = {:.1e} m3\".format(P.sum()))\nprint(\"total streamflow during event: Qstar = {:.1e} m3\".format(Q.sum()))\n\ntotal precipitation during event: Pstar = 2.6e+05 m3\ntotal streamflow during event: Qstar = 5.2e+04 m3\n\n\nMake another graph of \\(p(t)\\) and \\(q(t)\\), now with SI units.\n\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,7))\nfig.subplots_adjust(hspace=0.05)\n\nstart = \"2020-10-18\"\nend = \"2020-10-25\"\nax1.plot(df_p['PRECIPITATION'])\nax2.plot(df_q['discharge'], color=\"tab:blue\", lw=2)\n\nax1.set(xticks=[],\n        ylabel=r\"precipitation (m$^3$/s)\",\n        title=\"Precipitation and discharge, Boneyard Creek at Urbana, IL\\n 20-21 October 2020, 5-minute data\")\nax2.set(xlabel=\"date\",\n        ylabel=r\"discharge (m$^3$/s)\")\n\nplt.gcf().autofmt_xdate()  # makes slated dates\n\n\n\n\nItâ€™s time for base flow separation! Convert \\(q(t)\\) into \\(q^*(t)\\)\n\nfrom matplotlib.dates import HourLocator, DateFormatter\nimport matplotlib.dates as mdates\nimport matplotlib.ticker as ticker\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,7))\nfig.subplots_adjust(wspace=0.05)\n\nax1.plot(df_q['discharge'], color=\"black\", lw=2)\npoint1 = pd.to_datetime(\"2020-10-20 16:40:00\")\npoint2 = pd.to_datetime(\"2020-10-21 00:00:00\")\ntwo_points = df_q.loc[[point1, point2]]['discharge']\nax1.plot(two_points, 'o', color=\"tab:red\")\n\nnew = pd.DataFrame(data=two_points, index=two_points.index)\n\ndf_linear = (new.resample(\"5min\") #resample\n                .interpolate(method='time') #interpolate by time\n            )\n\nax1.plot(df_linear, color=\"tab:blue\")\n\ndf_between_2_points = df_q.loc[df_linear.index]\nax1.fill_between(df_between_2_points.index, df_between_2_points['discharge'],\n                 y2=df_linear['discharge'],\n                 color=\"tab:blue\", alpha=0.3)\n\nqstar = df_q.loc[df_linear.index]['discharge'] - df_linear['discharge']\nQstar = qstar.sum() * 60 * 5\n\nax2.plot(qstar, color=\"black\", lw=2)\nax2.fill_between(qstar.index, qstar,\n                 y2=0.0,\n                 color=\"tab:blue\", alpha=0.3)\n\nax1.set(xlim=[df_q.index[0],\n              df_q.index[-1]],\n        ylabel=r\"discharge (m$^3$/s)\",\n        ylim=[0, 5.5],\n        yticks=[0,1,2,3,4],\n        title=\"total discharge, q(t)\")\nax2.set(yticks=[],\n        ylim=[0, 5.5],\n        xlim=[df_q.index[0],\n              df_q.index[-1]],\n        title=\"effective discharge, q*(t)\"\n       )\n\nplt.gcf().autofmt_xdate()  # makes slated dates\n\n\n\n\nWe can calculate \\(p^*\\) now, using\n\\[\nP^* = Q^*\n\\]\nOne of the simplest methods is to multiply \\(p(t)\\) by a fixed constant (<1) to obtain \\(p^*\\), so that the equation above holds true.\n\nratio = Qstar/ P\npstar = df_p['PRECIPITATION'] * ratio\nPstar = pstar.sum() * 5 * 60\nprint(f\"Qstar / P = {ratio:.2f}\")\n\nQstar / P = 0.16\n\n\nCalculate now the centroid (\\(t_pc\\)) for effective precipitation \\(p^*\\) and centroid (\\(t_{qc}\\)) of effective discharge \\(q^*\\). Calculate also the time of peak discharge (\\(t_{pk}\\)). Then, calculate the centroid lag (\\(T_{LC}\\)), the centroid lag-to-peak (\\(T_{LPC}\\)), and the time of concentration (\\(T_c\\)). Use the equations below:\n\\(T_{LPC} \\simeq 0.60 \\cdot T_c\\)\nTime of precipitation centroid:\n\\[\nt_{pc} = \\frac{\\displaystyle \\sum_{i=1}^n p_i^* \\cdot t_i}{P^*}\n\\]\nTime of streamflow centroid:\n\\[\nt_{qc} = \\frac{\\displaystyle \\sum_{i=1}^n q_i^* \\cdot t_i}{Q^*}\n\\]\nCentroid lag:\n\\[\nT_{LC} = t_{qc} - t_{pc}\n\\]\nCentroid lag-to-peak: \\[\nT_{LPC} = t_{pk} - t_{pc}\n\\]\nTime of concentration: \\[\nT_{LPC} \\simeq 0.60 \\cdot T_c\n\\]\n\n# pstar centroid\n# time of the first (nonzero) rainfall data point\nt0 = pstar[pstar != 0.0].index[0]\n# time of the last (nonzero) rainfall data point\ntf = pstar[pstar != 0.0].index[-1]\n# duration of the rainfall event, in minutes\ntd = (tf-t0) / pd.Timedelta('1 min')\n# make time array, add 2.5 minutes (half of dt)\ntime = np.arange(0, td+1, 5) + 2.5\n# create pi array, only with relevant data (during rainfall duration)\npi = pstar.loc[(pstar.index >= t0) & (pstar.index <= tf)]\n# convert from m3/5min to m3/s\npi = pi.values * 60 * 5\n# time of precipitation centroid\nt_pc = (pi * time).sum() / pi.sum()\n# add initial time\nt_pc = t0 + pd.Timedelta(minutes=t_pc)\nt_pc\n\n# qstar centroid\n# time of the first (nonzero) discharge data point\nt0 = qstar[qstar != 0.0].index[0]\n# time of the last (nonzero) discharge data point\ntf = qstar[pstar != 0.0].index[-1]\n# duration of the discharge event, in minutes\ntd = (tf-t0) / pd.Timedelta('1 min')\n# make time array, add 2.5 minutes (half of dt)\ntime = np.arange(0, td+1, 5) + 2.5\n# create qi array, only with relevant data (during discharge duration)\nqi = qstar.loc[(qstar.index >= t0) & (qstar.index <= tf)]\n# convert from m3/5min to m3/s\nqi = qi.values * 60 * 5\n# time of discharge centroid\nt_qc = (qi * time).sum() / qi.sum()\n# add initial time\nt_qc = t0 + pd.Timedelta(minutes=t_qc)\nt_qc\n\n# time of peak discharge\nmax_discharge = qstar.max()\nt_pk = qstar[qstar == max_discharge].index[0]\n\n# centroid lag\nT_LC = t_qc - t_pc\n\n# centroid lag-to-peak\nT_LPC = t_pk - t_pc\n\n# time of concentration\nT_c = T_LPC / 0.60\n\nprint(f\"T_LC = {T_LC}\")\nprint(f\"T_LPC = {T_LPC}\")\nprint(f\"T_c = {T_c}\")\n\nT_LC = 0 days 00:53:03.186594\nT_LPC = 0 days 01:22:59.857820\nT_c = 0 days 02:18:19.763033333"
  },
  {
    "objectID": "streamflow/unit-hydrograph-lecture.html#linear-reservoir-model",
    "href": "streamflow/unit-hydrograph-lecture.html#linear-reservoir-model",
    "title": "15Â  Unit Hydrograph",
    "section": "15.1 Linear reservoir model",
    "text": "15.1 Linear reservoir model\n\n\n\nSource: Dingman (2015), page 472"
  },
  {
    "objectID": "streamflow/unit-hydrograph-lecture.html#rainfall-runoff-models",
    "href": "streamflow/unit-hydrograph-lecture.html#rainfall-runoff-models",
    "title": "15Â  Unit Hydrograph",
    "section": "15.2 Rainfall-Runoff Models",
    "text": "15.2 Rainfall-Runoff Models\n\n15.2.1 The Rational Method\nThe rational method postulates a simple pro- portionality between peak discharge, \\(q_{pk}\\), and rainfall intensity, \\(p^*\\):\n\\[\nq_{pk} = \\varepsilon_R \\cdot C_R \\cdot A_D \\cdot p^*\n\\]\n\n\\(q_{pk}\\): peak discharge (m\\(^3\\)/s)\n\\(\\varepsilon_R=0.278\\): unit-conversion factor\n\\(C_R\\): dimensionless runoff coefficient\n\\(A_D\\): drainage area (km\\(^2\\))\n\\(p^*\\): rainfall intensity (mm/h)\n\n\nObviously the results obtained with the method are highly sensitive to the value chosen for CR; values range from 0.05 for gently sloping lawns up to 0.95 for highly urbanized areas of roofs and pavement.\nThe rational method is widely used in urban drainage design, but Pilgrim and Cordery (1992) caution that there are typically few data available to guide the selection of CR, and that CR for a given watershed may vary widely from storm to storm due to differing antecedent conditions.\n\n\n\n15.2.2 The Soil Conservation Service Curve-Number Method (SCS-CN)\nAlso called NRCS curve number procedure. NRCS = Natural Resources Conservation Service - USDA\n\\[\nQ^* = P^* = \\frac{\\left( P-S_{I} \\right)^2}{P-S_I+S_{max}}\n\\]\nThe initial abstraction \\(S_I\\) is usually approximated as \\(0.2\\cdot S_{max}\\), therefore:\n\\[\nQ^* = P^* = \\frac{\\left( P-0.2\\cdot S_{max} \\right)^2}{P+0.8\\cdot S_{max}}\n\\]\n\\[\nS_{max} = 25.4\\left(\\frac{1000}{CN}-10\\right)\n\\]\nThe number 25.4 is a conversion factor from inches to millimeters.\n\n\nThe curve number (CN) is a function of the ability of soils to infiltrate water, land use, and the soil water conditions at the start of a rainfall event (antecedent soil water condition). To account for the infiltration character- istics of soils, the NRCS has divided soils into four hydrologic soil groups, which are defined as follows (NRCS, 1984):\n\nGroup A (low runoff potential): Soils with high infiltration rates even when thoroughly wetted. These consist chiefly of deep, well-drained sands and gravels. These soils have a high rate of water transmission (final infiltration rate greater than 0.3 in./h).\nGroup B: Soils with moderate infiltration rates when thoroughly wetted. These consist chiefly of soils that are moderately deep to deep, moderately well drained to well drained with moderately fine to moderately coarse textures. These soils have a moderate rate of water transmission (final infil- tration rate 0.15 to 0.30 in./h).\nGroup C: Soils with slow infiltration rates when thoroughly wetted. These consist chiefly of soils with a layer that impedes downward movement of water or soils with moderately fine to fine texture. These soils have a slow rate of water transmission (final infiltration rate 0.05 to 0.15 in./h).\nGroup D (high runoff potential): Soils with very slow infiltration rates when thoroughly wetted. These consist chiefly of clay soils with a high swelling potential, soils with a permanent high water table, soils with a claypan or clay layer at or near the surface, and shallow soils over nearly impervious materials. These soils have a very slow rate of water transmission (final infiltration rate less than 0.05 in./h).\n\nThere are also three categories for Antecedent Soil Moisture Condition (AMC): * AMC I: Dormant season antecedent soil moisture less than 0.5 in. Growing season antecedent soil moisture less than 1.4 in. * AMC II: Dormant season antecedent soil moisture between 0.5 and 1.1 in. Growing season anteced- ent soil moisture between 1.4 and 2.1 in. * AMC III: Dormant season antecedent soil mois- ture greater than 1.1 in. Growing season anteced- ent soil moisture greater than 2.1 in.\nSee the table below to find curve numbers for AMC II: \n\nP=21\nratio = 4.17e4/2.61e5\nCN=86\nSmax = 25.4 * (1000/CN - 10)\nPmin = 0.2 * Smax\nQstar = 0.0\nif P > Pmin:\n    Qstar = (P - 0.2*Smax)**2 / (P+0.8*Smax)\nQstar/P\n\n0.14270006393832066\n\n\n\nratio\n\n0.15977011494252874\n\n\n\nQstar / P\n\n0.9148811393863234\n\n\n\n%matplotlib notebook\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef Qstar_f(pe, CN):\n#     Smax = 25.4*(1000/CN - 10)\n    Smax = (1000/CN - 10)\n#     Smax = (1000/CN - 10) / 25.4\n    Qstar = (pe - 0.2*Smax)**2 / (pe+0.8*Smax)\n    return Qstar\n\npe = np.linspace(0,8,101)\n# plt.plot(pe, Qstar_f(pe, 35))\nplt.plot(pe, Qstar_f(pe, 50))\n# plt.plot(pe, Qstar_f(pe, 85))\n\n\n\n\n\n\n\n\n\n\n\nDingman, S. L. 2015. Physical Hydrology. 3rd edition. Waveland Press, Incorporated."
  },
  {
    "objectID": "summing-up/budyko-framework-lecture.html#water-and-surface-energy-balances",
    "href": "summing-up/budyko-framework-lecture.html#water-and-surface-energy-balances",
    "title": "16Â  Budyko framework",
    "section": "16.1 Water and surface energy balances",
    "text": "16.1 Water and surface energy balances\nFor long-term averages:\n\\[\nP = ET+Q\n\\]\n\\[\nR_n = \\lambda_w\\cdot ET + H\n\\]\n\n\\(P\\): precipitation (L T\\(^{-1}\\), e.g.: mm/day)\n\\(ET\\): evapotranspiration (L T\\(^{-1}\\))\n\\(Q\\): streamflow (L T\\(^{-1}\\))\n\\(R_n\\): net energy available at soil surface (M T\\(^{-3}\\), e.g.: W m\\(^{-2}\\))\n\\(\\lambda_w\\): latent heat of vaporization of water (M L\\(^{-1}\\)T\\(^{-2}\\), as defined here, the units will be weird)\n\\(H\\): sensible heat flux from the surface into the atmosphere (M T\\(^{-3}\\))\n\\(\\lambda_w \\cdot ET\\): latent heat flux (M T\\(^{-3}\\))"
  },
  {
    "objectID": "summing-up/budyko-framework-lecture.html#assumptions",
    "href": "summing-up/budyko-framework-lecture.html#assumptions",
    "title": "16Â  Budyko framework",
    "section": "16.2 Assumptions",
    "text": "16.2 Assumptions\n\nbecause we are dealing with long-term averages, there are negligible changes of watershed stored water.\nnegligible energy is stored at the soil surface, and heat transfer from soil surface to deeper soil layers (\\(G\\)) averages zero."
  },
  {
    "objectID": "summing-up/budyko-framework-lecture.html#question",
    "href": "summing-up/budyko-framework-lecture.html#question",
    "title": "16Â  Budyko framework",
    "section": "16.3 Question",
    "text": "16.3 Question\nGiven measurements of rainfall and meteorological conditions, can we predict the partitioning of \\(P\\) between \\(ET\\) and \\(Q\\)?"
  },
  {
    "objectID": "summing-up/budyko-framework-lecture.html#limits",
    "href": "summing-up/budyko-framework-lecture.html#limits",
    "title": "16Â  Budyko framework",
    "section": "16.4 Limits",
    "text": "16.4 Limits\nFor very dry watersheds (deserts, for example), almost all precipitation (\\(P\\)) is lost via evapotranspiration (\\(ET\\)). These watersheds are called water limited.\nIn wet watersheds, at the annual scale, the sensible heat (\\(H\\)) is directed from the surface to the atmosphere in almost all climatic zones on Earth (meaning: soil heats air). Therefore, \\(H\\) cannot supply much energy to the soil surface, and it is assumed that \\(R_n\\) provides entirely the energy required for evapotranspiration. Dividing the second equation by \\(\\lambda_w\\), we get \\(R_n/\\lambda_w = ET + H/\\lambda_w\\). It is clear that the maximum possible \\(ET\\) occurs when all incoming radiation energy \\(R_n\\) is consumed by evapotranspiration \\(ET\\), and there is negligible sensible heat flux \\(H\\). As a result, the upper limit of \\(\\lambda_w E\\) is \\(R_n\\), in wet watersheds. In these watersheds, called energy limited, \\(ET\\) tends to the potential evapotranspiration (\\(ET_0\\)).\n\n16.4.1 Summary:\nFor energy-limited watersheds\n\n\nAs precipitation \\(P\\rightarrow \\infty\\), evapotranspiration \\(ET\\rightarrow ET_0\\)\n\n\nFor water-limited watersheds\n\n\nAs potential evapotranspiration \\(ET_0\\rightarrow \\infty\\), actual evaporation \\(ET\\rightarrow P\\)\n\n\nIn general, we can write\n\\[\nET = f(P,ET_0)\n\\]\nThe variables \\(P\\) and \\(ET\\) have the same dimenstions (L T\\(^{-1}\\)), and we can divide the equation above by \\(P\\):\n\\[\n\\frac{ET}{P} = f(D_I),\n\\]\nwhere \\[\nD_I = \\displaystyle\\frac{ET_0}{P}\n\\] is called the dryness index. A useful classification is\n\n\n\nDryness Index\nClassification\n\n\n\n\n\\(D_I < 1.54\\)\nHumid\n\n\n\\(1.54 < D_I < 2\\)\nDry Subhumid\n\n\n\\(2 < D_I < 5\\)\nSemi-arid\n\n\n\\(5 < D_I < 20\\)\nArid\n\n\n\\(20 < D_I\\)\nHyper-arid\n\n\n\n\nATTENTION. The dryness index can also be called the â€œAridity Indexâ€ (\\(AI\\)), however sometimes the \\(AI\\) means the inverse of \\(D_I\\):\n\\[AI = 1/D_I\\]\nBe careful to check the definitions.\nThe summary (1) and (2) above can be now represented as:\n\n\nAs \\(D_I\\rightarrow 0\\), \\(\\displaystyle\\frac{ET}{P}\\rightarrow D_I\\)\n\n\n\n\nAs \\(D_I\\rightarrow \\infty\\), \\(\\displaystyle\\frac{ET}{P}\\rightarrow 1\\)\n\n\n\n\nBudyko (1974), proposed the following equation:\n\\[\n\\frac{ET}{P} = \\left[ D_I \\tanh\\left( \\frac{1}{D_I} \\right)\\left( 1-e^{-D_I} \\right) \\right]^{1/2}\n\\]\n\nSource: {% cite jones2012ecosystem %}\n\nSource: {% cite krajewski2021attempt %}\n\nThere are many alternatives to Budykoâ€™s equation. Many equations have adjustable parameters, such as Fuâ€™s equation:\n\\[\n\\frac{ET}{P} = 1 + D_I - (1 + D_I^w)^{1/w},\n\\]\nwhere \\(w>1\\). Each catchment has its own specific parameter \\(w\\), that may represent biophysical/landscape features. There is no concensus regarding the interpretation of \\(w\\), ranging from an effective empirical parameter, whose relationship to biophysical features can be discerned, to an arbitrary empirical constant with no a priori physical meaning. Source: {% cite reaver2020reinterpreting %}\nSource: {% cite zhang2004rational %}"
  },
  {
    "objectID": "summing-up/budyko-framework-lecture.html#hypotheses-for-why-dryness-index-controls-so-much-the-partitioning-of-p-into-et-and-q",
    "href": "summing-up/budyko-framework-lecture.html#hypotheses-for-why-dryness-index-controls-so-much-the-partitioning-of-p-into-et-and-q",
    "title": "16Â  Budyko framework",
    "section": "16.5 Hypotheses for why dryness index controls so much the partitioning of P into ET and Q",
    "text": "16.5 Hypotheses for why dryness index controls so much the partitioning of P into ET and Q\nSource: {% cite berghuijs2020unanswered %}\n\nThe first is that the Budyko curve is accurate because landscape features (e.g., soils and vegetation) coevolve with the local climate in such a manner that precipitation partitioning into streamflow and evapotranspiration converges towards the Budyko curve\nA second hypothesis is that catchments over time evolve towards the supply and demand limits (rather than towards a curve), because landscapes and their vegetation are unaware of the Budyko curve but do evolve to maximize their use of available resources (including water). However, because limiting factors such as climatic variability exist (which will reduce a catchmentâ€™s ability to use all water because it cannot fully buffer the highly variable precipitation input), catchments will tend to not reach these limits. This may lead to an (apparent) existence of the Budyko curve which falls relatively close to the demand and supply limits.\nA third hypothesis is that the existence of a strong universal relationship between aridity and catchment water balances might be explained by an underlying organizing principle such as maximum entropy production because the Budyko curve may be consistent with how hydrologic systems optimally partition water and energy\nA fourth hypothesis is that virtually any landscape and climate combination (also those in heavily disturbed landscapes: e.g., a city, agricultural lands, etc.) will fall near the Budyko curve because climate aridity will dominate precipitation partitioning largely independent of the climate-landscape configuration or any optimization principle."
  },
  {
    "objectID": "summing-up/budyko-framework-lecture.html#hypotheses-for-deviations-from-budyko-curve",
    "href": "summing-up/budyko-framework-lecture.html#hypotheses-for-deviations-from-budyko-curve",
    "title": "16Â  Budyko framework",
    "section": "16.6 Hypotheses for deviations from Budyko curve",
    "text": "16.6 Hypotheses for deviations from Budyko curve\nSource: {% cite creed2012budyko %}\n\nUnder stationary conditions (naturally occurring oscillations), catchments will fall on the Budyko Curve\nUnder non-stationary conditions (anthropogenic climate change), catchments will deviate from the Budyko Curve in a predictable manner\n\n\n16.6.1 Reasons for falling off the Budyko Curve\n\nInadequate representation of P and T (Loch Vale)\nInadequate representation of ET (Andrews)\nInadequate representation of Q (Marcell)\nForest conversion (Coweeta)\nForest disturbance (Luquillo)\n\n\n\n16.6.2 Critique\nSource: {% cite berghuijs2020unanswered %}\nThe (mathematical) specifics of such studies vary, but all approaches are founded on the assumption that catchments follow a (parametric) Budyko curve when aridity changes, and that consequently all other movements in the Budyko space are caused by other factors. The validity of this assumption remains mostly untested, which seems surprising given it underpins all of these studiesâ€™ findings."
  },
  {
    "objectID": "summing-up/budyko-framework-lecture.html#references",
    "href": "summing-up/budyko-framework-lecture.html#references",
    "title": "16Â  Budyko framework",
    "section": "16.7 References",
    "text": "16.7 References\n{% bibliography â€“cited %}"
  },
  {
    "objectID": "summing-up/spatial-distribution.html#the-problem",
    "href": "summing-up/spatial-distribution.html#the-problem",
    "title": "17Â  Spatial distribution - lecture",
    "section": "17.1 The problem",
    "text": "17.1 The problem\nLetâ€™s say we want to calculate the average rainfall on a watershed, and we have data available for 7 stations, as shown in the figure below [Dingman, figure 4.26]: \nThere are a number of methods for calculating the average precipitation."
  },
  {
    "objectID": "summing-up/spatial-distribution.html#thiessen-method-voronoi-diagram",
    "href": "summing-up/spatial-distribution.html#thiessen-method-voronoi-diagram",
    "title": "17Â  Spatial distribution - lecture",
    "section": "17.2 Thiessen method [Voronoi diagram]",
    "text": "17.2 Thiessen method [Voronoi diagram]\nBrutsaert, Figure 3.11 \nHow to compute the areas: \nAverage areal precipitation is a weighted sum:\n\\[\n\\langle P \\rangle = \\frac{\\sum_i A_i P_i}{\\sum_i A_i}\n\\]\nA nice way to understand the Thiessen method is depicted in the gif below (from Wikipedia):"
  },
  {
    "objectID": "summing-up/spatial-distribution.html#inverse-distance-method",
    "href": "summing-up/spatial-distribution.html#inverse-distance-method",
    "title": "17Â  Spatial distribution - lecture",
    "section": "17.3 Inverse distance method",
    "text": "17.3 Inverse distance method\nBrutsaert, Figure 3.12 \nThe precipitation for square 17 is\n\\[\nP_{17} =\n\\displaystyle\\frac\n{\\displaystyle\\sum_\\text{$i$ = all stations}\\frac{P_i}{d_{i,17}^2}}\n{\\displaystyle\\sum_\\text{$i$ = all stations}\\frac{1}{d_{i,17}^2}}\n\\]\nThe average precipitation for the whole watershed is the weighted average of all squares, where the weight is their area:\n\\[\n\\langle P \\rangle =\n\\displaystyle\\frac\n{\\displaystyle\\sum_\\text{$j$ = all squares} A_j P_j}\n{\\displaystyle\\sum_\\text{$j$ = all squares} A_j}\n\\]\nBrutsaert, page 93:\n\nDean and Snyder (1977) found that the exponent (for the distance \\(d^{-b}\\)) b = 2 yielded the best results in the Piedmont region of the southeastern United States, whereas Simanton and Osborn (1980) concluded from measurements in Arizona that b can range between 1 and 3 without significantly affecting the results."
  },
  {
    "objectID": "summing-up/spatial-distribution.html#isohyetal-method",
    "href": "summing-up/spatial-distribution.html#isohyetal-method",
    "title": "17Â  Spatial distribution - lecture",
    "section": "17.4 Isohyetal method",
    "text": "17.4 Isohyetal method\nBrutsaert, Figure 3.12 \nThe same equation of the Thiessen method can be used:\n\\[\n\\langle P \\rangle = \\frac{\\sum_i A_i P_i}{\\sum_i A_i}\n\\]"
  },
  {
    "objectID": "summing-up/spatial-distribution.html#how-it-is-actually-done",
    "href": "summing-up/spatial-distribution.html#how-it-is-actually-done",
    "title": "17Â  Spatial distribution - lecture",
    "section": "17.5 How it is actually done",
    "text": "17.5 How it is actually done\nMost often, Geographic Information System (GIS) software is used to analyze spatial data. Two of the most used programs are ArcGIS (proprietary) and QGIS (free).\nA good discussion of the different methods can be found on Manuel Gimondâ€™s website, Intro to GIS and Spatial Analysis.\nAttention, Donâ€™t mix precision with accuracy. There are many ways of interpolating, just because a result seems detailed, it does not imply that it is accurate! See below three interpolation methods.\n\nBelow you can find a simple Python code that exemplifies some of the methods, producing the following figure:\n\n%matplotlib notebook\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.interpolate import griddata\nfrom scipy.spatial import Voronoi, voronoi_plot_2d, ConvexHull\n\nfig, ax = plt.subplots(1, 3, figsize=(10,7))\nfig.subplots_adjust(left=0.0, right=1.0, top=0.96, bottom=0.05,\n                    hspace=0.02, wspace=0.02)\n\nN = 6\nPI = '3141592653589793'\npoints = np.random.rand(N, 2)\npoints = np.vstack([points,[0,0], [0,1], [1,0], [1,1]])\nvalues = np.array([int(x) for x in list(PI)])[:(N+4)]\n# values = np.array([3, 1, 4, 1, 5, 9, 2, 6, 5, 3])\n\ngrid_x, grid_y = np.mgrid[0:1:100j, 0:1:200j]\n\ngrid_z_nearest = griddata(points, values, (grid_x, grid_y), method='nearest')\ngrid_z_cubic = griddata(points, values, (grid_x, grid_y), method='cubic')\n\nax[0].plot(points[:,0], points[:,1], 'o', ms=3, markerfacecolor=\"red\", markeredgecolor=\"red\")\nax[0].set_aspect('equal', 'box')\nax[0].set(xlim=[0,1], ylim=[0,1])\nax[0].set_title(\"the stations\")\nfor i, v in enumerate(values):\n    ax[0].text(points[i,0], points[i,1], str(v))\n\nax[1].imshow(grid_z_nearest.T, extent=(0,1,0,1), origin='lower')\nax[1].plot(points[:,0], points[:,1], 'o', ms=3, markerfacecolor=\"red\", markeredgecolor=\"red\")\nvor = Voronoi(points)\nvoronoi_plot_2d(vor, show_vertices=False, line_colors='cyan',\n                line_width=3, line_alpha=1, point_size=0, ax=ax[1])\nax[1].set_title(\"Thiessen Method\")\n\nax[2].plot(points[:,0], points[:,1], 'o', ms=3, markerfacecolor=\"red\", markeredgecolor=\"red\")\nnlines = int((values.max()-values.min()+1)/2)\nax[2].contourf(grid_x, grid_y, grid_z_cubic, nlines)\ncont = ax[2].contour(grid_x, grid_y, grid_z_cubic, nlines, colors=\"black\")\nax[2].clabel(cont, inline=1, colors='white', fmt='%.0f')\nax[2].set_title(\"Isohyetal Method\")\n\nfor i, a in enumerate(ax):\n    a.set(xlim=[-0.2,1.2], ylim=[-0.2,1.2])\n    a.axis('off')\n    a.set_aspect('equal', 'box')\n\nfig.savefig(\"spatial-distribution.png\", dpi=500)"
  },
  {
    "objectID": "assignments/assignments-general.html#presentation",
    "href": "assignments/assignments-general.html#presentation",
    "title": "Assignments",
    "section": "ğŸŒ… Presentation",
    "text": "ğŸŒ… Presentation\nAll the assignment must be in one single Jupyter Notebook. Use markdown cells to discuss the analysis and results, and in code cells show all the code you used to produce the figures and data analysis. Leave only the code necessary for your analysis, delete unnecessary lines your wrote while analyzing your data. Donâ€™t forget to comment your code, just like we did during exercise sessions. The assignment will be written in English."
  },
  {
    "objectID": "assignments/assignments-general.html#evaluation",
    "href": "assignments/assignments-general.html#evaluation",
    "title": "Assignments",
    "section": "ğŸ’¯ Evaluation",
    "text": "ğŸ’¯ Evaluation\nAll your assignments will be evaluated according to the following criteria:\n\n40% Presentation. How the graphs look, labels, general organization, markdown, clean code.\n30% Discussion. This is where you explain what you did, what you found out, etc.\n15% Depth of analysis. You can analyze/explore the data with different levels of complexity, this is where we take that into consideration.\n10% Replicability: Your code runs flawlessly.\n5%: Code commenting. Explain in your code what you are doing, this is good for everyone, especially for yourself!"
  },
  {
    "objectID": "assignments/assignments-general.html#ai-policy",
    "href": "assignments/assignments-general.html#ai-policy",
    "title": "Assignments",
    "section": "ğŸ¤– AI Policy",
    "text": "ğŸ¤– AI Policy\nThe guidelines below are an adaptation of Ethan Mollickâ€™s extremely useful ideas on AI as an assistant tool for teaching.\nI EXPECT YOU to use LLMs (large language models) such as ChatGPT, Bing AI, Google Bard, Lex, or whatever else springs up since the time of this writing. You should familiarize yourself with the AIâ€™s capabilities and limitations.\nAt a minimum, you should use AI to check the quality of your English text, and make the text pleasant to read.\nConsider the following important points:\n\nUltimately, you, the student, are responsible for the assignment.\nDonâ€™t trust anything the LLM says. Assume everything is wrong unless you either know the answer of can check with another source. You will be responsible for any errors or omissions provided by the tool.\nYou can use LLMs to help you write both the text and the code. If you provide minimum effort prompts to the model, you will probably get low quality results. You will need to refine your prompts in order to get good outcomes. Practice a lot.\nAcknowledge the use of AI in your assignment. Be transparent about your use of the tool and the extent of assistance it provided.\n\n\nThe text above was written with the assistance of ChatGPT. The content is mine, ChatGPT checked my English and suggested some improvements."
  },
  {
    "objectID": "assignments/assignment1-precipitation.html#instructions",
    "href": "assignments/assignment1-precipitation.html#instructions",
    "title": "18Â  Assignment 1 - Precipitation",
    "section": "18.1 ğŸ“’ instructions",
    "text": "18.1 ğŸ“’ instructions\nThis is where learning happens, not during a lecture. Youâ€™ll learn a ton of things by doing them yourself. Much success! ğŸ˜„\nCreate a Jupyter Notebook called assignment-01-IDNUMBER, where IDNUMBER is your 9-digit ID. This is the file only file we will check."
  },
  {
    "objectID": "assignments/assignment1-precipitation.html#locations",
    "href": "assignments/assignment1-precipitation.html#locations",
    "title": "18Â  Assignment 1 - Precipitation",
    "section": "18.2 ğŸ“Œ locations",
    "text": "18.2 ğŸ“Œ locations\nChoose two meteorologic stations from NOAAâ€™s Global Summary of the Month.\nCriteria:\n1. at least 60 years of data for each station.\n2. choose stations with different characteristics, regarding mean annual precipitation, seasonality,  etc."
  },
  {
    "objectID": "assignments/assignment1-precipitation.html#tasks",
    "href": "assignments/assignment1-precipitation.html#tasks",
    "title": "18Â  Assignment 1 - Precipitation",
    "section": "18.3 ğŸ›  tasks",
    "text": "18.3 ğŸ›  tasks\nAnalyze the data and make graphs showing the differences and similarities between the two locations you chose. The analyses and graphs should be similar to those we saw during our lectures and exercise sessions. Of course, if you find something interesting we did not do in class, you are more than welcome to show it. Discuss about:\n1. mean annual precipitation and inter-annual variability.\n2. intra-annual variability (seasonality).\n\nYou will have two weeks to deliver your assignment. You should not hand in a dry document with only figures and code, Iâ€™m expecting text before and after each code/graph cell, explaining what you did, why you did it, and how it fits the story you are telling. Donâ€™t forget to put labels on your plot axes, title, legend, etc. Please refer to the main Assignments page for more details on how to write this report.\nYour Jupyter Notebook should be fully functional: if we press Kernel > Restart & Run All, all the code must work without any errors."
  },
  {
    "objectID": "assignments/assignment2-ET.html#instructions",
    "href": "assignments/assignment2-ET.html#instructions",
    "title": "19Â  Assignment 2 - Evapotranspiration",
    "section": "19.1 ğŸ“’ instructions",
    "text": "19.1 ğŸ“’ instructions\nThis is where learning happens, not during a lecture. Youâ€™ll learn a ton of things by doing them yourself. Much success! ğŸ˜„\nCreate a Jupyter Notebook called assignment-02-IDNUMBER, where IDNUMBER is your 9-digit ID. This is the file only file we will check."
  },
  {
    "objectID": "assignments/assignment2-ET.html#locations-and-data",
    "href": "assignments/assignment2-ET.html#locations-and-data",
    "title": "19Â  Assignment 2 - Evapotranspiration",
    "section": "19.2 ğŸ“Œ locations and data",
    "text": "19.2 ğŸ“Œ locations and data\nChoose two stations with different climates.\nGo to NOAAâ€™s Climate Reference Network Data website. The sub-hourly (5-min) data contains information on\n\nair temperature,\nprecipitation,\nglobal solar radiation,\nsurface infrared temperature,\nrelative humidity,\nsoil moisture and temperature,\nwetness, and\n1.5 meter wind speed.\n\nThere is no data on air pressure, so one needs to use the stations coordinates (lat, lon) to find its height above sea level, and from that infer the air pressure. You can use Google Earth or any other means to find the stationâ€™s height.\nIn the Data Access link, choose a year and a station you would like to analyze. If you are not sure where the stations are, find them using the 2-letter state abbreviation and the station name.\nDownload the following files: 1. One full year of data for each station. Make sure important data we need to calculate Penmanâ€™s ET estimation is available. 2. The headers file 3. The documentation file\nMake sure you understand what are the units provided for each measurement (see documentation)."
  },
  {
    "objectID": "assignments/assignment2-ET.html#tasks",
    "href": "assignments/assignment2-ET.html#tasks",
    "title": "19Â  Assignment 2 - Evapotranspiration",
    "section": "19.3 ğŸ›  tasks",
    "text": "19.3 ğŸ›  tasks\nProduce potential ET estimates using Thornthwaiteâ€™s equation and Penmanâ€™s equation. Produce plots of ET as a function of time for each station, comparing the two methods you used. Also, using Penmanâ€™s ET estimates, compare the two stations and discuss about their differences/similarities.\nYou might find interesting things in the data, such as periods of unusually high/low temperatures, radiation, etc. Discuss how these factors might have affected the ET estimates that you calculated.\nYou will have two weeks to deliver your assignment. You should not hand in a dry document with only figures and code, Iâ€™m expecting text before and after each code/graph cell, explaining what you did, why you did it, and how it fits the story you are telling. Donâ€™t forget to put labels on your plot axes, title, legend, etc.\nYour Jupyter Notebook should be fully functional: if we press Kernel > Restart & Run All, all the code must work without any errors."
  },
  {
    "objectID": "assignments/assignment2-ET.html#importing-the-data",
    "href": "assignments/assignment2-ET.html#importing-the-data",
    "title": "19Â  Assignment 2 - Evapotranspiration",
    "section": "19.4 ğŸšš importing the data",
    "text": "19.4 ğŸšš importing the data\nBelow you can find an example of how to import the data file provided by NOAAâ€™s Climate Reference Network Data website. You might have to make some adjustments to it.\ndata_file = \"CRNS0101-05-2020-CO_Boulder_14_W.txt\"\ndf = pd.read_csv(data_file,\n                 header=None,                      # no headers needed, we'll do that later\n                 delim_whitespace=True,            # blank spaces separate between columns\n                 na_values=[\"-99.000\", \"-9999.0\"]  # substitute these values for missing (NaN) values\n                )\nheaders = pd.read_csv(\"HEADERS_sub_hourly.txt\",    # load headers file\n                      header=1,                    # skip the first [0] line\n                      delim_whitespace=True\n                     )\ndf.columns = headers.columns                       # rename df columns with headers columns\n# LST = local standard time\ndf[\"LST_TIME\"] = [f\"{x:04d}\" for x in df[\"LST_TIME\"]]  # time needs padding of zeros, then convert to string\ndf['LST_DATE'] = df['LST_DATE'].astype(str)            # convert date into string\ndf['datetime'] = df['LST_DATE'] + ' ' + df['LST_TIME'] # combine date+time into datetime\ndf['datetime'] = pd.to_datetime(df['datetime'])        # interpret datetime\ndf = df.set_index('datetime')                          # make datetime the index\ndf"
  },
  {
    "objectID": "assignments/assignment3-streamflow.html#instructions",
    "href": "assignments/assignment3-streamflow.html#instructions",
    "title": "20Â  Assignment 3 - Streamflow",
    "section": "20.1 ğŸ“’ instructions",
    "text": "20.1 ğŸ“’ instructions\nThis is where learning happens, not during a lecture. Youâ€™ll learn a ton of things by doing them yourself. Much success! ğŸ˜„\nCreate a Jupyter Notebook called assignment-03-IDNUMBER, where IDNUMBER is your 9-digit ID. This is the file only file we will check."
  },
  {
    "objectID": "assignments/assignment3-streamflow.html#locations-and-data",
    "href": "assignments/assignment3-streamflow.html#locations-and-data",
    "title": "20Â  Assignment 3 - Streamflow",
    "section": "20.2 ğŸ“Œ locations and data",
    "text": "20.2 ğŸ“Œ locations and data\nChoose one location in the US.\n\nImport streamflow data from USGSâ€™s National Water Information System. Choose on the map any measuring station you see fit. Make sure there is available discharge data (usually given in cubic feet per second) in small time intervals, e.g., every 15 minutes.\nGo to NOAAâ€™s Climate Reference Network Data website. The sub-hourly (5-min) data contains information on many variables, we are interested in precipitation.\n\nAttention! Some os the USGS stations provide precipitation data. If you find one such station, step 2 above is unnecessary. If you only find discharge data in the USGS website, then make sure you choose two stations in very close proximity (USGS and NOAA). Because there are only a few high-resolution NOAA stations, you might want to start from there and then find discharge data for a stream near the NOAA station.\nBottom line: you are looking for precipitation and stream discharge data, for stations in close proximity, with a high temporal resolution (5 min, 15 min, etc)."
  },
  {
    "objectID": "assignments/assignment3-streamflow.html#tasks",
    "href": "assignments/assignment3-streamflow.html#tasks",
    "title": "20Â  Assignment 3 - Streamflow",
    "section": "20.3 ğŸ›  tasks",
    "text": "20.3 ğŸ›  tasks\nChoose a rain event of a few hours in your data set. Find the rate of effective water input (p) and the event flow rate (q). Analyze the data in a similar was as done during class (various graphs explaining what you see). Find also the characteristic times of the event (centroid lag \\(T_{LC}\\), and centroid lag-to-peak \\(T_{LPC}\\)).\nTry to find information on the climate, geography, soil, and land use of the watershed. Begin the assignment by explaining about the watershed you chose and characterizing it. When presenting the data and your analyses, discuss what you see based on the concepts learned in class (infiltration, runoff generation, and the factors that affect them). Does the information you found match what you see? What makes sense, and what doesnâ€™t?\nDiscussion is important!\nYou will have two weeks to deliver your assignment. You should not hand in a dry document with only figures and code, Iâ€™m expecting text before and after each code/graph cell, explaining what you did, why you did it, and how it fits the story you are telling. Donâ€™t forget to put labels on your plot axes, title, legend, etc.\nYour Jupyter Notebook should be fully functional: if we press Kernel > Restart & Run All, all the code must work without any errors."
  },
  {
    "objectID": "assignments/assignment3-streamflow.html#importing-the-data",
    "href": "assignments/assignment3-streamflow.html#importing-the-data",
    "title": "20Â  Assignment 3 - Streamflow",
    "section": "20.4 ğŸšš importing the data",
    "text": "20.4 ğŸšš importing the data\nYou can use the code from previous assignments and from the exercise lectures."
  },
  {
    "objectID": "assignments/assignment-FINAL.html#instructions",
    "href": "assignments/assignment-FINAL.html#instructions",
    "title": "21Â  Final Assignment",
    "section": "21.1 ğŸ“’ instructions",
    "text": "21.1 ğŸ“’ instructions\nThis is where learning happens, not during a lecture. Youâ€™ll learn a ton of things by doing them yourself. Much success! ğŸ˜„\nCreate two Jupyter Notebooks called 1. assignment-FINAL-CODE-IDNUMBER, and 2. assignment-FINAL-REPORT-IDNUMBER, where IDNUMBER is your 9-digit ID. These are the only files we will check."
  },
  {
    "objectID": "assignments/assignment-FINAL.html#locations-and-data",
    "href": "assignments/assignment-FINAL.html#locations-and-data",
    "title": "21Â  Final Assignment",
    "section": "21.2 ğŸ“Œ locations and data",
    "text": "21.2 ğŸ“Œ locations and data\nChoose one location in the US.\nDownload relevant data from NOAAâ€™s Global Summary of the Month, NOAAâ€™s Climate Reference Network Data, and from the USGSâ€™s National Water Information System.\nTry to find locations with many years of data, the more the better. Take some time to choose your station, plan well. Choose a location you have not worked with in past assignments."
  },
  {
    "objectID": "assignments/assignment-FINAL.html#tasks",
    "href": "assignments/assignment-FINAL.html#tasks",
    "title": "21Â  Final Assignment",
    "section": "21.3 ğŸ›  tasks",
    "text": "21.3 ğŸ›  tasks\nIn this final project, we will integrate the various topics we learned throughout the semester. You will tell a story about the location you chose, and describe the changes it experienced in the past many decades. You can focus on any kind of changes that would influence the hydrological fluxes we learned about. Here are a few examples of changes that you might work on: * severe droughts in part of the studied period, or an increasing trend in drought severity. * same as above for rainfall/floods, high temperatures, low temperatures, etc. * significant changes in land use, such as urbanization, deforestation, agricultural practices, etc.\nThe list above is not comprehensive, you can choose other factors. Consult with me in case of doubt.\nTry to find on the media and in scientific papers evidence for the change you are focusing on. Cite these sources: at least one peer-reviewed scientific paper, and at least 3 other sources, such as a government website, official weather sites, books, reputable news websites, etc.\nCan you see the same when analyzing data for the location you chose? Do your findings corroborate the expectation you had when you started this project? If they donâ€™t, can you explain why? Did you reach interesting or surprising conclusions in your analysis?\nAnalyze your locationâ€™s history with respect to the following: * Precipitation: seasonality, inter-annual variability, extreme precipitation events and return periods. * Potential evapotranspiration: Calculate PET using Penmanâ€™s equation for at least three different years of interest (not necessarily contiguous years). Calculate Thornthwaiteâ€™s PET for the whole length of the available data (comment about the suitability of Thornthwaiteâ€™s PET to the location you chose). * Analyze streamflow statistics in a similar manner as for precipitation: extreme discharge events and return periods. * Use Budykoâ€™s framework to calculate where the location you chose falls on the \\((ET/P,PET/P)\\) space for at least three different years of interest.\nTry to connect the dots: how do your different findings fit together? Discuss what you are trying to show, tell your story with the help of the data and your analyses. If you find things that go contrary to your expectations, can you raise hypotheses of why you see what you see?\nYou will have one month to hand in your project.\nMuch success! ğŸ˜"
  },
  {
    "objectID": "assignments/assignment-FINAL.html#presentation",
    "href": "assignments/assignment-FINAL.html#presentation",
    "title": "21Â  Final Assignment",
    "section": "21.4 ğŸŒ… presentation",
    "text": "21.4 ğŸŒ… presentation\nAll the assignment must be in two Jupyter Notebooks.\nThe notebook called CODE will contain all the code for the analyses you made. It must be fully functional, i.e., we must be able to Run All and not get any errors. Explain what you are doing in each step. Comment your code. Use markdown cells to split the notebook into subsections, one for each analysis (e.g.: ## Precipitation Analysis, ### Inter-annual variability, etc).\nThe notebook called Report will contain graphs and relevant data from the CODE notebook. It is here where you will introduce the location you chose, what you are trying to see. Here you will write all the results and discussion, as supported by the graphs and results you produced. Divide this notebook into sections: Introduction, Results and Discussion, Conclusion. Subdivide the sections into subsections when needed. In this file there should be no code at all.\nYou can write in English or in Hebrew, but the text in the figures must be in English. If you choose to write the discussion in Hebrew, be aware that Jupyter Notebooks donâ€™t have native right-to-left language support:\n× ×™×ª×Ÿ ×œ×›×ª×•×‘ ×‘×¢×‘×¨×™×ª, ×œ××¨×•×ª ×©×–×” ×œ× × ×¨××” ×›×´×› ×˜×•×‘â€¦\nYou can use some HTML code to achieve best results in Hebrew. Type the following\n<p dir=\"rtl\" style=\"text-align: right;\">\n×¢×›×©×™×• ×”×¨×‘×” ×™×•×ª×¨ ×˜×•×‘!\n</p>\nto get\n\n×¢×›×©×™×• ×”×¨×‘×” ×™×•×ª×¨ ×˜×•×‘!\n\nIf you have many paragraphs in hebrew, do the following:\n\n×¤×¡×§×” ××¡×¤×¨ 1.\n\n\n×¤×¡×§×” ××¡×¤×¨ 2.\n\n\n×× ×™×© ×œ×›× ×›××” ×¤×¡×§××•×ª, ×›×œ ××—×ª ××”×Ÿ ×ª×”×™×” ×‘×ª×•×š â€œdirâ€ ××©×œ×”\n\nIn my opinion it is too complicated to write in Hebrew in Jupyter Notebooks, just write in English, your grade will not be affected by typos nor less-than-perfect English proficiency."
  },
  {
    "objectID": "assignments/assignment-FINAL.html#evaluation",
    "href": "assignments/assignment-FINAL.html#evaluation",
    "title": "21Â  Final Assignment",
    "section": "21.5 ğŸ’¯ evaluation",
    "text": "21.5 ğŸ’¯ evaluation\nYour assignment will be evaluated according to the following criteria: * 40% Presentation. How the graphs look, labels, general organization, markdown, clean code. * 30% Discussion. This is where you explain what you did, what you found out, etc. * 15% Depth of analysis. You can analyze/explore the data with different levels of complexity, this is where we take that into consideration. * 10% Replicability: Your code runs flawlessly. * 5%: Code commenting. Explain in your code what you are doing, this is good for everyone, especially for yourself!"
  },
  {
    "objectID": "assignments/assignment-FINAL.html#importing-the-data",
    "href": "assignments/assignment-FINAL.html#importing-the-data",
    "title": "21Â  Final Assignment",
    "section": "21.6 ğŸšš importing the data",
    "text": "21.6 ğŸšš importing the data\nYou can use the code from previous assignments and from the exercise lectures."
  },
  {
    "objectID": "appendix/index.html",
    "href": "appendix/index.html",
    "title": "Appendix",
    "section": "",
    "text": "Welcome to extra stuff at the end of this book."
  },
  {
    "objectID": "appendix/date_formatting.html",
    "href": "appendix/date_formatting.html",
    "title": "22Â  Gain full control of date formatting",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport datetime\nfrom datetime import timedelta\nimport seaborn as sns\nsns.set(style=\"ticks\", font_scale=1.5)\nimport matplotlib.gridspec as gridspec\nfrom matplotlib.dates import DateFormatter\nimport matplotlib.dates as mdates\nimport matplotlib.ticker as ticker\n\n\nimport pandas as pd\n\nstart_date = '2018-01-01'\nend_date = '2018-04-30'\n\n# create date range with 1-hour intervals\ndates = pd.date_range(start_date, end_date, freq='1H')\n# create a random variable to plot\nvar = np.random.randint(low=-10, high=11, size=len(dates)).cumsum()\nvar = var - var.min()\n# create dataframe, make \"date\" the index\ndf = pd.DataFrame({'date': dates, 'variable': var})\ndf.set_index(df['date'], inplace=True)\ndf\n\n\n\n\n\n  \n    \n      \n      date\n      variable\n    \n    \n      date\n      \n      \n    \n  \n  \n    \n      2018-01-01 00:00:00\n      2018-01-01 00:00:00\n      856\n    \n    \n      2018-01-01 01:00:00\n      2018-01-01 01:00:00\n      863\n    \n    \n      2018-01-01 02:00:00\n      2018-01-01 02:00:00\n      867\n    \n    \n      2018-01-01 03:00:00\n      2018-01-01 03:00:00\n      874\n    \n    \n      2018-01-01 04:00:00\n      2018-01-01 04:00:00\n      864\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      2018-04-29 20:00:00\n      2018-04-29 20:00:00\n      20\n    \n    \n      2018-04-29 21:00:00\n      2018-04-29 21:00:00\n      20\n    \n    \n      2018-04-29 22:00:00\n      2018-04-29 22:00:00\n      27\n    \n    \n      2018-04-29 23:00:00\n      2018-04-29 23:00:00\n      23\n    \n    \n      2018-04-30 00:00:00\n      2018-04-30 00:00:00\n      32\n    \n  \n\n2857 rows Ã— 2 columns\n\n\n\ndefine a useful function to plot the graphs below\n\ndef explanation(ax, text, letter):\n    ax.text(0.99, 0.97, text,\n            transform=ax.transAxes,\n            horizontalalignment='right', verticalalignment='top',\n            fontweight=\"bold\")\n    ax.text(0.01, 0.01, letter,\n            transform=ax.transAxes,\n            horizontalalignment='left', verticalalignment='bottom',\n            fontweight=\"bold\")\n    ax.set(ylabel=\"variable (units)\")\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n\n\nfig, ax = plt.subplots(1, 1, figsize=(8, 6))\nax.plot(df['variable'])\nplt.gcf().autofmt_xdate()  # makes slated dates\nexplanation(ax, \"slanted dates\", \"\")\nfig.savefig(\"dates1.png\")\n\n\n\n\n\nfig, ax = plt.subplots(4, 1, figsize=(10, 16),\n                       gridspec_kw={'hspace': 0.3})\n\n### plot a ###\nax[0].plot(df['variable'])\ndate_form = DateFormatter(\"%b\")\nax[0].xaxis.set_major_locator(mdates.MonthLocator(interval=2))\nax[0].xaxis.set_major_formatter(date_form)\n\n### plot b ###\nax[1].plot(df['variable'])\ndate_form = DateFormatter(\"%B\")\nax[1].xaxis.set_major_locator(mdates.MonthLocator(interval=1))\nax[1].xaxis.set_major_formatter(date_form)\n\n### plot c ###\nax[2].plot(df['variable'])\nax[2].xaxis.set_major_locator(mdates.MonthLocator())\n# 16 is a slight approximation for the center, since months differ in number of days.\nax[2].xaxis.set_minor_locator(mdates.MonthLocator(bymonthday=16))\nax[2].xaxis.set_major_formatter(ticker.NullFormatter())\nax[2].xaxis.set_minor_formatter(DateFormatter('%B'))\nfor tick in ax[2].xaxis.get_minor_ticks():\n    tick.tick1line.set_markersize(0)\n    tick.tick2line.set_markersize(0)\n    tick.label1.set_horizontalalignment('center')\n\n### plot d ###\nax[3].plot(df['variable'])\ndate_form = DateFormatter(\"%d %b\")\nax[3].xaxis.set_major_locator(mdates.DayLocator(interval=15))\nax[3].xaxis.set_major_formatter(date_form)\n\nexplanation(ax[0], \"month abbreviations, every 2 months\", \"a\")\nexplanation(ax[1], \"full month names\", \"b\")\nexplanation(ax[2], \"full month names centered between the 1st of the month\", \"c\")\nexplanation(ax[3], \"day + month abbr. --- every 15 days\", \"d\")\n\nfig.savefig(\"dates2.png\")\n\n\n\n\n\nfig, ax = plt.subplots(4, 1, figsize=(10, 16),\n                       gridspec_kw={'hspace': 0.3})\n\n### plot e ###\nax[0].plot(df['variable'])\ndate_form = DateFormatter(\"%d/%m\")\nax[0].xaxis.set_major_locator(mdates.DayLocator(bymonthday=[5, 20]))\nax[0].xaxis.set_major_formatter(date_form)\n\n### plot f ###\nax[1].plot(df['variable'])\nlocator = mdates.AutoDateLocator(minticks=11, maxticks=17)\nformatter = mdates.ConciseDateFormatter(locator)\nax[1].xaxis.set_major_locator(locator)\nax[1].xaxis.set_major_formatter(formatter)\n\n### plot g ###\nax[2].plot(df.loc['2018-01-01':'2018-03-01', 'variable'])\nlocator = mdates.AutoDateLocator(minticks=6, maxticks=14)\nformatter = mdates.ConciseDateFormatter(locator)\nax[2].xaxis.set_major_locator(locator)\nax[2].xaxis.set_major_formatter(formatter)\n\n### plot h ###\nax[3].plot(df.loc['2018-01-01':'2018-01-02', 'variable'])\nlocator = mdates.AutoDateLocator(minticks=6, maxticks=10)\nformatter = mdates.ConciseDateFormatter(locator)\nax[3].xaxis.set_major_locator(locator)\nax[3].xaxis.set_major_formatter(formatter)\n\nexplanation(ax[0], \"exactly on days 05 and 20 of each month\", \"e\")\nexplanation(ax[1], \"ConciseDateFormatter\", \"f\")\nexplanation(ax[2], \"ConciseDateFormatter\", \"g\")\nexplanation(ax[3], \"ConciseDateFormatter\", \"h\")\n\nfig.savefig(\"dates3.png\")\n\n\n\n\n\nfig, ax = plt.subplots(1, 1, figsize=(10, 4),\n                       gridspec_kw={'hspace': 0.3})\n\n# import constants for the days of the week\nfrom matplotlib.dates import MO, TU, WE, TH, FR, SA, SU\nax.plot(df['variable'])\n# tick on sundays every third week\nloc = mdates.WeekdayLocator(byweekday=SU, interval=3)\nax.xaxis.set_major_locator(loc)\ndate_form = DateFormatter(\"%a, %b %d\")\nax.xaxis.set_major_formatter(date_form)\nfig.autofmt_xdate(bottom=0.2, rotation=30, ha='right')\nexplanation(ax, \"every 3 Sundays, rotate labels\", \"\")\n\n\n\n\n\n\n\nCode\nExplanation\n\n\n\n\n%Y\n4-digit year (e.g., 2022)\n\n\n%y\n2-digit year (e.g., 22)\n\n\n%m\n2-digit month (e.g., 12)\n\n\n%B\nFull month name (e.g., December)\n\n\n%b\nAbbreviated month name (e.g., Dec)\n\n\n%d\n2-digit day of the month (e.g., 09)\n\n\n%A\nFull weekday name (e.g., Tuesday)\n\n\n%a\nAbbreviated weekday name (e.g., Tue)\n\n\n%H\n24-hour clock hour (e.g., 23)\n\n\n%I\n12-hour clock hour (e.g., 11)\n\n\n%M\n2-digit minute (e.g., 59)\n\n\n%S\n2-digit second (e.g., 59)\n\n\n%p\nâ€œAMâ€ or â€œPMâ€\n\n\n%Z\nTime zone name\n\n\n%z\nTime zone offset from UTC (e.g., -0500)"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "23Â  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\nThis is Yair making changes to summary."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Brutsaert, Wilfried. 2005. Hydrology: An Introduction.\nCambridge University Press.\n\n\nDingman, S. L. 2015. Physical Hydrology. 3rd edition. Waveland\nPress, Incorporated.\n\n\ndreamstime. 2022. â€œWorld Map of AFRICA.â€\nDreamstime. https://www.dreamstime.com/world-map-africa-egypt-libya-ethiopia-arabia-mauritania-nigeria-somalia-namibia-tanzania-madagascar-geographic-xxl-chart-image154799901.\n\n\nFiona Bruce. 2015. â€œA Family Holiday in Lake Malawi: Zen and the\nArt of Paddleboarding.â€ The Telegraph. https://twitter.com/hallaboutafrica/status/1203419359303159809?s=20&t=SkH17UkWrNcXzIqRF0ic_A.\n\n\nleddris. 2010. â€œRainfall Seasonality.â€ Land and\nEcosystem Degradation and Desertification Response Information\nSystem. http://leddris.aegean.gr/ses-parameters/293-rainfall-seasonality.html#:~:text=Rainfall%20seasonality%20index%20is%20a,in%20relation%20to%20water%20availability.\n\n\nMargulis, Steve. 2019. â€œIntroduction to Hydrology. eBook.â€\nhttps://margulis-group.github.io/textbook/.\n\n\nRaymond, Lyle S. Jr. 1988. â€œWhat Is Groundwater?â€\nCornell eCommons. https://ecommons.cornell.edu/handle/1813/3408.\n\n\nSuma Groulx. 2015. â€œWater Infiltration.â€ Suma\nGroulx. http://sumagroulx.com/water-infiltration/.\n\n\nValentÃ­ Rodellas. 1988. â€œEvaluating Submarine Groundwater\nDischarge to the Mediterranean Sea by Using Radium Isotopes.â€\nResearch Gate. https://www.researchgate.net/figure/Principal-pathways-for-submarine-groundwater-discharge-to-the-coastal-ocean-including_fig1_274590439.\n\n\nWalsh, RPD, and DM Lawler. 1981. â€œRainfall Seasonality:\nDescription, Spatial Patterns and Change Through Time.â€\nWeather 36 (7): 201â€“8. https://doi.org/10.1002/j.1477-8696.1981.tb05400.x.\n\n\nWater Science School. 2018. â€œWhere Is Earthâ€™s Water?â€\nU.S. Geological Survey. https://www.usgs.gov/special-topics/water-science-school/science/where-earths-water.\n\n\nâ€”â€”â€”. 2019a. â€œConceptual Groundwater-Flow Diagram.â€ U.S.\nGeological Survey. https://www.usgs.gov/media/images/conceptual-groundwater-flow-diagram.\n\n\nâ€”â€”â€”. 2019b. â€œGroundwater Is the Area Underground Where Openings\nAre Full of Water.â€ U.S. Geological Survey. https://www.usgs.gov/media/images/groundwater-area-underground-where-openings-are-full-water.\n\n\nâ€”â€”â€”. 2019c. â€œHow Much Water Is There on Earth?â€ U.S.\nGeological Survey. https://www.usgs.gov/special-topics/water-science-school/science/how-much-water-there-earth.\n\n\nâ€”â€”â€”. 2019d. â€œIce, Snow, and Glaciers and the Water Cycle.â€\nU.S. Geological Survey. https://www.usgs.gov/special-topics/water-science-school/science/ice-snow-and-glaciers-and-water-cycle.\n\n\nâ€”â€”â€”. 2019e. â€œPrecipitation and the Water Cycle.â€ U.S.\nGeological Survey. https://www.usgs.gov/special-topics/water-science-school/science/precipitation-and-water-cycle.\n\n\nâ€”â€”â€”. 2019f. â€œRain and Precipitation.â€ U.S. Geological\nSurvey. https://www.usgs.gov/special-topics/water-science-school/science/rain-and-precipitation.\n\n\nâ€”â€”â€”. 2019g. â€œThe Natural Water Cycle.â€ U.S. Geological\nSurvey. https://www.usgs.gov/media/images/natural-water-cycle-jpg.\n\n\nâ€”â€”â€”. 2022. â€œThe Water Cycle.â€ U.S. Geological\nSurvey. https://www.usgs.gov/media/images/water-cycle-png.\n\n\n×—×“×©×•×ª ×¤×ª×— ×ª×§×•×•×”. 2020. â€œ××•×‘×š ×•××¢×¨×›×ª ×’×©××™× ×›×‘×“×” × ×•×¡×¤×ª.â€\nMelabes. https://www.melabes.co.il/news/51773."
  }
]