[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Surface Hydrology",
    "section": "",
    "text": "About\nWelcome to Surface Hydrology (71630) at the Hebrew University of Jerusalem. This is Yair Mau, your host for today. I am a senior lecturer at the Institute of Environmental Sciences, at the Faculty of Agriculture, Food and Environment, in Rehovot, Israel.\nThis website contains (almost) all the material you’ll need for the course. If you find any mistakes, or have any comments, please email me.",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "index.html#syllabus",
    "href": "index.html#syllabus",
    "title": "Surface Hydrology",
    "section": "Syllabus",
    "text": "Syllabus\n\nCourse description\nThis is an introductory course in Surface Hydrology, dealing with some of the major processes in the hydrologic cycle: precipitation, evaporation and transpiration, infiltration, runoff generation and streamflow. The different topics will be treated using mathematical models and practical programming exercises.\n\n\nCourse aims\nThe course aims at giving the students a quantitative understanding of the main processes in the hydrologic cycle. We will characterize the hydrologic cycle and its fluxes through mass balance equations. The random nature of the various processes will be studied with statistics, time series analysis, return periods, extreme value distributions, etc. We will take a “hands-on approach”, where students will actively engage with the material by analysing data and writing models using Python.\n\n\nLearning outcomes\nOn successful completion of this module, students should be able to:\n\nIdentify the various components of hydrologic budget and their interdependency.\nDescribe the various processes in hydrology (precipitation, infiltration, evaporation, etc) in a mathematical language.\nWrite computer code to analyze the statistics of hydrologic fluxes, and construct models of hydrological systems.\n\n\n\nBooks and other sources\n\nDingman, S. L. (2015). Physical hydrology (3rd edition). Waveland press.\nWard, A. D., & Trimble, S. W. (2003). Environmental hydrology. CRC Press.\nBrutsaert, W. (2005). Hydrology: An Introduction. Cambridge University Press.\n\n\n\nCourse evaluation\nThere will be some small projects during the semester, all worth 50% of the grade. A final and larger project (50% of the grade) will be due at the end of the semester. All projects will be done in Python (on Jupyter Notebooks).",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "introduction/introduction-lecture.html",
    "href": "introduction/introduction-lecture.html",
    "title": "1  Water Cycle: Fluxes and Storage",
    "section": "",
    "text": "1.1 How much water is there? Where?",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Water Cycle: Fluxes and Storage</span>"
    ]
  },
  {
    "objectID": "introduction/introduction-lecture.html#how-much-water-is-there-where",
    "href": "introduction/introduction-lecture.html#how-much-water-is-there-where",
    "title": "1  Water Cycle: Fluxes and Storage",
    "section": "",
    "text": "Source: Water Science School (2019c)\n\n\n\n\n\nSource: Water Science School (2018)",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Water Cycle: Fluxes and Storage</span>"
    ]
  },
  {
    "objectID": "introduction/introduction-lecture.html#the-natural-water-cycle-2019",
    "href": "introduction/introduction-lecture.html#the-natural-water-cycle-2019",
    "title": "1  Water Cycle: Fluxes and Storage",
    "section": "1.2 The natural water cycle (2019)",
    "text": "1.2 The natural water cycle (2019)\n\n\n\nSource: Water Science School (2019g)",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Water Cycle: Fluxes and Storage</span>"
    ]
  },
  {
    "objectID": "introduction/introduction-lecture.html#the-new-water-cycle-2022",
    "href": "introduction/introduction-lecture.html#the-new-water-cycle-2022",
    "title": "1  Water Cycle: Fluxes and Storage",
    "section": "1.3 The new water cycle (2022)",
    "text": "1.3 The new water cycle (2022)\n\n\n\nSource: Water Science School (2022)\n\n\nInteractive chart: Pools and fluxes in the water cycle",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Water Cycle: Fluxes and Storage</span>"
    ]
  },
  {
    "objectID": "introduction/introduction-lecture.html#global-water-distribution",
    "href": "introduction/introduction-lecture.html#global-water-distribution",
    "title": "1  Water Cycle: Fluxes and Storage",
    "section": "1.4 Global water distribution",
    "text": "1.4 Global water distribution\n\nSource: Water Science School (2018). (Percents are rounded, so will not add to 100)\n\n\n\n\n\n\n\n\nWater source\nVolume (km^3)\n% of freshwater\n% of total water\n\n\n\n\nOceans, Seas, & Bays\n1,338,000,000\n–\n96.54\n\n\nIce caps, Glaciers, & Permanent Snow\n24,064,000\n68.7\n1.74\n\n\nGroundwater\n23,400,000\n–\n1.69\n\n\n\\quadFresh\n10,530,000\n30.1\n0.76\n\n\n\\quadSaline\n12,870,000\n–\n0.93\n\n\nSoil Moisture\n16,500\n0.05\n0.001\n\n\nGround Ice & Permafrost\n300,000\n0.86\n0.022\n\n\nLakes\n176,400\n–\n0.013\n\n\n\\quadFresh\n91,000\n0.26\n0.007\n\n\n\\quadSaline\n85,400\n–\n0.006\n\n\nAtmosphere\n12,900\n0.04\n0.001\n\n\nSwamp Water\n11,470\n0.03\n0.0008\n\n\nRivers\n2,120\n0.006\n0.0002\n\n\nBiological Water\n1,120\n0.003\n0.0001",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Water Cycle: Fluxes and Storage</span>"
    ]
  },
  {
    "objectID": "introduction/introduction-lecture.html#energy-drives-the-hydrologic-cycle",
    "href": "introduction/introduction-lecture.html#energy-drives-the-hydrologic-cycle",
    "title": "1  Water Cycle: Fluxes and Storage",
    "section": "1.5 Energy drives the hydrologic cycle",
    "text": "1.5 Energy drives the hydrologic cycle\nFrom Margulis (2019)\n\nA key aspect of the hydrologic cycle is the fact that it is driven by energy inputs (primarily from the sun). At the global scale, the system is essentially closed with respect to water; negligible water is entering or leaving the system. In other words, there is no external forcing in terms of a water flux. Systems with no external forcing will generally eventually come to an equilibrium state. So what makes the hydrologic cycle so dynamic? The solar radiative energy input, which is external to the system, drives the hydrologic cycle. Averaged over the globe, 342 W m^{-2} of solar radiative energy is being continuously input to the system at the top of the atmosphere. This energy input must be dissipated, and this is done, to a large extent, via the hydrologic cycle. Due to this fact, the study of hydrology is not isolated to the study of water storage and movement, but also must often include study of energy storage and movements.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Water Cycle: Fluxes and Storage</span>"
    ]
  },
  {
    "objectID": "introduction/introduction-lecture.html#components-of-the-water-cycle",
    "href": "introduction/introduction-lecture.html#components-of-the-water-cycle",
    "title": "1  Water Cycle: Fluxes and Storage",
    "section": "1.6 Components of the water cycle",
    "text": "1.6 Components of the water cycle\n\n1.6.1 Water storage in oceans\n\n\n1.6.2 Evaporation / Sublimation\nEvaporation \\longrightarrow cooling\n\n\n\n  \n\n\n1.6.3 Evapotranspiration\n\n\n\n1.6.4 Water storage in the atmosphere\nCumulonimbus cloud over Africa \nPicture of cumulonimbus taken from the International Space Station, over western Africa near the Senegal-Mali border.\nIf all of the water in the atmosphere rained down at once, it would only cover the globe to a depth of 2.5 centimeters. \n\\begin{split}\n\\text{amount of water in the atmosphere} & \\qquad V = 12\\, 900\\, \\text{km}^3 \\\\\n\\text{surface of Earth} & \\qquad S = 4 \\pi R^2;\\quad R=6371\\,\\text{km}\\\\\n& \\qquad V = S \\times h \\\\\n\\text{height} & \\qquad h = \\frac{V}{S} \\simeq 2.5\\,\\text{cm}\n\\end{split}\n\nTry to calculate this yourself, and click on the button below to check how to do it.\n\n\nShow/hide the code\n# amount of water in the atmosphere\nV = 12900 # km^3\n# Earth's radius\nR = 6371 # km\n# surface of Earth = 4 pi Rˆ2\nS = 4 * 3.141592 * R**2\n# Volume: V = S * h, therefore\n# height\nh = V / S # in km\nh_cm = h * 1e5 # in cm\nprint(f\"The height would be ~ {h_cm:.1f} cm\")\n\n\nThe height would be ~ 2.5 cm\n\n\n\n\n1.6.5 Condensation\n\n\n1.6.6 Precipitation\n\n\n\nSource: Water Science School (2019f)\n\n\n\nSource: Water Science School (2019e)\n\n\n\n\n\n\n\n\n\n\nIntensity (cm/h)\nMedian diameter (mm)\nVelocity of fall (m/s)\nDrops s^{-1} m^{-2}\n\n\n\n\nFog\n0.013\n0.01\n0.003\n67,425,000\n\n\nMist\n0.005\n0.1\n0.21\n27,000\n\n\nDrizzle\n0.025\n0.96\n4.1\n151\n\n\nLight rain\n0.10\n1.24\n4.8\n280\n\n\nModerate rain\n0.38\n1.60\n5.7\n495\n\n\nHeavy rain\n1.52\n2.05\n6.7\n495\n\n\nExcessive rain\n4.06\n2.40\n7.3\n818\n\n\nCloudburst\n10.2\n2.85\n7.9\n1,220\n\n\n\n\n\n1.6.7 Water storage in ice and snow\n\n\n\nSource: Water Science School (2019d)\n\n\n\n\n\nSource: Water Science School (2019d)\n\n\n\n\n1.6.8 Snowmelt runoff to streams\n\n\n1.6.9 Surface runoff\n\n\n\nSource: חדשות פתח תקווה (2020)\n\n\n\n\n\n1.6.10 Streamflow\nThe Mississippi river basin is very large \nThe Amazon river basin is Huge \n\n\n\nSource: Yair Mau\n\n\n\n\n1.6.11 Lakes and rivers\n\n\n\nSource: dreamstime (2022)\n\n\nLake Malawi \n\n\n\nSource: Fiona Bruce (2015)\n\n\n\n\n1.6.12 Infiltration\n\n\n\nSource: Suma Groulx (2015)\n\n\n\n\n1.6.13 Groundwater storage\n\n\n\nSource: Water Science School (2019b)\n\n\n\n\n\nSource: Andrew Amelinckx (2015)\n\n\n\n\n\nSource: Kbh3rd (2009)\n\n\nCenter Pivot irrigation in Nebraska taps the Ogallala Aquifer. \n\n\n1.6.14 Groundwater flow and discharge\n\n\n\nSource: Water Science School (2019a)\n\n\n\n\n\nSource: Raymond, Lyle S. Jr. (1988)\n\n\n\n\n\nSource: Valentí Rodellas (1988)\n\n\n\n\n1.6.15 Spring\nEin Gedi \nThousand Springs, Idaho \n\n\n\n\nAmazon Waters. 2022. “Amazon Waters.” Amazon Waters. https://amazonwaters.org/basins.\n\n\nAndrew Amelinckx. 2015. “Even Without a Drought, We’re Depleting Groundwater at an Alarming Pace.” Modern Farmer. https://modernfarmer.com/2015/07/ogallala-aquifer-depletion/.\n\n\ndreamstime. 2022. “World Map of AFRICA.” Dreamstime. https://www.dreamstime.com/world-map-africa-egypt-libya-ethiopia-arabia-mauritania-nigeria-somalia-namibia-tanzania-madagascar-geographic-xxl-chart-image154799901.\n\n\nFiona Bruce. 2015. “A Family Holiday in Lake Malawi: Zen and the Art of Paddleboarding.” The Telegraph. https://twitter.com/hallaboutafrica/status/1203419359303159809?s=20&t=SkH17UkWrNcXzIqRF0ic_A.\n\n\nJames Hall. 2019. “Lake Malawi.” Twitter. https://twitter.com/hallaboutafrica/status/1203419359303159809?s=20&t=SkH17UkWrNcXzIqRF0ic_A.\n\n\nKbh3rd. 2009. “High Plains Fresh Groundwater Usage 2000.” Wikimedia. https://commons.wikimedia.org/wiki/File:High_plains_fresh_groundwater_usage_2000.svg.\n\n\nMargulis, Steve. 2019. “Introduction to Hydrology. eBook.” https://margulis-group.github.io/textbook/.\n\n\nMarty Friedlander. 2015. “Natural Springs of Israel: Seven Cool Watering Holes to Visit This Summer.” Haaretz. https://www.haaretz.com/israel-news/travel/seven-cool-natural-springs-of-israel-1.5388627.\n\n\nNational Park Service. 2022. “Mississippi River Facts.” National Park Service. https://www.nps.gov/miss/riverfacts.htm.\n\n\nNatural Attractions. 2014. “Ogallala Aquifer.” Nebraska Education on Location. https://nebraskaeducationonlocation.org/natural-attractions/ogallala-aquifer/.\n\n\nRaymond, Lyle S. Jr. 1988. “What Is Groundwater?” Cornell eCommons. https://ecommons.cornell.edu/handle/1813/3408.\n\n\nSuma Groulx. 2015. “Water Infiltration.” Suma Groulx. http://sumagroulx.com/water-infiltration/.\n\n\nValentí Rodellas. 1988. “Evaluating Submarine Groundwater Discharge to the Mediterranean Sea by Using Radium Isotopes.” Research Gate. https://www.researchgate.net/figure/Principal-pathways-for-submarine-groundwater-discharge-to-the-coastal-ocean-including_fig1_274590439.\n\n\nWater Science School. 2016. “Water Flowing Underground Can Find Openings Back to the Land Surface.” U.S. Geological Survey. https://www.usgs.gov/media/images/water-flowing-underground-can-find-openings-back-land-surface.\n\n\n———. 2018. “Where Is Earth’s Water?” U.S. Geological Survey. https://www.usgs.gov/special-topics/water-science-school/science/where-earths-water.\n\n\n———. 2019a. “Conceptual Groundwater-Flow Diagram.” U.S. Geological Survey. https://www.usgs.gov/media/images/conceptual-groundwater-flow-diagram.\n\n\n———. 2019b. “Groundwater Is the Area Underground Where Openings Are Full of Water.” U.S. Geological Survey. https://www.usgs.gov/media/images/groundwater-area-underground-where-openings-are-full-water.\n\n\n———. 2019c. “How Much Water Is There on Earth?” U.S. Geological Survey. https://www.usgs.gov/special-topics/water-science-school/science/how-much-water-there-earth.\n\n\n———. 2019d. “Ice, Snow, and Glaciers and the Water Cycle.” U.S. Geological Survey. https://www.usgs.gov/special-topics/water-science-school/science/ice-snow-and-glaciers-and-water-cycle.\n\n\n———. 2019e. “Precipitation and the Water Cycle.” U.S. Geological Survey. https://www.usgs.gov/special-topics/water-science-school/science/precipitation-and-water-cycle.\n\n\n———. 2019f. “Rain and Precipitation.” U.S. Geological Survey. https://www.usgs.gov/special-topics/water-science-school/science/rain-and-precipitation.\n\n\n———. 2019g. “The Natural Water Cycle.” U.S. Geological Survey. https://www.usgs.gov/media/images/natural-water-cycle-jpg.\n\n\n———. 2022. “The Water Cycle.” U.S. Geological Survey. https://www.usgs.gov/media/images/water-cycle-png.\n\n\nחדשות פתח תקווה. 2020. “אובך ומערכת גשמים כבדה נוספת.” Melabes. https://www.melabes.co.il/news/51773.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Water Cycle: Fluxes and Storage</span>"
    ]
  },
  {
    "objectID": "introduction/introduction-exercises.html",
    "href": "introduction/introduction-exercises.html",
    "title": "2  Exercises",
    "section": "",
    "text": "2.1 download the data\nlet’s have fun plotting some data 😀",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "introduction/introduction-exercises.html#download-the-data",
    "href": "introduction/introduction-exercises.html#download-the-data",
    "title": "2  Exercises",
    "section": "",
    "text": "Go to the Faculty of Agriculture’s weather station.\nClick on משיכת נתונים and download data for 1 September 2020 to 28 February 2021, with a 24h interval. Call it data-sep2020-feb2021\nOpen the .csv file with Excel, see how it looks like\nIf you can’t download the data, just click here.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "introduction/introduction-exercises.html#import-packages",
    "href": "introduction/introduction-exercises.html#import-packages",
    "title": "2  Exercises",
    "section": "2.2 import packages",
    "text": "2.2 import packages\nWe need to import this data into python. First we import useful packages. Type (don’t copy and paste) the following lines in the code cell below.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_theme(style=\"ticks\", font_scale=1.5)",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "introduction/introduction-exercises.html#import-data-with-pandas",
    "href": "introduction/introduction-exercises.html#import-data-with-pandas",
    "title": "2  Exercises",
    "section": "2.3 import data with pandas",
    "text": "2.3 import data with pandas\nImport data from csv and put it in a pandas dataframe (a table). Make line 5 the header (column names)\n\ndf = pd.read_csv(\"data-sep2020-feb2021.csv\",\n                 skiprows=4,\n                 encoding='latin1',\n                 )\ndf\n\n\n\n\n\n\n\n\nUnnamed: 0\n°C\n°C.1\nkm/h\nmm\nmm.1\n\n\n\n\n0\n01/09/20\n32.8\n25.3\n29.7\n0.0\n0.0\n\n\n1\n02/09/20\n33.0\n24.0\n28.8\n0.0\n0.0\n\n\n2\n03/09/20\n34.2\n23.8\n31.6\n0.0\n0.0\n\n\n3\n04/09/20\n36.3\n27.3\n24.2\n0.0\n0.0\n\n\n4\n05/09/20\n34.2\n26.3\n22.4\n0.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n176\n24/02/21\n20.6\n9.9\n28.8\n0.0\n481.7\n\n\n177\n25/02/21\n19.4\n9.3\n23.3\n0.0\n481.7\n\n\n178\n26/02/21\n21.3\n8.0\n24.2\n0.1\n481.8\n\n\n179\n27/02/21\n23.4\n9.2\n30.6\n0.0\n481.8\n\n\n180\n28/02/21\n19.7\n9.2\n22.4\n0.0\n481.8\n\n\n\n\n181 rows × 6 columns",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "introduction/introduction-exercises.html#rename-columns",
    "href": "introduction/introduction-exercises.html#rename-columns",
    "title": "2  Exercises",
    "section": "2.4 rename columns",
    "text": "2.4 rename columns\nrename the columns to:\ndate, tmax, tmin, wind, rain24h, rain_cumulative\n\ndf.columns = ['date', 'tmax', 'tmin', 'wind', 'rain24h', 'rain_cumulative']\ndf\n\n\n\n\n\n\n\n\ndate\ntmax\ntmin\nwind\nrain24h\nrain_cumulative\n\n\n\n\n0\n01/09/20\n32.8\n25.3\n29.7\n0.0\n0.0\n\n\n1\n02/09/20\n33.0\n24.0\n28.8\n0.0\n0.0\n\n\n2\n03/09/20\n34.2\n23.8\n31.6\n0.0\n0.0\n\n\n3\n04/09/20\n36.3\n27.3\n24.2\n0.0\n0.0\n\n\n4\n05/09/20\n34.2\n26.3\n22.4\n0.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n176\n24/02/21\n20.6\n9.9\n28.8\n0.0\n481.7\n\n\n177\n25/02/21\n19.4\n9.3\n23.3\n0.0\n481.7\n\n\n178\n26/02/21\n21.3\n8.0\n24.2\n0.1\n481.8\n\n\n179\n27/02/21\n23.4\n9.2\n30.6\n0.0\n481.8\n\n\n180\n28/02/21\n19.7\n9.2\n22.4\n0.0\n481.8\n\n\n\n\n181 rows × 6 columns",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "introduction/introduction-exercises.html#a-first-plot",
    "href": "introduction/introduction-exercises.html#a-first-plot",
    "title": "2  Exercises",
    "section": "2.5 a first plot!",
    "text": "2.5 a first plot!\nplot the minimum temperature:\n\nplt.plot(df['tmin'])",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "introduction/introduction-exercises.html#how-to-deal-with-dates",
    "href": "introduction/introduction-exercises.html#how-to-deal-with-dates",
    "title": "2  Exercises",
    "section": "2.6 how to deal with dates",
    "text": "2.6 how to deal with dates\nWe want the dates to appear on the horizontal axis.\nInterpret ‘date’ column as a pandas datetime, see how it looks different from before\nbefore: 01/09/20\nafter: 2020-09-01\n\ndf['date'] = pd.to_datetime(df['date'], dayfirst=True)\ndf\n\n\n\n\n\n\n\n\ndate\ntmax\ntmin\nwind\nrain24h\nrain_cumulative\n\n\n\n\n0\n2020-09-01\n32.8\n25.3\n29.7\n0.0\n0.0\n\n\n1\n2020-09-02\n33.0\n24.0\n28.8\n0.0\n0.0\n\n\n2\n2020-09-03\n34.2\n23.8\n31.6\n0.0\n0.0\n\n\n3\n2020-09-04\n36.3\n27.3\n24.2\n0.0\n0.0\n\n\n4\n2020-09-05\n34.2\n26.3\n22.4\n0.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n176\n2021-02-24\n20.6\n9.9\n28.8\n0.0\n481.7\n\n\n177\n2021-02-25\n19.4\n9.3\n23.3\n0.0\n481.7\n\n\n178\n2021-02-26\n21.3\n8.0\n24.2\n0.1\n481.8\n\n\n179\n2021-02-27\n23.4\n9.2\n30.6\n0.0\n481.8\n\n\n180\n2021-02-28\n19.7\n9.2\n22.4\n0.0\n481.8\n\n\n\n\n181 rows × 6 columns\n\n\n\n\n2.6.1 date as dataframe index\nMake ‘date’ the dataframe’s index (leftmost column, but not really a column!)\n\ndf = df.set_index('date')\ndf\n\n\n\n\n\n\n\n\ntmax\ntmin\nwind\nrain24h\nrain_cumulative\n\n\ndate\n\n\n\n\n\n\n\n\n\n2020-09-01\n32.8\n25.3\n29.7\n0.0\n0.0\n\n\n2020-09-02\n33.0\n24.0\n28.8\n0.0\n0.0\n\n\n2020-09-03\n34.2\n23.8\n31.6\n0.0\n0.0\n\n\n2020-09-04\n36.3\n27.3\n24.2\n0.0\n0.0\n\n\n2020-09-05\n34.2\n26.3\n22.4\n0.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n\n\n2021-02-24\n20.6\n9.9\n28.8\n0.0\n481.7\n\n\n2021-02-25\n19.4\n9.3\n23.3\n0.0\n481.7\n\n\n2021-02-26\n21.3\n8.0\n24.2\n0.1\n481.8\n\n\n2021-02-27\n23.4\n9.2\n30.6\n0.0\n481.8\n\n\n2021-02-28\n19.7\n9.2\n22.4\n0.0\n481.8\n\n\n\n\n181 rows × 5 columns",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "introduction/introduction-exercises.html#plot-again-now-with-dates",
    "href": "introduction/introduction-exercises.html#plot-again-now-with-dates",
    "title": "2  Exercises",
    "section": "2.7 plot again, now with dates",
    "text": "2.7 plot again, now with dates\nPlot minimum temperature, now we have dates on the horizontal axis\n\nplt.plot(df['tmin'])",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "introduction/introduction-exercises.html#were-getting-there-the-graph-could-look-better",
    "href": "introduction/introduction-exercises.html#were-getting-there-the-graph-could-look-better",
    "title": "2  Exercises",
    "section": "2.8 we’re getting there! the graph could look better",
    "text": "2.8 we’re getting there! the graph could look better\nLet’s make the graph look better: labels, title, slanted dates, etc\n\n# creates figure (the canvas) and the axis (rectangle where the plot sits)\nfig, ax = plt.subplots(1, figsize=(10,7))\n# two line plots\nax.plot(df['tmax'], color=\"coral\", label=\"Temp (max)\")\nax.plot(df['tmin'], color=\"dodgerblue\", label=\"Temp (min)\")\n# axes labels and figure title\nax.set_xlabel('date')\nax.set_ylabel('temperature (°C)')\nax.set_title('maximum and minimum temperatures')\n# some ticks adjustments\nax.set_yticks(np.arange(0,45,5))  # we can choose where to put ticks\nax.grid(axis='y')         # makes horizontal lines\nplt.gcf().autofmt_xdate()  # makes slanted dates\n# legend\nax.legend(loc='upper right')\n# save png figure\nplt.savefig(\"temp_max_min.png\")",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "introduction/introduction-exercises.html#make-the-following-figure",
    "href": "introduction/introduction-exercises.html#make-the-following-figure",
    "title": "2  Exercises",
    "section": "2.9 make the following figure",
    "text": "2.9 make the following figure\nUse the following function to plot bars for daily rainfall\nax.bar(x_array, y_array)\nCan you write yourself some lines of code that calculate the cumulative rainfall from the daily rainfall?\n\n\nShow the code\n# creates figure (the canvas) and the axis (rectangle where the plot sits)\nfig, ax = plt.subplots(1, figsize=(10,7))\n\n# line and bar plots\nax.bar(df.index, df['rain24h'], color=\"mediumblue\", label=\"daily rainfall\")\n\n# there are many ways of calculating the cumulative rain\n\n# method 1, use a for loop:\n# rain = df['rain24h'].to_numpy()\n# cumulative = rain * 0\n# for i in range(len(rain)):\n#     cumulative[i] = np.sum(rain[:i])\n# df['cumulative1'] = cumulative\n\n# method 2, use list comprehension:\n# rain = df['rain24h'].to_numpy()\n# cumulative = [np.sum(rain[:i]) for i in range(len(rain))]\n# df['cumulative2'] = cumulative\n\n# method 3, use existing functions:\ndf['cumulative3'] = np.cumsum(df['rain24h'])\n\nax.plot(df['cumulative3'], color=\"deepskyblue\", label=\"cumulative rainfall\")\n# compare our cumulative rainfall with the downloaded data\n# ax.plot(df['rain_cumulative'], 'x')\n# axes labels and figure title\nax.set(xlabel='date',\n       ylabel='rainfall (mm)',\n       title='daily and cumulative rainfall',\n       xlim=pd.to_datetime(['2020-11-01','2021-02-28'])\n      )\n# some ticks adjustments\nplt.gcf().autofmt_xdate()  # makes slanted dates\n# legend\nax.legend(loc='upper left', frameon=False)\n# save png figure\nplt.savefig(\"cumulative_rainfall.png\")",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "introduction/introduction-exercises.html#make-another-figure",
    "href": "introduction/introduction-exercises.html#make-another-figure",
    "title": "2  Exercises",
    "section": "2.10 make another figure",
    "text": "2.10 make another figure\nIn order to choose just a part of the time series, you can use the following:\nstart_date = '2021-01-01'\nend_date = '2021-01-31'\njanuary = df[start_date:end_date]\n\n\nShow the code\n# creates figure (the canvas) and the axis (rectangle where the plot sits)\nfig, ax = plt.subplots(1, figsize=(10,7))\n# define date range\nstart_date = '2021-01-01'\nend_date = '2021-01-31'\njanuary = df.loc[start_date:end_date, 'tmax']\n# plots\nax.plot(january, color=\"darkgoldenrod\", label=\"daily max\")\nax.plot(january*0 + january.mean(), color=\"gold\", linestyle=\"--\", label=\"average daily max\")\n# axes labels and figure title\nax.set_xlabel('date')\nax.set_ylabel('temperature (°C)')\nax.set_title('average daily maximum temperature for January 2021')\n# some ticks adjustments\nplt.gcf().autofmt_xdate()  # makes slanted dates\n# legend\nax.legend(loc='upper right', frameon=False)\n# save png figure\nplt.savefig(\"average_max_temp.png\")",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "introduction/introduction-exercises.html#one-last-figure-for-today",
    "href": "introduction/introduction-exercises.html#one-last-figure-for-today",
    "title": "2  Exercises",
    "section": "2.11 one last figure for today",
    "text": "2.11 one last figure for today\nUse the following code to create histograms with user-defined bins:\nb = np.arange(0, 56, 5)  # bins from 0 to 55, width = 5\nax.hist(df['wind'], bins=b, density=True)\nPlay with the bins, see what happens. What does density=True do?\n\n# creates figure (the canvas) and the axis (rectangle where the plot sits)\nfig, ax = plt.subplots(1, figsize=(10,7))\n# histogram\nb = np.arange(0, 56, 5)  # bins from 0 to 55, width = 5\nax.hist(df['wind'], bins=b, density=True)\n# axes labels and figure title\nax.set(xlabel='max wind speed (km/h)',\n       ylabel='frequency',\n       title='frequency of maximum wind speed'\n      )\n# save png figure\nplt.savefig(\"wind-histogram.png\")",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "introduction/introduction-exercises.html#homework",
    "href": "introduction/introduction-exercises.html#homework",
    "title": "2  Exercises",
    "section": "2.12 homework",
    "text": "2.12 homework\nGo back to the weather station website, download one year of data from 01.01.2020 to 31.12.2020 (24h data). If you can’t download the data, just click here.\n\n2.12.1 graph 1\nMake one graph with the following:\n\ndaily tmax and tmin\nsmoothed data for tmax and tmin\n\nIn order to smooth the data with a 30 day window, use the following function:\ndf['tmin'].rolling(30, center=True).mean()\nThis means that you will take the mean of 30 days, and put the result in the center of this 30-day window.\nPlay with this function, see what you can do with it. What happens when you change the size of the window? Why is the smoothed data shorter than the original data? See the documentation for rolling to find more options.\n\n\nShow the code\nfig, ax = plt.subplots(figsize=(10,7))\ncol_names = ['date', 'tmax', 'tmin', 'wind', 'rain24h', 'rain_cumulative']\ndf2 = pd.read_csv(\"1year.csv\",\n                  skiprows=5,\n                  encoding='latin1',\n                  names=col_names,\n                  parse_dates=['date'],\n                  dayfirst=True,\n                  index_col='date'\n                 )\ntmin_smooth = df2['tmin'].rolling('30D', center=True).mean()\ntmax_smooth = df2['tmax'].rolling(30, center=True).mean()\nax.plot(df2['tmax'], label='tmax', color=\"coral\")\nax.plot(tmax_smooth, label='tmax smoothed', color=\"crimson\", linestyle=\"--\", linewidth=3)\nax.plot(df2['tmin'], label='tmin', color=\"dodgerblue\")\nax.plot(tmin_smooth, label='tmin smoothed', color=\"navy\", linestyle=\"--\", linewidth=3)\nax.legend(frameon=False)\nax.set(ylabel='temperature (°C)',\n       title='maximum and minimum daily temperatures, Rehovot'\n      )\nplt.savefig(\"t_smoothed.png\")\n\n\n\n\n\n\n\n\n\n\n\n2.12.2 graph 2\nMake another graph that focuses on a part of the year, not the whole thing. We saw before how to do that. Put on this graph two lines, representing two variables of your choosing. Give these lines good colors, and maybe different linestyles (solid, dashed, dotted) if you feel fancy.\n\n\n2.12.3 graph 3\nChoose another variable, and make two histograms (each in its own panel), each representing a different time interval. Here is an example how you make subplots:\n\n\nShow the code\nfig, (ax1, ax2) = plt.subplots(2, 1)\nN = 10\nax1.plot(np.random.random(N))\nax2.plot(np.random.random(N))\nax1.set(ylabel='variable A (units)',\n        title='title A'\n       )\nax2.set(ylabel='variable B (units)',\n        # title='title B'\n       )\n\n\n\n\n\n\n\n\n\nOf course, I plotted random data as a line plot, your task is to plot histograms instead.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "precipitation/precipitation.html",
    "href": "precipitation/precipitation.html",
    "title": "Precipitation",
    "section": "",
    "text": "Here are some of the files we’ll use in this module, in case you can’t download them from their original repositories.\n\nBEN_GURION_monthly.csv\nBEER_SHEVA_monthly.csv\nEilat_daily.csv",
    "crumbs": [
      "Precipitation"
    ]
  },
  {
    "objectID": "precipitation/intra-annual-lecture.html",
    "href": "precipitation/intra-annual-lecture.html",
    "title": "3  Intra-annual variability of precipitation",
    "section": "",
    "text": "3.1 hydrological year\nThe hydrological year is time period of 12 months for which precipitation totals are measured. The hydrological year is designated by the calendar year in which it ends.\nIn temperate regions with distinct seasonal patterns, the hydrological year often starts in the fall, when precipitation and streamflow are typically at their lowest levels. This timing ensures that most of the surface runoff during the water year is attributable to the precipitation that fell during the same period.\nLet’s define the hydrological year for Tel Aviv from 1 October to 30 September.\nהאם אקלים הגשם שלנו משתנה\nWe will now shift the months according to Tel Aviv’s hydrological year.\nplot rainfall distribution according to Tel Aviv’s hydrological year\nfig, ax = plt.subplots(figsize=(10,7))\nNroll = 3  # number of months to roll\nroll_telaviv = np.roll(monthly_telaviv['PRCP'], Nroll)\nroll_london = np.roll(monthly_london['PRCP'], Nroll)\nroll_months = np.roll(monthly_london.index, Nroll)\n# bar plots\nax.bar(monthly_london.index, roll_london,\n        alpha=0.5, color=\"blue\", label=f\"London ({monthly_london.values.sum():.0f} mm per year)\")\nax.bar(monthly_telaviv.index, roll_telaviv,\n        alpha=0.5, color=\"red\", width=0.5, label=f\"Tel Aviv ({monthly_telaviv.values.sum():.0f} mm per year)\")\n\n# axes labels and figure title\nax.set(xlabel='month',\n       ylabel='monthly rainfall average (mm)',\n       title='seasonality of two cities with similar yearly rainfall',\n       xticks=monthly_london.index,\n       xticklabels=roll_months\n      )\nax.legend(loc='upper right', frameon=False);\n\n# save figure\n# plt.savefig(\"monthly_tel_aviv_london_bars.png\")\nAnother way of representing this data is with polar coordinates:\nplot in polar coordinates\nfig = plt.figure(figsize=(10,10))\n\n# radar chart\nax = fig.add_subplot(111, polar=True)     # make polar plot\nax.set_theta_zero_location(\"N\")           # January on top (\"N\"orth)\nax.set_theta_direction(-1)                # clockwise direction\nax.set_rlabel_position(90)                # radial labels on the right\nax.set_rticks([50,100])                   # two radial ticks is enough\nax.set_rlim(0,150)                        # limits of r axis\nangles=np.linspace(0, 2*np.pi, 12, endpoint=False)       # divide circle into 12 slices\nangles=np.append(angles, angles[0])                      # close loop, otherwise lines will be open\nmonth_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\nax.set_thetagrids(angles[:-1] * 180/np.pi, month_names)  # relabel angles with month names\n\n# plot london data\nstats_london = np.array(monthly_london['PRCP'].values)        # get london data\nstats_london = np.append(stats_london, stats_london[0])            # close loop\nax.plot(angles, stats_london, \"o-\", color='blue', label=\"london\")  # plot line\nax.fill(angles, stats_london, alpha=0.25, color='blue')            # fill\n\n# plot tel aviv data\nstats_telaviv = np.array(monthly_telaviv['PRCP'].values)        # get tel aviv data\nstats_telaviv = np.append(stats_telaviv, stats_telaviv[0])           # close loop\nax.plot(angles, stats_telaviv, \"o-\", color='red', label=\"tel aviv\")  # plot line\nax.fill(angles, stats_telaviv, alpha=0.25, color='red')              # fill\n\nax.set_title(\"Monthly rainfall averages\")\nax.legend(loc=(-0.1,0.9));  # legend at x=-0.2 so it doesn't overlap with graph\n\n# save figure\n# plt.savefig(\"radar_chart_tel_aviv_london.png\")",
    "crumbs": [
      "Precipitation",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Intra-annual variability of precipitation</span>"
    ]
  },
  {
    "objectID": "precipitation/intra-annual-lecture.html#seasonality-index",
    "href": "precipitation/intra-annual-lecture.html#seasonality-index",
    "title": "3  Intra-annual variability of precipitation",
    "section": "3.2 Seasonality Index",
    "text": "3.2 Seasonality Index\nSources: leddris (2010), Walsh and Lawler (1981)\n\\langle{P}\\rangle= mean annual precipitation\nm_i= precipitation mean for month i\n\nSI = \\displaystyle \\frac{1}{\\langle{P}\\rangle} \\sum_{n=1}^{n=12} \\left| m_i - \\frac{\\langle{P}\\rangle}{12} \\right|\n\n\n\n\n\n\n\n\nSI\nPrecipitation Regime\n\n\n\n\n&lt;0.19\nPrecipitation spread throughout the year\n\n\n0.20-0.39\nPrecipitation spread throughout the year, but with a definite wetter season\n\n\n0.40-0.59\nRather seasonal with a short dry season\n\n\n0.60-0.79\nSeasonal\n\n\n0.80-0.99\nMarked seasonal with a long dry season\n\n\n1.00-1.19\nMost precipitation in &lt;3 months\n\n\n\nLet’s write some code to calculate the SI for Tel Aviv and London.\n\n\nShow/hide the code\ndef walsh_index(df):\n    m = df[\"PRCP\"].values\n    R = m.sum()\n    SI = np.sum(np.abs(m-R/12)) / R\n    return SI\n\nlondon_index = walsh_index(monthly_london)\ntelaviv_index = walsh_index(monthly_telaviv)\nprint(\"Seasonality index (Walsh and Lawler, 1981)\")\nprint(f\"London: {london_index:.2f}\")\nprint(f\"Tel Aviv: {telaviv_index:.2f}\")\n\n\nSeasonality index (Walsh and Lawler, 1981)\nLondon: 0.13\nTel Aviv: 1.00\n\n\n\n\nShow the code\nfig, ax = plt.subplots(figsize=(10,7))\n\nplt.rcParams['hatch.linewidth'] = 3\nroll_telaviv\nxlim = [1, 13]\ntotal_telaviv = np.sum(roll_telaviv)\nax.plot(xlim, [total_telaviv/12]*2, color=\"tab:blue\", linewidth=3)\nax.set_xlim(xlim)\n\nshaded = roll_telaviv - total_telaviv/12\nmonths = monthly_telaviv.index\nax.bar(months, shaded,\n       alpha=0.9, color=\"None\", width=1,\n       hatch=\"//\", edgecolor='k',\n       align='edge', bottom=total_telaviv/12,\n       label=f\"absolute difference\")\n\nax.bar(months, roll_telaviv,\n       alpha=0.5, color=\"red\", width=1,\n       align='edge',\n       label=f\"total rainfall\", zorder=0)\n\nax.text(5.3, 86.5, r\"SI$=1.00=$\", fontsize=20)\nax.text(xlim[-1], total_telaviv/12, \" mean\", va=\"center\")\nax.plot([7.8, 12.8], [89.5]*2, color=\"black\", lw=2)\n# axes labels and figure title\nax.set(xlabel='month',\n       ylabel='monthly rainfall average (mm)',\n       title='Walsh and Lawler (1981) Seasonality Index; Tel Aviv',\n       xticks=np.arange(1.5,12.6,1),\n       xticklabels=roll_months,\n      )\n\nplt.legend(loc='upper right', frameon=False, bbox_to_anchor=(1, 0.7),\n           fontsize=18);\n\n# save figure\n# plt.savefig(\"si_walsh_telaviv.png\")\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nfig, ax = plt.subplots(figsize=(10,7))\n\nplt.rcParams['hatch.linewidth'] = 3\nxlim = [1, 13]\ntotal_london = np.sum(roll_london)\nax.plot(xlim, [total_london/12]*2, color=\"tab:blue\", linewidth=3)\nax.set_xlim(xlim)\n\nshaded = roll_london - total_london/12\nmonths = monthly_london.index\nax.bar(months, shaded,\n       alpha=0.9, color=\"None\", width=1,\n       hatch=\"//\", edgecolor='k',\n       align='edge', bottom=total_london/12,\n       label=f\"absolute difference\")\n\nax.bar(months, roll_london,\n       alpha=0.5, color=\"red\", width=1,\n       align='edge',\n       label=f\"total rainfall\", zorder=0)\n\n\nax.text(5.3, 74, r\"SI$=0.13=$\", fontsize=20)\nax.text(xlim[-1], total_london/12, \" mean\", va=\"center\")\nax.plot([7.8, 12.8], [75.5]*2, color=\"black\", lw=2)\n# axes labels and figure title\nax.set(xlabel='month',\n       ylabel='monthly rainfall average (mm)',\n       title='Walsh and Lawler (1981) Seasonality Index; London',\n       xticks=np.arange(1.5,12.6,1),\n       xticklabels=roll_months,\n       ylim=[0,83],\n      )\n\nplt.legend(loc='upper right', frameon=False, bbox_to_anchor=(1, 1.005),\n           fontsize=18);\n\n# save figure\n# plt.savefig(\"si_walsh_telaviv.png\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n What is greatest possible value for the Walsh and Lawler seasonality index?\n\n\n\n\n\nThis must be the case when all the rainfall in concentrated in only one month of the year.\n\n\ncalculation\n\nWithout loss of generality, assume that all the rain in the year (P) is in January: m_1=P and m_i=0 for other months.\n\n\\begin{split}\nSI &= \\frac{1}{P} \\sum_{n=1}^{n=12} \\left| m_i - \\frac{\\langle{P}\\rangle}{12} \\right| \\\\\n   &= \\frac{1}{P} \\left| P - \\frac{P}{12}  \\right| + \\frac{1}{P} \\sum_{n=2}^{n=12} \\left| 0 - \\frac{P}{12} \\right| \\\\\n   &= \\frac{11}{12} + 11\\cdot \\frac{1}{12} \\\\\n   &= \\frac{11}{6} \\\\\n   &= 1.83\n\\end{split}\n\n\n\n\n\n\n\n\n\n\n\n Can you think of a better seasonality index?\n\n\n\n\n\nThink of possible problems with Walsh and Lawler’s index, then try to fix them :)\n\n\n\n\n\n\n\n\n\n What would happen to the index value if we were to randomly shuffle the months?\n\n\n\n\n\n\n\n\n\n\n\n\n\nleddris. 2010. “Rainfall Seasonality.” Land and Ecosystem Degradation and Desertification Response Information System. http://leddris.aegean.gr/ses-parameters/293-rainfall-seasonality.html#:~:text=Rainfall%20seasonality%20index%20is%20a,in%20relation%20to%20water%20availability.\n\n\nWalsh, RPD, and DM Lawler. 1981. “Rainfall Seasonality: Description, Spatial Patterns and Change Through Time.” Weather 36 (7): 201–8. https://doi.org/10.1002/j.1477-8696.1981.tb05400.x.",
    "crumbs": [
      "Precipitation",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Intra-annual variability of precipitation</span>"
    ]
  },
  {
    "objectID": "precipitation/intra-annual-exercises.html",
    "href": "precipitation/intra-annual-exercises.html",
    "title": "4  Exercises",
    "section": "",
    "text": "4.1 intra-annual variability\nImport relevant packages\nGo to NOAA’s National Centers for Environmental Information (NCEI)\nClimate Data Online: Dataset Discovery\nFind station codes in this map. On the left, click on the little wrench (🔧) next to “Global Summary of the Month”, then click on “identify” on the panel that just opened, and click on a station (purple circle). You will see the station’s name, it’s ID, and the period of record. For example, for Ben-Gurion’s Airport in Israel:\nBEN GURION, IS\nSTATION ID: ISM00040180\nPeriod of Record: 1951-01-01 to 2020-03-01\nYou can download daily or monthly data for each station. Use the function below to download this data to your computer.\nIf everything fails and you need easy access to the files we’ll be using today, click here:\nBen Gurion, Beer Sheva.\ndef download_data(station_name, station_code):\n    url_daily = 'https://www.ncei.noaa.gov/data/global-historical-climatology-network-daily/access/'\n    url_monthly = 'https://www.ncei.noaa.gov/data/gsom/access/'\n    # download daily data - uncomment the next 2 lines to make this work\n    # urllib.request.urlretrieve(url_daily + station_code + '.csv',\n    #                            station_name + '_daily.csv')\n    # download monthly data\n    urllib.request.urlretrieve(url_monthly + station_code + '.csv',\n                               station_name + '_monthly.csv')\nNow, choose any station with a period of record longer than 30 years, and download its data:\nLoad the data into a datafram, and before you continue with the analysis, plot the rainfall data, to see how it looks like.\ndownload_data('BEN_GURION', 'ISM00040180')\ndf = pd.read_csv('BEN_GURION_monthly.csv', sep=\",\")\n# make 'DATE' the dataframe index\ndf['DATE'] = pd.to_datetime(df['DATE'])\ndf = df.set_index('DATE')\nplt.plot(df['PRCP']);\nIt doesn’t look great for Ben-Gurion airport, lots of missing data! You might need to choose another station…\nDownload data for Beer Sheva, ID IS000051690.\ndownload_data('BEER_SHEVA', 'IS000051690')\ndf = pd.read_csv('BEER_SHEVA_monthly.csv', sep=\",\")\n# make 'DATE' the dataframe index\ndf['DATE'] = pd.to_datetime(df['DATE'])\ndf = df.set_index('DATE')\nplt.plot(df['PRCP']);\nThat’s much better! We need to aggregate all data from each month, so we can calculate monthly averages. How to do that?\ngroup_by_month = df['PRCP'].groupby(df.index.month)\ndf_beersheva = (group_by_month\n                  .mean()\n                  .to_frame()\n               )\ndf_beersheva = df_beersheva.reset_index()\ndf_beersheva.columns = ['month number', 'monthly rainfall (mm)']\ndf_beersheva\n\n\n\n\n\n\n\n\nmonth number\nmonthly rainfall (mm)\n\n\n\n\n0\n1\n48.743158\n\n\n1\n2\n37.347368\n\n\n2\n3\n26.551579\n\n\n3\n4\n9.038947\n\n\n4\n5\n2.735789\n\n\n5\n6\n0.013830\n\n\n6\n7\n0.000000\n\n\n7\n8\n0.002128\n\n\n8\n9\n0.271277\n\n\n9\n10\n6.669474\n\n\n10\n11\n21.850526\n\n\n11\n12\n41.786316\ngroupby is a very powerful tool, but it takes some time to get used to it. We usually make operations on the groupby object like this:\nIf you try to see the object group_by_month you won’t see anything. This object waits for further instructions to be useful. Another way of understanding what’s going on with this operation is to see with our eyes one of the groups:\nIf you want to calculate the same averages using a loop instead of groupby, then you can do the following:\n# choose only the precipitation column\ndf_month = df['PRCP']\n# calculate monthly mean\nmonthly_mean = np.array([])  # empty array\nmonth_numbers = np.arange(1,13)\n\nfor m in month_numbers:      # cycle over months (1, 2, 3, etc)\n    this_month_all_indices = (df_month.index.month == m)       # indices in df_month belonging to month m\n    this_month_mean = df_month[this_month_all_indices].mean()  # this is the monthly mean\n    monthly_mean = np.append(monthly_mean, this_month_mean)    # append\n\ndf_beersheva = pd.DataFrame({'monthly rainfall (mm)':monthly_mean,\n                             'month number':month_numbers\n                            })\ndf_beersheva\n\n\n\n\n\n\n\n\nmonthly rainfall (mm)\nmonth number\n\n\n\n\n0\n48.743158\n1\n\n\n1\n37.347368\n2\n\n\n2\n26.551579\n3\n\n\n3\n9.038947\n4\n\n\n4\n2.735789\n5\n\n\n5\n0.013830\n6\n\n\n6\n0.000000\n7\n\n\n7\n0.002128\n8\n\n\n8\n0.271277\n9\n\n\n9\n6.669474\n10\n\n\n10\n21.850526\n11\n\n\n11\n41.786316\n12\nPlot the data and see if it makes sense. Try to get a figure like this one.\nfig, ax = plt.subplots(figsize=(10,7))\nax.bar(df_beersheva['month number'], df_beersheva['monthly rainfall (mm)'])\nax.set(xlabel=\"months\",\n       ylabel=\"monthly average (mm)\",\n       title=\"Beer Sheva\",\n       xticks=df_beersheva['month number'],\n       xticklabels=df_beersheva['month number']);\n# plt.savefig(\"beersheva_monthly_average.png\")\nLet’s calculate now the Walsh and Lawler Seasonality Index: leddris (2010), Walsh and Lawler (1981).\nWrite a function that receives a dataframe like the one we have just created, and returns the seasonality index.\nR= mean annual precipitation\nm_i= precipitation mean for month i\nSI = \\displaystyle \\frac{1}{R} \\sum_{n=1}^{n=12} \\left| m_i - \\frac{R}{12} \\right|\nShow the code\ndef walsh_index(df):\n    mi = df[\"monthly rainfall (mm)\"]\n    R = df[\"monthly rainfall (mm)\"].sum()\n    SI = np.sum(np.abs(mi - R/12)) / R\n    return SI\nbeersheva_SI = walsh_index(df_beersheva)\nprint(f\"Beer Sheva, SI = {beersheva_SI:.2f}\")\n\n\nBeer Sheva, SI = 0.97",
    "crumbs": [
      "Precipitation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "precipitation/intra-annual-exercises.html#intra-annual-variability",
    "href": "precipitation/intra-annual-exercises.html#intra-annual-variability",
    "title": "4  Exercises",
    "section": "",
    "text": "The code above is an example of an API (Application Programming Interface). An API is a set of rules and protocols that allows different software applications to communicate and interact with each other. It acts as an intermediary layer that enables data transmission between different systems or components in a standardized way. For example, when you use a mobile app to book a ride, the app communicates with the ride-sharing service’s systems through their API to request and receive data about available drivers, pricing, and booking details.\n\n\ndownload_data('BEN_GURION', 'ISM00040180')\n\n\n\n\nALWAYS look at your data to see if it looks good.\nNEVER mindlessly run code on data you don’t know to be good.\n^\\starOf course, if you have a lot of data, you can’t look at it with your eyes, and smart methods can be devised to increase the chances that everything is alright.\n\n\n\n\n\n\ndf_beersheva = (df['PRCP']\n                  .groupby(df.index.month)\n                  .mean()\n                  .to_frame()\n               )\n\ngroup_by_month.get_group(3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSI\nPrecipitation Regime\n\n\n\n\n&lt;0.19\nPrecipitation spread throughout the year\n\n\n0.20-0.39\nPrecipitation spread throughout the year, but with a definite wetter season\n\n\n0.40-0.59\nRather seasonal with a short dry season\n\n\n0.60-0.79\nSeasonal\n\n\n0.80-0.99\nMarked seasonal with a long dry season\n\n\n1.00-1.19\nMost precipitation in &lt; 3 months\n\n\n\n\n\n\n\n\nleddris. 2010. “Rainfall Seasonality.” Land and Ecosystem Degradation and Desertification Response Information System. http://leddris.aegean.gr/ses-parameters/293-rainfall-seasonality.html#:~:text=Rainfall%20seasonality%20index%20is%20a,in%20relation%20to%20water%20availability.\n\n\nWalsh, RPD, and DM Lawler. 1981. “Rainfall Seasonality: Description, Spatial Patterns and Change Through Time.” Weather 36 (7): 201–8. https://doi.org/10.1002/j.1477-8696.1981.tb05400.x.",
    "crumbs": [
      "Precipitation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "precipitation/interannual-lecture.html",
    "href": "precipitation/interannual-lecture.html",
    "title": "5  Interannual variability of precipitation",
    "section": "",
    "text": "5.1 coefficient of variation\nLet’s aggregate (resample) precipitation according to the hydrological year.\n\\langle{P}\\rangle= average precipitation\n\\sigma= standard deviation\nCV = \\frac{\\sigma}{\\langle{P}\\rangle}\nThe coefficient of variation (dimensionless) quantifies the variation (std) magnitude with respect to the mean. In the examples above, although Tel Aviv has a much higher standard deviation in annual precipitation, the spread of precipitation in Eilat is much larger, considered relative to its average.\nShow the code\nprint(f\"Tel Aviv:\\tstd = {std_telaviv:.2f} mm\\t\\tCV = {cv_telaviv:.2f}\")\nprint(f\"Eilat:\\t\\tstd = {std_eilat:.2f} mm\\t\\tCV = {cv_eilat:.2f}\")\n\n\nTel Aviv:   std = 161.19 mm     CV = 0.30\nEilat:      std = 20.49 mm      CV = 0.77\nAnother way to understand the CV: for gaussian (normal) distributions, 67% of the data lies 1 std from the mean. Assuming that the annual rainfall for Tel Aviv and Eilat roughly follows a gaussian distribution, we could say that:",
    "crumbs": [
      "Precipitation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Interannual variability of precipitation</span>"
    ]
  },
  {
    "objectID": "precipitation/interannual-lecture.html#coefficient-of-variation",
    "href": "precipitation/interannual-lecture.html#coefficient-of-variation",
    "title": "5  Interannual variability of precipitation",
    "section": "",
    "text": "Tel Aviv: about 67% of the annual precipitation is no more than 30% from the average.\nEilat: about 67% of the annual precipitation is no more than 77% from the average.",
    "crumbs": [
      "Precipitation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Interannual variability of precipitation</span>"
    ]
  },
  {
    "objectID": "precipitation/interannual-lecture.html#climate-normals",
    "href": "precipitation/interannual-lecture.html#climate-normals",
    "title": "5  Interannual variability of precipitation",
    "section": "5.2 climate normals",
    "text": "5.2 climate normals\nPrecipitation averages are usually calculated for time intervals of 30 years. According to the National Oceanic and Atmospheric Administration — NOAA:\n\nNormals serve two purposes: a reference period for monitoring current weather and climate, and a good description of the expected climate at a location over the seasons. They provide a basis for determining whether today’s weather is warmer or colder, wetter or drier. They also can be used to plan for conditions beyond the time span of reliable weather forecasts. A 30-year time period was chosen by the governing body of international meteorology in the 1930s, so the first normals were for 1901-1930, the longest period for which most countries had reliable climate records. International normals were called for in 1931-1960 and 1961-1990, but many countries updated normals more frequently, every 10 years, so as to keep them up to date. In 2015 this was made the WMO standard, so all countries will be creating normals for 1991-2020.",
    "crumbs": [
      "Precipitation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Interannual variability of precipitation</span>"
    ]
  },
  {
    "objectID": "precipitation/interannual-lecture.html#running-averages",
    "href": "precipitation/interannual-lecture.html#running-averages",
    "title": "5  Interannual variability of precipitation",
    "section": "5.3 running averages",
    "text": "5.3 running averages\n\n\nplot 30-year averages\nfig, ax = plt.subplots(figsize=(10,7))\n\nax.plot(df_year['rain (mm)'], color=\"lightgray\")\n\n# windows of length 30 years\nwindows = [[1940,1969], [1970,1999]]\nfor window in windows:\n    start_date = f\"{window[0]:d}-09-30\"\n    end_date = f\"{window[1]:d}-09-30\"\n    window_mean = df_year['rain (mm)'][start_date:end_date].mean()\n    ax.plot(df_year[start_date:end_date]*0+window_mean, color=\"purple\", linewidth=3)\n    ax.text(start_date, window_mean+5, f\"{window[0]} to {window[1]}:  {window_mean:.0f} mm\",)\n\n# plot mean\nrain_mean = df_year['rain (mm)'].mean()\nax.plot(df_year*0 + rain_mean, linewidth=3, color=\"tab:orange\", alpha=0.5)\nax.text(df_year.index[-1], rain_mean, \" mean\".format(rain_mean),\n        horizontalalignment=\"left\", verticalalignment=\"center\",\n        color=\"tab:orange\", alpha=0.5)\n\n# adjust labels, ticks, title, limits, etc\nax.set(title=\"Annual precipitation averages in Tel Aviv, 1940–1999\",\n       xlabel=\"date\",\n       ylabel=\"annual precipitation (mm)\",\n       xlim=[df_year.index[0], df_year.index[-1]],\n       ylim=[0, 1100],\n      );\n\n# save figure\n# plt.savefig(\"mean_tel_aviv_2_windows.png\")\n\n\n\n\n\n\n\n\n\n\n\nplot 30-year averages\nfig, ax = plt.subplots(figsize=(10,7))\n\n# windows of length 30 years\nwindows = [[x,x+29] for x in [1940,1950,1960,1970]]\nfor window in windows:\n    start_date = f\"{window[0]:d}-09-30\"\n    end_date = f\"{window[1]:d}-09-30\"\n    window_mean = df_year['rain (mm)'][start_date:end_date].mean()\n    ax.plot(df_year[start_date:end_date]*0+window_mean, color=\"purple\", linewidth=3)\n    ax.text(start_date, window_mean+0.5, f\"{window[0]} to {window[1]}:  {window_mean:.0f} mm\",)\n\n# plot mean\nrain_mean = df_year['rain (mm)'].mean()\nax.plot(df_year*0 + rain_mean, linewidth=3, color=\"tab:orange\", alpha=0.5)\nax.text(df_year.index[-1], rain_mean, \" mean\".format(rain_mean),\n        horizontalalignment=\"left\", verticalalignment=\"center\",\n        color=\"tab:orange\", alpha=0.5)\n\n# adjust labels, ticks, title, limits, etc\nax.set(title=\"Annual precipitation averages in Tel Aviv, 1940–1999\",\n       xlabel=\"date\",\n       ylabel=\"annual precipitation (mm)\",\n       xlim=[df_year.index[0], df_year.index[-1]],\n       ylim=[500, 560],\n      );\n\n# save figure\n# plt.savefig(\"mean_tel_aviv_2_windows.png\")\n\n\n\n\n\n\n\n\n\n\n\nwidget for rolling average\nimport altair as alt\n\n# Custom theme for readability\ndef readable():   \n    return {\n        \"config\" : {\n             \"title\": {'fontSize': 16},\n             \"axis\": {\n                  \"labelFontSize\": 16,\n                  \"titleFontSize\": 16,\n             },\n             \"header\": {\n                  \"labelFontSize\": 14,\n                  \"titleFontSize\": 14,\n             },\n             \"legend\": {\n                  \"labelFontSize\": 14,\n                  \"titleFontSize\": 14,\n             },\n             \"mark\": {\n                 'fontSize': 14,\n                 \"tooltip\": {\"content\": \"encoding\"},  # enable tooltips\n            },\n        }\n    }\n\nalt.themes.register('readable', readable)\nalt.themes.enable('readable')\n\n# Altair only recognizes column data; it ignores index values. You can plot the index data by first resetting the index\nsource = df_year.reset_index()\nbrush = alt.selection_interval(encodings=['x'])\n\n# T: temporal, a time or date value\n# Q: quantitative, a continuous real-valued quantity\n# https://altair-viz.github.io/user_guide/encoding.html#encoding-data-types\nbars = alt.Chart().mark_bar().encode(\n    x=alt.X('DATE:T', axis=alt.Axis(title='date')),\n    y=alt.Y('rain (mm):Q',  axis=alt.Axis(title='annual precipitation (mm) and average')),\n    opacity=alt.condition(brush, alt.OpacityValue(1), alt.OpacityValue(0.2)),\n).add_params(\n    brush\n).properties(\n    title='Select year range and drag for rolling average of annual precipitation in Tel Aviv'\n).properties(\n    width=600,\n    height=400\n)\n\nline = alt.Chart().mark_rule(color='orange').encode(\n    y='mean(rain (mm)):Q',\n    size=alt.SizeValue(3)\n).transform_filter(\n    brush\n)\n\nalt.layer(bars, line, data=source)\n\n\n\n\n\n\n\n\n\n\nplot rolling average\nfig, ax = plt.subplots(figsize=(10,7))\n\nax.plot(df_year['rain (mm)'], color=\"lightgray\")\n\n# plot rolling mean\nrolling_mean = df_year.rolling(window=30, center=True).mean()\nax.plot(rolling_mean, linewidth=3, color=\"purple\", zorder=5)\nax.text(pd.to_datetime(\"1970\"), 450, \"rolling mean\".format(rain_mean),\n        horizontalalignment=\"left\", verticalalignment=\"center\",\n        color=\"purple\",)\n\n# plot mean\nax.plot(df_year*0 + rain_mean, linewidth=3, color=\"tab:orange\", alpha=0.5)\nax.text(df_year.index[-1], rain_mean, \" mean\".format(rain_mean),\n        horizontalalignment=\"left\", verticalalignment=\"center\",\n        color=\"tab:orange\", alpha=0.5);\n\nax.set(title=\"30-year rolling average, Tel Aviv\",\n       xlabel=\"date\",\n       ylabel=\"annual precipitation (mm)\",\n       ylim=[0, 1100],\n       xlim=[df_year.index[0], df_year.index[-1]]\n      );\n# save figure\n# plt.savefig(\"rolling_average_tel_aviv.png\")",
    "crumbs": [
      "Precipitation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Interannual variability of precipitation</span>"
    ]
  },
  {
    "objectID": "precipitation/interannual-exercises.html",
    "href": "precipitation/interannual-exercises.html",
    "title": "6  Exercises",
    "section": "",
    "text": "Import relevant packages\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_theme(style=\"ticks\", font_scale=1.5)\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\n\nPlot monthly rainfall for your station.\nLoad the data into a dataframe, and before you continue with the analysis, plot the rainfall data, to see how it looks like.\n\ndf = pd.read_csv('BEER_SHEVA_monthly.csv', sep=\",\")\n# make 'DATE' the dataframe index\ndf['DATE'] = pd.to_datetime(df['DATE'])\ndf = df.set_index('DATE')\n\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,7))\nax1.plot(df['PRCP'])\nax2.plot(df['PRCP']['2010-07-01':'2015-07-01'])\n\n\n\n\n\n\n\n\nHow to aggregate rainfall accoding to the hydrological year? We use the function resample.\nread more about resampling options:\nhttps://pandas.pydata.org/docs/user_guide/timeseries.html#offset-aliases\nalso, annual resampling can be anchored to the end of specific months: https://pandas.pydata.org/docs/user_guide/timeseries.html#anchored-offsets\n\n# annual frequency, anchored 31 December\ndf_year_all = df['PRCP'].resample('YE').sum().to_frame()\n# annual frequency, anchored 01 January\ndf_year_all = df['PRCP'].resample('YS').sum().to_frame()\n# annual frequency, anchored end of September\ndf_year_all = df['PRCP'].resample('YE-SEP').sum().to_frame()\n# rename 'PRCP' column to 'rain (mm)'\ndf_year_all.columns = ['rain (mm)']\ndf_year_all\n\n\n\n\n\n\n\n\nrain (mm)\n\n\nDATE\n\n\n\n\n\n1922-09-30\n136.6\n\n\n1923-09-30\n144.5\n\n\n1924-09-30\n130.4\n\n\n1925-09-30\n165.3\n\n\n1926-09-30\n188.7\n\n\n...\n...\n\n\n2012-09-30\n145.7\n\n\n2013-09-30\n175.3\n\n\n2014-09-30\n259.2\n\n\n2015-09-30\n249.3\n\n\n2016-09-30\n257.6\n\n\n\n\n95 rows × 1 columns\n\n\n\nYou might need to exclude the first or the last line, since their data might have less that 12 months. For example:\n\n# exclude 1st row\ndf_year = df_year_all.iloc[1:]\n# exclude last row\ndf_year = df_year_all.iloc[:-1]\n# exclude both 1st and last rows\ndf_year = df_year_all.iloc[1:-1]\ndf_year\n\n\n\n\n\n\n\n\nrain (mm)\n\n\nDATE\n\n\n\n\n\n1923-09-30\n144.5\n\n\n1924-09-30\n130.4\n\n\n1925-09-30\n165.3\n\n\n1926-09-30\n188.7\n\n\n1927-09-30\n130.2\n\n\n...\n...\n\n\n2011-09-30\n151.6\n\n\n2012-09-30\n145.7\n\n\n2013-09-30\n175.3\n\n\n2014-09-30\n259.2\n\n\n2015-09-30\n249.3\n\n\n\n\n93 rows × 1 columns\n\n\n\nCalculate the average annual rainfall. Plot annual rainfall for the whole range, together with the average. You should get something like this:\n\nfig, ax = plt.subplots(figsize=(10,7))\n\n# plot YEARLY precipitation\nax.bar(df_year.index, df_year['rain (mm)'],\n       width=365, align='edge', color=\"tab:blue\")\n\n# plot mean\nrain_mean = df_year['rain (mm)'].mean()\nax.plot(ax.get_xlim(), [rain_mean]*2, linewidth=3, color=\"tab:orange\")\nax.set(xlabel=\"date\",\n       ylabel=\"yearly rainfall (mm)\",\n       title=f\"Beer Sheva, mean = {rain_mean:.0f} mm\");\n# save figure\n# plt.savefig(\"beersheva_yearly_rainfall_1923_2016.png\")\n\n\n\n\n\n\n\n\nPlot a histogram of annual rainfall, with the mean and standard deviation. Calculate the coefficient of variation. Try to plot something like this:\n\nfig, ax = plt.subplots(figsize=(10,7))\n\n# calculate mean, standard deviation, CV\nrain_mean = df_year['rain (mm)'].mean()\nrain_std = df_year['rain (mm)'].std()\nCV = rain_std/rain_mean\n# plot histogram\nb = np.arange(0, 401, 50)  # bins from 0 to 400, width = 50\nax.hist(df_year['rain (mm)'], bins=b)\n\n# plot vertical lines with mean, std, etc\nylim = np.array(ax.get_ylim())\nylim[1] = ylim[1]*1.1\nax.plot([rain_mean]*2, ylim, linewidth=3, color=\"tab:orange\")\nax.plot([rain_mean+rain_std]*2, ylim, linewidth=3, linestyle=\"--\", color=\"tab:olive\")\nax.plot([rain_mean-rain_std]*2, ylim, linewidth=3, linestyle=\"--\", color=\"tab:olive\")\nax.set(ylim=ylim,\n       xlabel=\"annual rainfall (mm)\",\n       ylabel=\"number of years\",\n       title=f\"Beer Sheva, 1922–2016. Mean={rain_mean:.0f} mm, STD={rain_std:.0f} mm\")\nax.text(300, 25, f\"CV = {CV:.2f}\")\n# plt.savefig(\"histogram_beersheva.png\")\n\nText(300, 25, 'CV = 0.33')\n\n\n\n\n\n\n\n\n\nCalculate the mean annual rainfall for various 30-year intervals\n\n####### the hard way #######\n# fig, ax = plt.subplots(figsize=(10,7))\n\n# mean_30_59 = df_year.loc['1930-09-30':'1959-09-01','rain (mm)'].mean()\n# mean_40_69 = df_year.loc['1940-09-30':'1969-09-01','rain (mm)'].mean()\n# mean_50_79 = df_year.loc['1950-09-30':'1979-09-01','rain (mm)'].mean()\n# mean_60_89 = df_year.loc['1960-09-30':'1989-09-01','rain (mm)'].mean()\n# mean_70_99 = df_year.loc['1970-09-30':'1999-09-01','rain (mm)'].mean()\n# mean_80_09 = df_year.loc['1980-09-30':'2009-09-01','rain (mm)'].mean()\n\n# ax.plot([mean_30_59,\n#          mean_40_69,\n#          mean_50_79,\n#          mean_60_89,\n#          mean_70_99,\n#          mean_80_09])\n\n\n####### the easy way #######\n\nfig, ax = plt.subplots(figsize=(10,7))\n\n# use list comprehension\nwindows = [[x, x+29] for x in [1930,1940,1950,1960,1970,1980]]\nmean = [df_year.loc[f'{w[0]:d}-09-30':f'{w[1]:d}-09-01','rain (mm)'].mean() for w in windows]\nax.plot(mean)\nax.set(xticks=np.arange(len(mean)),\n       xticklabels=[str(w) for w in windows],\n       ylabel=\"window average (mm)\"\n      );",
    "crumbs": [
      "Precipitation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "precipitation/return-period-lecture.html",
    "href": "precipitation/return-period-lecture.html",
    "title": "7  Return Period",
    "section": "",
    "text": "7.1 Bilbao, Spain",
    "crumbs": [
      "Precipitation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Return Period</span>"
    ]
  },
  {
    "objectID": "precipitation/return-period-lecture.html#today",
    "href": "precipitation/return-period-lecture.html#today",
    "title": "7  Return Period",
    "section": "7.2 Today",
    "text": "7.2 Today",
    "crumbs": [
      "Precipitation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Return Period</span>"
    ]
  },
  {
    "objectID": "precipitation/return-period-lecture.html#august-1983",
    "href": "precipitation/return-period-lecture.html#august-1983",
    "title": "7  Return Period",
    "section": "7.3 August 1983",
    "text": "7.3 August 1983\n\nOn Friday, August 26, 1983, Bilbao was celebrating its Aste Nagusia or Great Week, the main annual festivity in the city, when it and other municipalities of the Basque Country, Burgos, and Cantabria suffered devastating flooding due to heavy rains. In 24 hours, the volume of water registered 600 liters per square meter. Across all the affected areas, the weather service recorded 1.5 billion tons of water. In areas of Bilbao, the water reached a height of 5 meters (15 feet). Transportation, electricity and gas services, drinking water, food, telephone, and many other basic services were severely affected. 32 people died in Biscay, 4 people died in Cantabria, 2 people died in Alava, and 2 people died Burgos. 5 more people went missing.",
    "crumbs": [
      "Precipitation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Return Period</span>"
    ]
  },
  {
    "objectID": "precipitation/return-period-lecture.html#how-often-will-such-rainfall-happen",
    "href": "precipitation/return-period-lecture.html#how-often-will-such-rainfall-happen",
    "title": "7  Return Period",
    "section": "7.4 How often will such rainfall happen?",
    "text": "7.4 How often will such rainfall happen?\nHow often does it rain 50 mm in 1 day? What about 100 mm in 1 day? How big is a “once-in-a-century event”?\nLet’s examine Bilbao’s daily rainfall (mm), between 1947 to 2021\n\n\nimport stuff\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_theme(style=\"ticks\", font_scale=1.5)\nimport urllib.request\nfrom matplotlib.dates import DateFormatter\nimport matplotlib.dates as mdates\nimport altair as alt\nalt.data_transformers.disable_max_rows()\nfrom scipy.stats import genextreme\n\n\n\n\ndefine function and download data\ndef download_data(station_name, station_code):\n    url_daily = 'https://www.ncei.noaa.gov/data/global-historical-climatology-network-daily/access/'\n    url_monthly = 'https://www.ncei.noaa.gov/data/gsom/access/'\n#     download daily data - uncomment to make this work\n    urllib.request.urlretrieve(url_daily + station_code + '.csv',\n                               station_name + '_daily.csv')\n    # download monthly data\n    urllib.request.urlretrieve(url_monthly + station_code + '.csv',\n                               station_name + '_monthly.csv')\ndownload_data('BILBAO', 'SPE00120611')\n\n\n\n\nload data and plot precipitation\ndf = pd.read_csv('BILBAO_daily.csv',\n                 sep=\",\",\n                 parse_dates=['DATE'],\n                 index_col='DATE')\n# IMPORTANT!! daily precipitation data is in tenths of mm, divide by 10 to get it in mm.\ndf['PRCP'] = df['PRCP'] / 10\n\nfig, ax = plt.subplots(figsize=(10,7))\nax.plot(df['PRCP'])\nax.set(xlabel=\"date\",\n       ylabel=\"daily rainfall (mm)\",\n       title=\"Bilbao, Spain, 1947--2021\"\n      )\nax.annotate(\"26 August 1983\",\n             xy=(pd.to_datetime('1983-08-26'), 2500), xycoords='data',\n             xytext=(0.7, 0.95), textcoords='axes fraction',\n             fontsize=16, va=\"center\",\n             arrowprops=dict(facecolor='black', shrink=0.05));\n\n\n\n\n\n\n\n\n\nOn the week of 22-28 August 1983, Bilbao’s weather station measured 45 cm of rainfall!\n\n\nShow the code\n\nfig, ax = plt.subplots(figsize=(10,7))\none_week = df.loc['1983-08-22':'1983-08-28', 'PRCP']\nbars = ax.bar(one_week.index, one_week)\nax.set_xlabel(\"date\")\nax.set_ylabel(\"daily rainfall (mm)\")\nax.set_title(\"Bilbao, Spain, August 1983\")\n\n# write daily rainfall\nfor i in range(len(one_week)):\n    ax.text(one_week.index[i], one_week.iloc[i], f\"{one_week.iloc[i]:.0f}\", ha=\"center\", fontsize=16)\n    # ax.text(one_week.index[i], one_week[i], f\"{one_week[i]:.0f}\", ha=\"center\", fontsize=16);\n\nax.text(0.1, 0.8, f\"Total rainfall during this week:\\n{one_week.sum():.0f} mm\",\n        transform=ax.transAxes, fontsize=16)\n    \n# Define the date format\n# https://docs.python.org/2/library/datetime.html#strftime-and-strptime-behavior\ndate_form = DateFormatter(\"%b-%d\")\nax.xaxis.set_major_formatter(date_form)\n# Ensure a major tick for each day using (interval=1)\n# https://matplotlib.org/stable/api/dates_api.html#date-tickers\nax.xaxis.set_major_locator(mdates.DayLocator(interval=1))\n\n\n\n\n\n\n\n\n\nLet’s analyze this data and find out how rare such events are. First we need to find the annual maximum for each hydrological year. Do we see any seasonal patterns with our eyes? Play with the widget below.\n\n\nwidget\n# Altair only recognizes column data; it ignores index values.\n# You can plot the index data by first resetting the index\n# I know that I've just made 'DATE' the index, but I want to have this here nonetheless so I can refer to this in the future\ndf_new = df.reset_index()\nsource = df_new[['DATE', 'PRCP']]\n\nbrush = alt.selection_interval(encodings=['x'])\n\nbase = alt.Chart(source).mark_line().encode(\n    x = 'DATE:T',\n    y = 'PRCP:Q'\n).properties(\n    width=600,\n    height=200\n)\n\nupper = base.encode(\n    alt.X('DATE:T', scale=alt.Scale(domain=brush)),\n    alt.Y('PRCP:Q', scale=alt.Scale(domain=(0,100)))\n)\n\nlower = base.properties(\n    height=60\n).add_params(brush)\n\nalt.vconcat(upper, lower)\n\n\n\n\n\n\n\n\nLet’s do what we learned already in the previous lectures, and plot monthly precipitation averages. For Bilbao, we will consider the hydrological year starting on 1 August.\n\n\ncalculate and plot monthly precipitation averages\ndf_month = df['PRCP'].resample('ME').sum().to_frame()\ndf_month_avg = (df_month['PRCP']\n                  .groupby(df_month.index.month)\n                  .mean()\n                  .to_frame()\n               )\nfig, ax = plt.subplots(figsize=(10,7))\nax.bar(df_month_avg.index, df_month_avg['PRCP'])\nax.set(xlabel=\"month\",\n       ylabel=\"monthly precipiation (mm)\",\n       title=\"Monthly average, Bilbao\",\n       xticks=np.arange(1,13));\n\n\n\n\n\n\n\n\n\n\nTop: Histogram of annual daily precipitation maximum events.\n\nBottom: The cumulative answers the question: “How many events can be found below a given threshold?”\n\n\n\ncalculate max annual and plot histograms\nmax_annual = (df['PRCP'].resample('YE-JUL')\n                        .max()\n                        .to_frame()\n             )\n\n\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,8), sharex=True)\n\nh=max_annual['PRCP'].values\n\nbins=np.arange(0,270,20)\nax1.hist(h, bins=bins)\nax2.hist(h, bins=bins, cumulative=1)\n\nax1.set(ylabel=\"number of years\")\nax2.set(xlabel=\"annual daily max (mm)\",\n        ylabel=\"cumulative\",\n        xlim=[0,280]);\n\n\n\n\n\n\n\n\n\n\nTop: We can normalize the histogram such that the total area is 1. Now the histogram is called probability density function (pdf). The probability is NOT the pdf, but the area between two thresholds.\nBottom: The cumulative now becomes a probability between 0 and 1. It is now called cumulative density function (cdf). The cdf answers the question: “What is the probability to choose an event below a given threshold?”\n\n\n\nplot pdf and cdf\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,8), sharex=True)\n\nax1.hist(h, bins=bins, density=True)\nax2.hist(h, bins=bins, cumulative=1, density=True)\n\nax1.set(ylabel=\"pdf\")\nax2.set(xlabel=\"annual daily max (mm)\",\n        ylabel=\"cdf\",\n        xlim=[0,280]\n        )\nax1.text(0.5, 0.5, \"probability density function\",\n         transform=ax1.transAxes, fontsize=16,\n         bbox=dict(boxstyle='round', facecolor='wheat', alpha=1))\nax2.text(0.5, 0.5, \"cumulative density function\",\n         transform=ax2.transAxes, fontsize=16,\n         bbox=dict(boxstyle='round', facecolor='wheat', alpha=1));\n\n\n\n\n\n\n\n\n\nWe are interested in extreme events, and we want to estimate how many years, on average, do we have to wait to get an annual maximum above a given threshold?\nThis question is very similar to what we asked regarding the cdf. 🤔\nWe switched the word “below” for “above”. The complementary of the cumulative is called the exceedance (or survival) probability:\n\n\\text{exceedance, survival} = 1 - \\text{cdf}\n\n\n\ndefine useful function to plot pdf and survival\ndef plot_pdf_and_survival(survival):\n    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,6), sharex=True)\n\n    ax1.hist(h, bins=bins, density=True, histtype='stepfilled', alpha=0.2)\n    ax2.hist(h, bins=bins, density=True, histtype='stepfilled', alpha=0.2, cumulative=-1)\n\n    params = genextreme.fit(h)\n    rain_max = 200.0\n    rain = np.arange(0,rain_max)\n    pdf = genextreme(c=params[0], loc=params[1], scale=params[2]).pdf\n    cdf = genextreme(c=params[0], loc=params[1], scale=params[2]).cdf\n    ax1.plot(rain, pdf(rain), 'r-', lw=5, alpha=0.6, clip_on=False)\n    ax2.plot(rain, 1-cdf(rain), 'r-', lw=5, alpha=0.6, clip_on=False)\n    ax1.set(ylabel=\"probability density\")\n    ax2.set(xlabel=\"annual daily max (mm)\",\n            ylabel=\"survival = 1-cdf\",\n            xlim=[0,200])\n\n    # survival = 0.20\n    threshold = genextreme(c=params[0], loc=params[1], scale=params[2]).ppf(1-survival)\n    xfill = np.linspace(threshold, rain_max, 100)\n    ax1.fill_between(xfill, pdf(xfill), color='None', hatch=\"//\",edgecolor='k', label=f\"{survival:.0%} of the area\")\n    ax2.plot([0, threshold, threshold], [survival, survival ,0], color=\"black\", ls=\":\")\n    ax2.text(20, survival, \"{:.0f}%\".format(100*survival), ha=\"left\", va=\"bottom\", fontsize=16)\n\n    ax1.set(title=(\"we'll wait \"+\n                r\"$\\bf{\" + \"on\\;average\" + \"}$ \"+\n                f\"({survival:.0%})\" +\n                r\"$^{-1}=$\" +\n                f\"({survival:.2f})\" +\n                r\"$^{-1}=$\" +\n                f\" {1/survival:.0f} years\\nfor a yearly maximum above {threshold:.0f} mm\"\n                )\n        )\n    ax1.legend(loc=\"upper right\", frameon=False)\n    ax2.text(100, 0.95, \"the survival shows the probability\\nthat next year's annual daily max\\nis above a given threshold\",\n            va=\"top\")\n\n\n\n\nplot for survival = 0.5\nplot_pdf_and_survival(0.5)\n\n\n\n\n\n\n\n\n\n\n\nplot for survival = 0.2\nplot_pdf_and_survival(0.2)",
    "crumbs": [
      "Precipitation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Return Period</span>"
    ]
  },
  {
    "objectID": "precipitation/return-period-lecture.html#return-period",
    "href": "precipitation/return-period-lecture.html#return-period",
    "title": "7  Return Period",
    "section": "7.5 Return Period",
    "text": "7.5 Return Period\nWe will follow Brutsaert (2005), page 513.\nWe call F(x) the CDF of the PDF f(x). F(x) indicates the non-exceedance probability, i.e., the probability that a certain event above x has not occurred (or that an event below x has occurred, same thing). The execeedance probability, also called survival probability, equals 1-F(x), and is the probability that a certain event above x has occurred. It’s reciprocal is the return period:\n\nT_r(x) = \\frac{1}{1-F(x)}\n\nThis return period is the expected number of observations required until x is exceeded once. In our case, we can ask the question: how many years will pass (on average) until we see a rainfall event greater that that of 26 August 1983?\nLet’s call p=F(x) the probability that we measured once and that an event greater than x has not occurred. What is the probability that a rainfall above x will occur only on year number k?\n\nit hasn’t occurred on year 1 (probability p)\nit hasn’t occurred on year 2 (probability p)\nit hasn’t occurred on year 3 (probability p)\n…\nit has occurred on year k (probability 1-p)\n\nP\\{k \\text{ trials until }X&gt;x\\} = p^{k-1}(1-p)\nEvery time the number k will be different. What will be k on average?\n\n\\bar{k} = \\displaystyle\\sum_{k=1}^{\\infty} k P(k) = \\displaystyle\\sum_{k=1}^{\\infty} k p^{k-1}(1-p)\n\nLet’s open that up:\n\n\\begin{split}\n\\bar{k} &= 1-p + 2p(1-p) + 3p^2(1-p) + 4p^3(1-p)+ \\cdots\\\\\n\\bar{k} &= 1-p + 2p - 2p^2 + 3p^2 - 3p^4 + 4p^3 - 4p^4+ \\cdots \\\\\n\\bar{k} &= 1 + p + p^2 + p^3 + p^4 + \\cdots\n\\end{split}\n\nFor p&lt;1, the series converges to \n1 + p + p^2 + p^3 + p^4 + \\cdots = \\frac{1}{1-p},\n therefore \n\\bar{k} = \\frac{1}{1-p}.\n\nWe conclude that if we know the exceedance probability, we immediately can say what the return times are. We now need a way of estimating this exceedance probability.",
    "crumbs": [
      "Precipitation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Return Period</span>"
    ]
  },
  {
    "objectID": "precipitation/return-period-lecture.html#generalized-extreme-value-distribution",
    "href": "precipitation/return-period-lecture.html#generalized-extreme-value-distribution",
    "title": "7  Return Period",
    "section": "7.6 Generalized extreme value distribution",
    "text": "7.6 Generalized extreme value distribution\nThis part of the lecture was heavily inspired by Alexandre Martinez’s excellent blog post.\nThe Generalized Extreme Value (GEV) distribution is the limit distribution of properly normalized maxima of a sequence of independent and identically distributed random variables (from Wikipedia).\nIt has three parameters:\n\n\\xi= shape,\n\\mu= location,\n\\sigma= scale.\n\nSee a few examples of how the gev function looks for different parameters.\n\n\ngev with different parameter values\nfig, ax = plt.subplots(figsize=(10,7))\n\nshape = [-0.5, -0.1, -0.9]\nlocation = [1.0, 2.5, 2.5]\nscale = [0.5, 1.0, 2.0]\ncolor=[\"black\", \"xkcd:hot pink\", \"dodgerblue\"]\nx = np.arange(0, 5, 0.01)\nfor i in range(len(shape)):\n    pdf = genextreme.pdf(x, shape[i], loc=location[i], scale=scale[i])\n    ax.plot(x, pdf, lw=2, color=color[i], label=rf\"$\\xi={shape[i]}$,  $\\mu={location[i]}$,  $\\sigma={scale[i]}$\")\nax.legend(loc=\"upper right\", frameon=False)\nax.set(xlabel=\"x\",\n       ylabel=\"pdf(x)\");\n\n\n\n\n\n\n\n\n\nOur task now is to find the “best curve” that describes our data. We do that by fitting the GEV curve, i.e., we need to find the best combination of parameters.\n\n\nplot pdf and cdf\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,8), sharex=True)\n\nax1.hist(h, bins=bins, density=True)\nax2.hist(h, bins=bins, cumulative=1, density=True)\n\nparams = genextreme.fit(h)\nrain_max = 400.0\nrain = np.arange(0,rain_max)\npdf = genextreme(c=params[0], loc=params[1], scale=params[2]).pdf\ncdf = genextreme(c=params[0], loc=params[1], scale=params[2]).cdf\nax1.plot(rain, pdf(rain), color='tab:orange', clip_on=False, lw=2)\nax2.plot(rain, cdf(rain), color='tab:orange', clip_on=False, lw=2)\nax2.text(270, 0.8, \"because gev is a function,\\nwe can extend it to much\\nhigher daily max values\\nthan those in the data\",\n         fontsize=14, va=\"top\")\n\nax1.set(ylabel=\"pdf\")\nax2.set(xlabel=\"annual daily max (mm)\",\n        ylabel=\"cdf\",\n        xlim=[0,400]\n        );\n\n\n\n\n\n\n\n\n\n\n7.6.1 cdf from data\nHere is a plot of annual daily precipitation maxima for Bilbao.\n\n\nannual daily max for each year\nfig, ax = plt.subplots(figsize=(10,7))\nax.plot(max_annual['PRCP'])\nax.set(ylabel=\"annual daily precipitation max (mm)\",\n       ylim=[0, 270])\n\n\n\n\n\n\n\n\n\nThere are 74 points here. Let’s order them from small to large:\n\n\nordered annual daily max\n# sort yearly max from highest to lowest\nmax_annual = max_annual.sort_values(by=['PRCP'], ascending=True)\nmax_annual['rank'] = np.arange(1, len(max_annual) + 1)\n\nfig, ax = plt.subplots(figsize=(10,7))\nax.plot(max_annual['rank'], max_annual['PRCP'], 'o')\nax.set(ylabel=\"annual daily precipitation max (mm)\",\n       xlabel=f\"order=rank, from 1 to {len(max_annual)}\",\n       ylim=[0, 270],\n       xlim=[0, 80]);\n\n\n\n\n\n\n\n\n\n\n\nordered annual daily max\nfig, ax = plt.subplots(figsize=(10,7))\nax.plot(max_annual['rank'], max_annual['PRCP'], 'o')\n\nn = len(max_annual['rank'])\nm = max_annual['rank']\ncdf_fromdata = m / (n+1)\n\nthreshold100 = 100  # millimeters\ncount100 = np.sum(max_annual['PRCP'] &lt; threshold100)\np100 = count100/(n+1)\nax.text(5, 105, f\"{count100}/{n+1} = {p100:.0%} of the points\\nare below the {threshold100} mm threshold\")\nax.plot(max_annual['rank'], threshold100 + 0*max_annual['PRCP'],\n        color=\"tab:orange\", lw=2)\n\nthreshold60 = 60  # millimeters\ncount60 = np.sum(max_annual['PRCP'] &lt; threshold60)\np60 = count60/(n+1)\nax.text(5, 65, f\"{count60}/{n+1} = {p60:.0%} of the points\\nare below the {threshold60} mm threshold\")\nax.plot(max_annual['rank'], threshold60 + 0*max_annual['PRCP'],\n        color=\"tab:orange\", lw=2)\n\nax.set(ylabel=\"annual daily precipitation max (mm)\",\n       xlabel=f\"order=rank, from 1 to {len(max_annual)}\",\n       ylim=[0, 270],\n       xlim=[0, 80]);\n\n\n\n\n\n\n\n\n\nNow, instead of having the order of the event on the horizontal axis, let’s make it a fraction from 0 to 1.\n\n\nnow horizontal axis is cdf\nfig, ax = plt.subplots(figsize=(10,7))\nax.plot(cdf_fromdata, max_annual['PRCP'], 'o')\nax.text(0.05, 105, f\"{count100}/{n+1} = {p100:.0%} of the points\\nare below the {threshold100} mm threshold\")\nax.plot(cdf_fromdata, threshold100 + 0*max_annual['PRCP'],\n        color=\"tab:orange\", lw=2)\nax.text(0.05, 65, f\"{count60}/{n+1} = {p60:.0%} of the points\\nare below the {threshold60} mm threshold\")\nax.plot(cdf_fromdata, threshold60 + 0*max_annual['PRCP'],\n        color=\"tab:orange\", lw=2)\nax.plot([p100, p100], [0, threshold100], ls=\":\", color=\"black\")\nax.text(p100, 5, f\"{p100:.2f}\")\nax.plot([p60, p60], [0, threshold60], ls=\":\", color=\"black\")\nax.text(p60, 5, f\"{p60:.2f}\")\nax.text(0.5, 200, r\"cdf $=\\frac{\\text{rank}}{n+1}$\",\n        fontsize=26, ha=\"center\")\nax.set(ylabel=\"annual daily precipitation max (mm)\",\n       xlabel=f\"cdf = probability of being below a certain threshold\",\n       ylim=[0, 270],\n       xlim=[0, 1]);\n\n\n\n\n\n\n\n\n\nThe cdf was calculated using the Weibull plotting position:\n\nP_m = \\frac{\\text{rank}}{n+1}\n\nIn the context of analyzing extreme values in precipitation, using the Weibull plotting position formula above is crucial for accurately estimating the cumulative distribution function (CDF). This method ensures a more even distribution of plotting positions, correcting the bias that often occurs with small sample sizes when using n alone. By dividing by n+1, each rank’s cumulative probability is slightly adjusted, resulting in more realistic and representative plotting positions. This adjustment is particularly important in hydrology and meteorology, where accurate representation of extreme precipitation events is essential for risk assessment and infrastructure planning. The Weibull plotting position thus provides a more reliable tool for understanding and predicting extreme weather patterns.\nNow we just need to flip the vertical and horizontal axes, and we’re done! We have our cdf!\n\n\ncdf as we are use to\nfig, ax = plt.subplots(figsize=(10,7))\nax.plot(max_annual['PRCP'], cdf_fromdata, 'o')\nax.set(xlabel=\"annual daily precipitation max (mm)\",\n       ylabel=f\"cdf\",\n       xlim=[0, 270],\n       ylim=[0, 1]);\n\n\n\n\n\n\n\n\n\nLet’s compare this to the cumulative distribution from before, based on the histogram.\n\n\ncdf as we are use to\nfig, ax = plt.subplots(figsize=(10,7))\nax.plot(max_annual['PRCP'], cdf_fromdata, 'o', label=\"exact cdf from data\")\nax.hist(h, bins=bins, cumulative=1, density=True, histtype=\"bar\", color=\"lightgray\", label=\"cdf from histogram\")\nax.legend(loc=\"lower right\")\nax.set(xlabel=\"annual daily precipitation max (mm)\",\n       ylabel=f\"cdf\",\n       xlim=[0, 270],\n       ylim=[0, 1]);\n\n\n\n\n\n\n\n\n\nThe highest data point in this graph goes only to 252 mm, corresponding to the highest event recorded in 74 years. We can use the GEV cdf to calculate return times for any desired levels, simply by converting the vertical axis (cdf) to return period, using the equation we found earlier. \nT_r(x) = \\frac{1}{1-F(x)},\n\nwhere T_r is the return period (in years), and F is the cdf.\n\n\ncdf as we are use to\nfig, ax = plt.subplots(figsize=(10,7))\n\nT = 1 / (1-cdf_fromdata)\nax.plot(T, max_annual['PRCP'], 'o', label=\"return time from data\")\n\nax.plot(1/(1-cdf(rain)), rain, color='tab:orange', lw=2, label=\"return time from gev\")\nax.legend(loc=\"upper right\", frameon=False)\nax.set(xlabel=\"return time (year)\",\n       ylabel=f\"annual daily precipitation max (mm)\",\n       xlim=[0, 125],\n       ylim=[0, 400]);\n\n\n\n\n\n\n\n\n\nThe information contained in the last two graphs is exactly the same, but somehow this last graph looks much worse! Why is this so?\n\n\n\n\nBrutsaert, Wilfried. 2005. Hydrology: An Introduction. Cambridge University Press.",
    "crumbs": [
      "Precipitation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Return Period</span>"
    ]
  },
  {
    "objectID": "precipitation/return-period-exercises.html",
    "href": "precipitation/return-period-exercises.html",
    "title": "8  Exercises",
    "section": "",
    "text": "8.1 loading data and pre-processing\nImport relevant packages\nShow the code\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_theme(style=\"ticks\", font_scale=1.5)\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\nimport urllib.request\nfrom scipy.stats import genextreme\nfrom scipy.optimize import curve_fit\nGo to NOAA’s National Centers for Environmental Information (NCEI)\nClimate Data Online: Dataset Discovery\nFind station codes in this map. On the left, click on the little wrench next to “Global Summary of the Month”, then click on “identify” on the panel that just opened, and click on a station (purple circle). You will see the station’s name, it’s ID, and the period of record. For example, for Ben-Gurion’s Airport in Israel:\nBEN GURION, IS\nSTATION ID: ISM00040180\nPeriod of Record: 1951-01-01 to 2020-03-01\nYou can download daily or monthly data for each station. Use the function below to download this data to your computer. station_name can be whatever you want, station_code is the station ID.\nIf everything fails and you need easy access to the files we’ll be using today, click here:\nEilat daily.\nShow the code\ndef download_data(station_name, station_code):\n    url_daily = 'https://www.ncei.noaa.gov/data/global-historical-climatology-network-daily/access/'\n    url_monthly = 'https://www.ncei.noaa.gov/data/gsom/access/'\n    # download daily data - uncomment the following 2 lines to make this work\n    urllib.request.urlretrieve(url_daily + station_code + '.csv',\n                              station_name + '_daily.csv')\n    # download monthly data\n    urllib.request.urlretrieve(url_monthly + station_code + '.csv',\n                               station_name + '_monthly.csv')\nDownload daily rainfall data for Eilat, Israel. ID: IS000009972\nShow the code\ndownload_data('Eilat', 'IS000009972')\nThen load the data into a dataframe.\nIMPORTANT!! daily precipitation data is in tenths of mm, divide by 10 to get it in mm.\nHow do we know that? It’s in the documentation!\nShow the code\ndf = pd.read_csv('Eilat_daily.csv', sep=\",\")\n# make 'DATE' the dataframe index\ndf['DATE'] = pd.to_datetime(df['DATE'])\ndf = df.set_index('DATE')\n# IMPORTANT!! daily precipitation data is in tenths of mm, divide by 10 to get it in mm.\ndf['PRCP'] = df['PRCP'] / 10\ndf\n\n\n\n\n\n\n\n\n\nSTATION\nLATITUDE\nLONGITUDE\nELEVATION\nNAME\nPRCP\nPRCP_ATTRIBUTES\nTMAX\nTMAX_ATTRIBUTES\nTMIN\nTMIN_ATTRIBUTES\nTAVG\nTAVG_ATTRIBUTES\n\n\nDATE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1949-11-30\nIS000009972\n29.55\n34.95\n12.0\nELAT, IS\n0.0\n,,E\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1949-12-01\nIS000009972\n29.55\n34.95\n12.0\nELAT, IS\n0.0\n,,E\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1949-12-02\nIS000009972\n29.55\n34.95\n12.0\nELAT, IS\n0.0\n,,E\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1949-12-03\nIS000009972\n29.55\n34.95\n12.0\nELAT, IS\n0.0\n,,E\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1949-12-04\nIS000009972\n29.55\n34.95\n12.0\nELAT, IS\n0.0\n,,E\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2024-01-16\nIS000009972\n29.55\n34.95\n12.0\nELAT, IS\nNaN\nNaN\n231.0\n,,S\n108.0\n,,S\n170.0\nH,,S\n\n\n2024-01-17\nIS000009972\n29.55\n34.95\n12.0\nELAT, IS\nNaN\nNaN\n211.0\n,,S\n117.0\n,,S\n164.0\nH,,S\n\n\n2024-01-18\nIS000009972\n29.55\n34.95\n12.0\nELAT, IS\nNaN\nNaN\n240.0\n,,S\n111.0\n,,S\n174.0\nH,,S\n\n\n2024-01-19\nIS000009972\n29.55\n34.95\n12.0\nELAT, IS\nNaN\nNaN\n244.0\n,,S\n135.0\n,,S\n182.0\nH,,S\n\n\n2024-01-20\nIS000009972\n29.55\n34.95\n12.0\nELAT, IS\nNaN\nNaN\nNaN\nNaN\n118.0\n,,S\n147.0\nH,,S\n\n\n\n\n27072 rows × 13 columns\nPlot precipitation data (‘PRCP’ column) and see if everything is all right.\nShow the code\nfig, ax = plt.subplots(figsize=(10,7))\nax.plot(df['PRCP'])\nax.set_xlabel(\"date\")\nax.set_ylabel(\"daily rainfall (mm)\")\nax.set_title(\"Eilat, 1949–2024\")\n\n\nText(0.5, 1.0, 'Eilat, 1949–2024')\nBased on what you see, you might want to exclude certain periods, e.g.:\nShow the code\nlast_date = '2018-08-01'\nfirst_date = '1950-08-01'\ndf = df.loc[first_date:last_date]\ndf\n\n\n\n\n\n\n\n\n\nSTATION\nLATITUDE\nLONGITUDE\nELEVATION\nNAME\nPRCP\nPRCP_ATTRIBUTES\nTMAX\nTMAX_ATTRIBUTES\nTMIN\nTMIN_ATTRIBUTES\nTAVG\nTAVG_ATTRIBUTES\n\n\nDATE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1950-08-01\nIS000009972\n29.55\n34.95\n12.0\nELAT, IS\n0.0\n,,E\n410.0\n,,G\n250.0\n,,G\nNaN\nNaN\n\n\n1950-08-02\nIS000009972\n29.55\n34.95\n12.0\nELAT, IS\n0.0\n,,E\n400.0\n,,G\n240.0\n,,G\nNaN\nNaN\n\n\n1950-08-03\nIS000009972\n29.55\n34.95\n12.0\nELAT, IS\n0.0\n,,E\n410.0\n,,G\n260.0\n,,G\nNaN\nNaN\n\n\n1950-08-04\nIS000009972\n29.55\n34.95\n12.0\nELAT, IS\n0.0\n,,E\n400.0\n,,G\n260.0\n,,G\nNaN\nNaN\n\n\n1950-08-05\nIS000009972\n29.55\n34.95\n12.0\nELAT, IS\n0.0\n,,E\nNaN\nNaN\n240.0\n,,G\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2018-07-28\nIS000009972\n29.55\n34.95\n12.0\nELAT, IS\n0.0\n,,S\n386.0\n,,S\nNaN\nNaN\n329.0\nH,,S\n\n\n2018-07-29\nIS000009972\n29.55\n34.95\n12.0\nELAT, IS\n0.0\n,,S\nNaN\nNaN\n268.0\n,,S\n334.0\nH,,S\n\n\n2018-07-30\nIS000009972\n29.55\n34.95\n12.0\nELAT, IS\n0.0\n,,S\n375.0\n,,S\n277.0\n,,S\n327.0\nH,,S\n\n\n2018-07-31\nIS000009972\n29.55\n34.95\n12.0\nELAT, IS\n0.0\n,,S\n390.0\n,,S\nNaN\nNaN\n336.0\nH,,S\n\n\n2018-08-01\nIS000009972\n29.55\n34.95\n12.0\nELAT, IS\n0.0\n,,S\nNaN\nNaN\n278.0\n,,S\n346.0\nH,,S\n\n\n\n\n24838 rows × 13 columns\nThe rainfall data for Eilat is VERY seasonal, it’s easy to see that there is no rainfall at all during the summer. We can assume a hydrological year starting on 1 August. If you’re not sure, you can plot the monthly means (see last week’s lecture) and find what date makes sense best.\nShow the code\ndf_month = df['PRCP'].resample('M').sum().to_frame()\ndf_month_avg = (df_month['PRCP']\n                  .groupby(df_month.index.month)\n                  .mean()\n                  .to_frame()\n               )\ndf_month_avg\n\n\n/var/folders/c3/7hp0d36n6vv8jc9hm2440__00000gn/T/ipykernel_71663/1784230487.py:1: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n  df_month = df['PRCP'].resample('M').sum().to_frame()\n\n\n\n\n\n\n\n\n\nPRCP\n\n\nDATE\n\n\n\n\n\n1\n3.445588\n\n\n2\n4.629412\n\n\n3\n3.958824\n\n\n4\n2.483824\n\n\n5\n1.086765\n\n\n6\n0.000000\n\n\n7\n0.000000\n\n\n8\n0.000000\n\n\n9\n0.008824\n\n\n10\n2.923529\n\n\n11\n2.701471\n\n\n12\n5.792647\nShow the code\nfig, ax = plt.subplots(figsize=(10,7))\nax.bar(df_month_avg.index, df_month_avg['PRCP'])\nax.set(xlabel=\"month\",\n       ylabel=\"monthly rainfall (mm)\",\n       title=\"Monthly average, Eilat, 1949--2018\",\n       xticks=np.arange(1,13));\nLet’s resample the data according to the hydrological year (1 August), and we’ll keep the maximum value:\nShow the code\nmax_annual = (df['PRCP'].resample('A-JUL')\n                        .max()\n                        .to_frame()\n             )\nmax_annual\n\n\n/var/folders/c3/7hp0d36n6vv8jc9hm2440__00000gn/T/ipykernel_71663/299619059.py:1: FutureWarning: 'A-JUL' is deprecated and will be removed in a future version, please use 'YE-JUL' instead.\n  max_annual = (df['PRCP'].resample('A-JUL')\n\n\n\n\n\n\n\n\n\nPRCP\n\n\nDATE\n\n\n\n\n\n1951-07-31\n10.8\n\n\n1952-07-31\n15.0\n\n\n1953-07-31\n34.4\n\n\n1954-07-31\n24.3\n\n\n1955-07-31\n19.0\n\n\n...\n...\n\n\n2015-07-31\n2.4\n\n\n2016-07-31\n8.5\n\n\n2017-07-31\n34.5\n\n\n2018-07-31\n11.7\n\n\n2019-07-31\n0.0\n\n\n\n\n69 rows × 1 columns\nMake two graphs: a) the histogram for the annual maximum (pdf) b) the cumulative probability (cdf)\nShow the code\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,8))\n\nh=max_annual['PRCP'].values\nax1.hist(h, bins=np.arange(0,100,10), density=True)\nax2.hist(h, bins=np.arange(0,100,10), cumulative=1, density=True)\n\nax1.set(ylabel=\"pdf\")\nax2.set(xlabel=\"annual daily precipitation maxima (mm)\",\n        ylabel=\"cdf\",\n        );",
    "crumbs": [
      "Precipitation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "precipitation/return-period-exercises.html#weibull-plotting-position",
    "href": "precipitation/return-period-exercises.html#weibull-plotting-position",
    "title": "8  Exercises",
    "section": "8.2 Weibull plotting position",
    "text": "8.2 Weibull plotting position\nHow to make a cdf by yourself?\n\n\nShow the code\n# sort the annual daily precipitation maxima, from lowest to highest\nmax_annual['max_sorted'] = np.sort(max_annual['PRCP'])\n# let's give it a name, h\nh = max_annual['max_sorted'].values\n# make an array \"order\" of size N=len(h), from 1 to N\nN = len(h)\nrank = np.arange(N) + 1\n# make a new array, \"rank\"\ncdf_weibull = rank / (N+1)\n\n\nPlot it next to the cdf that pandas’ hist makes for you. What do you see?\n\n\nShow the code\nfig, ax = plt.subplots(figsize=(10,7))\nax.hist(h, bins=np.arange(0,100,10), cumulative=1, density=True, label=\"from 'hist'\")\nax.plot(h, cdf_weibull, color=\"tab:orange\", linewidth=3, label=\"our cdf\")\nax.set_ylabel(\"cdf\")\nax.set_xlabel(\"annual daily precipitation maxima (mm)\")\nax.set_title(\"Eilat\")\nax.legend()\n\n\n\n\n\n\n\n\n\nThe generalized extreme value distribution has 3 parameters: shape, location, scale.\nLet’s get a “best fit” estimate of these parameters for Eilat’s rainfall statistics.\n\n\nShow the code\nparams = genextreme.fit(h)\nprint(\"Best fit:\")\nprint(f\"shape = {params[0]:.2f}\\nlocation = {params[1]:.2f}\\nscale = {params[2]:.2f}\")\n\n\nBest fit:\nshape = -0.42\nlocation = 6.05\nscale = 5.68\n\n\nLet’s see the GEV distribution for these parameters\n\n\nShow the code\nfig, ax = plt.subplots(figsize=(10,7))\nax.hist(h, bins=np.arange(0,100,10), density=True, label=\"from 'hist'\")\nrain = np.arange(0,80)\npdf_rain = genextreme(c=params[0], loc=params[1], scale=params[2]).pdf(rain)\nax.plot(rain, pdf_rain, color=\"tab:orange\", lw=3, label=\"gev fit\")\nax.set_ylabel(\"pdf\")\nax.set_xlabel(\"annual daily precipitation maxima (mm)\")\nax.set_title(\"Eilat\")\nax.legend()\n\n\n\n\n\n\n\n\n\nWe can do the same for the cdf…\n\n\nShow the code\nfig, ax = plt.subplots(figsize=(10,7))\nax.plot(h, cdf_weibull, color=\"tab:blue\", linewidth=3, label=\"weibull cdf\")\nrain = np.arange(0,80)\ncdf_rain = genextreme(c=params[0], loc=params[1], scale=params[2]).cdf(rain)\nax.plot(rain, cdf_rain, color=\"tab:orange\", lw=3, label=\"gev fit\")\nax.set_ylabel(\"cdf\")\nax.set_xlabel(\"annual daily precipitation maxima (mm)\")\nax.set_title(\"Eilat\")\nax.legend()\n\n\n\n\n\n\n\n\n\nWe are almost there! Remember that the return time are given by:\n\nT_r(x) = \\frac{1}{1-F(x)},\n\nwhere F is the cdf.\nSurvival = 1-F\nThe package that we are using, scipy.stats.genextreme has a method called isf, or inverse survival function, which is exactly what we want! In order to use it, you have to feed it a “quantile” q or probability. Suppose you want to know how strong is a 1 in a 100 year event, then your return period is 100 (years), and the probability is simply its inverse, 1/100.\n\n\ncdf as we are use to\nfig, ax = plt.subplots(figsize=(10,7))\n\nT = 1 / (1-cdf_weibull)\nax.plot(T, h, 'o', label=\"return time from data\")\n\nrain = np.arange(0,150)\ncdf_rain = genextreme(c=params[0], loc=params[1], scale=params[2]).cdf(rain)\n\nax.plot(1/(1-cdf_rain), rain, color='tab:orange', lw=2, label=\"return time from gev\")\nax.legend(loc=\"upper right\", frameon=False)\nax.set(xlabel=\"return time (year)\",\n       ylabel=f\"annual daily precipitation max (mm)\",\n       xlim=[0, 125],\n       ylim=[0, 150]);\n\n\n\n\n\n\n\n\n\nIn the code below, we use 1/T as the argument for isf. Why?\nWe know that\n\nT = \\frac{1}{1-\\text{CDF}} = \\frac{1}{\\text{SF}}\n\nIf we take the reciprocal of the equation above, SF will become the inverse SF, or ISF:\n\n\\text{ISF} = \\frac{1}{T}\n\nThe code below was heavily inspired by this Stack Overflow response.\n\n\nShow the code\n# Compute the return levels for several return periods.\nreturn_periods = np.array([5, 10, 20, 50, 100, 500])\nreturn_levels = genextreme.isf(1/return_periods, *params)\n\nprint(\"Return levels:\")\nprint()\nprint(\"Period    Level\")\nprint(\"(years)   (mm)\")\n\nfor period, level in zip(return_periods, return_levels):\n    print(f'{period:4.0f}  {level:9.2f}')\n\n\nReturn levels:\n\nPeriod    Level\n(years)   (mm)\n   5      17.88\n  10      27.22\n  20      39.36\n  50      61.56\n 100      84.84\n 500     173.12\n\n\nYou might want to do the opposite: given a list of critical daily max levels, what are the return periods for them? In this case you can use the sf method, “survival function”.\n\n\nShow the code\nlevels_mm = np.array([20, 50, 100, 200, 300])\nreturn_per = 1/genextreme.sf(levels_mm, *params)\n\nprint(\"Return levels:\")\nprint()\nprint(\"Level       Period\")\nprint(\"(mm)       (years)\")\n\nfor level,period in zip(levels_mm, return_per):\n    print(f'{level:9.2f}  {period:4.0f}')\n\n\nReturn levels:\n\nLevel       Period\n(mm)       (years)\n    20.00     6\n    50.00    32\n   100.00   144\n   200.00   698\n   300.00  1798",
    "crumbs": [
      "Precipitation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "precipitation/return-period-exercises.html#fit",
    "href": "precipitation/return-period-exercises.html#fit",
    "title": "8  Exercises",
    "section": "8.3 fit",
    "text": "8.3 fit\nNot always the fit operation succeeds. Sometimes, the fitted parameters yield curves that do not seem to describe well the pdf or the cdf we are studying. What to do?\n\nALWAYS check your parameters. Plot the fitted curve against the experimental data and see with your eyes if it makes sense.\nIf it doesn’t make sense, you have to run fit again, with some changes. A common problem is that the algorithm chose initial values for the parameters that do not converge to the optimal parameters we are looking for. In this case, one needs to help fit by giving it initial guesses for the parameters, like this:\n\nlocation_guess = 6.0\nscale_guess = 5.0\nshape_guess = -0.5\nparams = genextreme.fit(data, shape_guess, loc=location_guess, scale=scale_guess)\nMore details on this can be found in the documentation.",
    "crumbs": [
      "Precipitation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "evapotranspiration/evapotranspiration-lecture.html",
    "href": "evapotranspiration/evapotranspiration-lecture.html",
    "title": "9  Evapotranspiration",
    "section": "",
    "text": "9.0.1 Potential Evapotranspiration\nDingman (2015), chapter 6.\nGlobally, about 62% of the precipitation that falls on the continents is evapotranspirated, amounting to 73 thousand km^3/yr. Of this, about 42% (29 thousand km^3/yr) is transpiration, and about 3% is open-water evaporation. Most of the remainder is interception loss; soil evaporation is a minor component of the total.\nPotential Evapotranspiration (PET) is the rate at which evapotranspiration would occur from a large area completely and uniformly covered with growing vegetation with access to an unlimited supply of soil water and without advection or heat-storage effects.\nSeveral characteristics of a vegetative surface have a strong influence on ET rate.",
    "crumbs": [
      "Evapotranspiration",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Evapotranspiration</span>"
    ]
  },
  {
    "objectID": "evapotranspiration/evapotranspiration-lecture.html#review-of-methods",
    "href": "evapotranspiration/evapotranspiration-lecture.html#review-of-methods",
    "title": "9  Evapotranspiration",
    "section": "9.1 Review of methods",
    "text": "9.1 Review of methods\nThere are a variety of ways to estimate evaporative flux in nature. The following table categorizes each method based on the data that must be acquired to apply it:\n\n\n\nSource: Ward and Trimble (2003)\n\n\nThese methods also vary in the timescales in which they are relevant, typically in correlation with the variety of data needed:\n\nThornthwaite and SCS Blaney-Criddle: monthly or seasonal estimations (minimal data)\nJensen-Haise: 5-day estimates (good enough timescale and data for irrigation scheduling)\nPenman: daily estimates\nPenman-Monteith: hourly estimates (requires a lot of data)\n\n\n\n\nSource: Ward and Trimble (2003)",
    "crumbs": [
      "Evapotranspiration",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Evapotranspiration</span>"
    ]
  },
  {
    "objectID": "evapotranspiration/evapotranspiration-lecture.html#thornthwaite",
    "href": "evapotranspiration/evapotranspiration-lecture.html#thornthwaite",
    "title": "9  Evapotranspiration",
    "section": "9.2 Thornthwaite",
    "text": "9.2 Thornthwaite\nSource: Ward and Trimble (2003), pages 107-108.\nThornthwaite (1948) developed an equation to predict monthly evapotranspiration from mean monthly temperature and latitude data (Equation 4.27). The small amount of data needed is attractive because often ET needs to be predicted for sites where few weather data are available. Based on what we know about ET, we should be skeptical about the general applicability of such a simple equation. Thornthwaite (1948) was not satisfied with the proposed approach: “The mathematical development is far from satisfactory. It is empirical. … The chief obstacle at present to the development of a rational equation is the lack of understanding of why potential ET corresponding to a given temperature is not the same everywhere.”\nTaylor and Ashcroft (1972), as cited in Skaggs (1980), provided insight into the answer to Thornthwaite’s ques- tion. They said:\n\nThis equation, being based entirely upon a temperature relationship, has the disadvantage of a rather flimsy phys- ical basis and has only weak theoretical justification. Since temperature and vapor pressure gradients are mod- ified by the movement of air and by the heating of the soil and surroundings, the formula is not generally valid, but must be tested empirically whenever the climate is appreciably different from areas in which it has been tested. … In spite of these shortcomings, the method has been widely used. Because it is based entirely on temper- ature data that are available in a large number of localities, it can be applied in situations where the basic data of the Penman method are not available.\n\nM.E. Jensen et al. (1990) warn that Thornthwaite’s method is generally only applicable to areas that have climates similar to that of the east central U.S., and it is not applicable to arid and semiarid regions.\nThornthwaite (1948) found that evapotranspiration could be predicted from an equation of the form\n\nE = 16\\left[ \\frac{10\\,T^\\text{monthly mean}}{I} \\right]^a,\n where \nI = \\sum_{i=1}^{12} \\left[ \\frac{T_i^\\text{monthly mean}}{5} \\right]^{1.514},\n and \n\\begin{split}\na =& +6.75\\times 10^{-7}I^3 \\\\\n   &- 7.71\\times 10^{-5}I^2 \\\\\n   &+ 1.792\\times 10^{-2}I \\\\\n   &+ 0.49239\n\\end{split}\n\n\nE is the monthly potential ET (mm)\nT_\\text{monthly mean} is the mean monthly temperature in °C\nI is a heat index\na is a location-dependent coefficient",
    "crumbs": [
      "Evapotranspiration",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Evapotranspiration</span>"
    ]
  },
  {
    "objectID": "evapotranspiration/evapotranspiration-lecture.html#penman",
    "href": "evapotranspiration/evapotranspiration-lecture.html#penman",
    "title": "9  Evapotranspiration",
    "section": "9.3 Penman",
    "text": "9.3 Penman\nSources:\nBrutsaert (2005), pages 123-127.\nWard and Trimble (2003), subsections 4.5.2, 4.5.3, 4.5.5, 4.6.6.\nAllen et al. (1998), “Crop evapotranspiration - Guidelines for computing crop water requirements - FAO Irrigation and drainage paper 56”\nThe Penman model is almost entirely a theory-based formula for predicting evaporative flux. It can run on a much finer timescale, and requires a much wider variety of data than most models. In addition to temperature, the Penman functions on measurements of radiation, wind speed, elevation above sea level, vapor-pressure deficit, and heat flux density to the ground. The potential ET (in mm d^{-1}) is given by:\n\nE = \\frac{1}{\\lambda}\\left[ \\frac{\\Delta}{\\Delta+\\gamma}Q_{ne}+ \\frac{\\gamma}{\\Delta+\\gamma}E_A \\right],\n\nwhere Q_n is the available energy flux density\n\nQ_n = R_n - G,\n\nand E_A is the drying power of the air\n\nE_A = 6.43\\cdot f(u)\\cdot\\text{VPD}.\n\nThe constituents of the equations above are\n\nE: potential evapotranspiration (mm d^{-1})\n\\Delta: slope of the saturation water vapor pressure curve (kPa °C^{-1})\n\\gamma: psychrometric constant (kPA °C^{-1})\n\\lambda: latent heat of vaporization (MJ kg^{-1})\nR_n: net radiation (MJ m^{-2} d^{-1})\nG: heat flux density to the ground (MJ m^{-2} d^{-1})\nf(u): wind function (dimensionless)\nVPD: vapor pressure deficit (kPa)\n\nand the number 6.43 adjusts the units of E_A so it is in MJ m^{-2} d^{-1}. In what follows, we will further discuss these constituents.\n\n9.3.1 Psychrometric Constant\nThe psychrometric constant \\gamma (kPA °C^{-1}) relates the partial pressure of water in air to the air temperature:\n\n\\begin{split}\n    \\gamma &= \\frac{c_p\\, P}{\\lambda\\cdot MW_\\text{ratio}} \\\\\n    P &= 101.3-0.01055 H \\\\\n    \\lambda &= 2.501 - 2.361\\times 10^{-3}\\,T\n\\end{split}\n\n\nMW_\\text{ratio}=0.622: ratio molecular weight of water vapor/dry air\nP: atmospheric pressure (kPa). Can be either measured or inferred from station height above sea level (m).\n\\lambda: latent heat of water vaporization (MJ kg^{-1})\nc_p=0.001013: specific heat capacity of moist air (MJ kg^{-1} °C^{-1})\n\n\n\n9.3.2 Net Radiation\nSource: Ward and Trimble (2003), page 99.\nR_n (MJ m^{-2} d^{-1}) is net radiation, the balance between net short wave R_s and the long wave R_b components of the radiation:\n\nR_n = (1-\\alpha)R_s\\!\\! \\downarrow -R_b \\!\\! \\uparrow,\n\nwhere \\alpha (dimensionless) is the albedo. The net outgoing thermal radiation R_b is given by\n\nR_b = \\left( a\\frac{R_s}{R_{so}+b} \\right)R_{bo},\n\nwhere R_{so} is the solar radiation on a cloudless day, and it depends on latitude and day of the year. R_{bo} is given by\n\nR_{bo} = \\epsilon\\, \\sigma\\, T^4_{Kelvin},\n\nwhere \\sigma=4.903\\times 10^{-9} MJ m^{-2} d^{-1} K^{-4}, and \\epsilon is net net emissivity:\n\n\\epsilon=-0.02+0.261 \\exp\\left(-7.77\\times10^{-4}T_{Celcius}^2\\right).\n\nThe parameters a and b are determined for the climate of the area:\n\na=1.0, b=0.0 for humid areas,\na=1.2, b=-0.2 for arid areas,\na=1.1, b=-0.1 for semihumid areas.\n\nWe can find below a table for R_{so}, from Ward and Trimble (2003), page 100. \n\n\n9.3.3 Heat Flux Density to the Ground\nThe heat flux density to the ground G (MJ m^{-2} d^{-1}) can be calculated using\n\n    G = 4.2\\frac{T_{i+1}-T_{i-1}}{\\Delta t},\n\nwhere \\Delta t is the time in days between midpoints of time periods i+1 and i−1, and T is the air temperature (°C).\nThis expression is really a finite differences implementation of a time derivative:\n\n\\displaystyle \\frac{\\text{d}T}{\\text{d}t} = \\lim_{\\Delta t\\rightarrow 0}\\frac{T(t+\\Delta t) - T(t-\\Delta t)}{2\\Delta t}.\n\n\n\n\n9.3.4 Vapor Pressure\nSource: Ward and Trimble (2003), page 95.\nThe Vapor Pressure Deficit (VPD, in kPa) is the difference between saturation vapor pressure e_s and actual vapor pressure e_d:\n\n\\text{VPD} = e_s - e_d.\n\nFor temperatures ranging from 0 to 50 °C, the saturation vapor pressure can be calculated with\n\n    e_s = \\exp \\left[ \\frac{16.78\\, T -116.9}{T+237.3} \\right],\n\nand the actual vapor pressure is given by\n\n    e_d = e_s \\frac{RH}{100},\n\nwhere RH is the relative humidity (%), and the temperature T in the equations above is in degrees Celcius.\nWe can see below a graph of e_s(T)\n\n\n\nSource: Ward and Trimble (2003), page 96\n\n\nThe factor \\Delta is the slope of e_s(T). See the figure below from Brutsaert, where the saturation vapor pressure is called e^*):\n\n\n\nSource: Brutsaert (2005), page 28\n\n\nThere are a few ways of defining the function for \\Delta(T) (kPa °C^{-1}). Ward and Trimble (2003) give the following:\n\n    \\Delta = 0.200 \\cdot (0.00738\\,T + 0.8072)^7 - 0.000116,\n\nwhile differentiating the exponential expression given before yields:\n\n    \\Delta = \\frac{\\text{d} e_s}{\\text{d}T} = e_s(T)\\cdot \\frac{4098.79}{(T+237.3)^2}.\n\n\n\n9.3.5 Wind Function\nSource: Ward and Trimble (2003), page 108\n\n    f(u) = 0.26(1.0 + 0.54\\, u_2)",
    "crumbs": [
      "Evapotranspiration",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Evapotranspiration</span>"
    ]
  },
  {
    "objectID": "evapotranspiration/evapotranspiration-lecture.html#pitfalls",
    "href": "evapotranspiration/evapotranspiration-lecture.html#pitfalls",
    "title": "9  Evapotranspiration",
    "section": "10.1 Pitfalls",
    "text": "10.1 Pitfalls\nDifferent books and papers will present slightly different versions of the Penman equation. Basically, they differ in the units they use for the various components, and one should be vary aware of what inputs any given equation is expecting to get.\n\n\n\n\nAllen, Richard G, Luis S Pereira, Dirk Raes, Martin Smith, et al. 1998. “Crop Evapotranspiration-Guidelines for Computing Crop Water Requirements-FAO Irrigation and Drainage Paper 56.” Fao, Rome 300 (9): D05109.\n\n\nBrutsaert, Wilfried. 2005. Hydrology: An Introduction. Cambridge University Press.\n\n\nDingman, S. L. 2015. Physical Hydrology. 3rd edition. Waveland Press, Incorporated.\n\n\nWard, Andy D, and Stanley W Trimble. 2003. Environmental Hydrology. 2nd ed. CRC Press.",
    "crumbs": [
      "Evapotranspiration",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Evapotranspiration</span>"
    ]
  },
  {
    "objectID": "evapotranspiration/evapotranspiration-exercises.html",
    "href": "evapotranspiration/evapotranspiration-exercises.html",
    "title": "10  Exercises",
    "section": "",
    "text": "10.1 Download data from the IMS\nWe will calculate evapotranspiration using two methods: Thornthwaite and Penman. After that, we will compare these estimates with measurements of pan evaporation.\nPlease follow the instructions below exactly as they are written. Go to the Israel Meteorological Service website, and download the following data:\nIf for some reason you can’t download the files following the instructions above, click here:",
    "crumbs": [
      "Evapotranspiration",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "evapotranspiration/evapotranspiration-exercises.html#download-data-from-the-ims",
    "href": "evapotranspiration/evapotranspiration-exercises.html#download-data-from-the-ims",
    "title": "10  Exercises",
    "section": "",
    "text": "10-min data\n\n\nOn the navigation bar on the left, choose “10 Minutes Observations”\nClock: Local time winter (UTC +2)\nChoose the following date range: 01/01/2020 00:00 to 01/01/2021 00:00\nChoose station Bet Dagan\nSelect units: Celcius, m/s, KJ/m^2\nUnder “Select parameters”, choose “Check All”\nChoose option “by station”, then “Submit”\n“Download Result as” CSV, call it bet-dagan-10min.csv\n\n\nradiation data\n\n\nOn the navigation bar on the left, choose “Hourly Radiation”\nClock: Local time winter (UTC +2)\nChoose the following date range: 01/01/2020 00:00 to 01/01/2021 00:00\nSelect hours: Check all hours\nChoose station Bet Dagan\nSelect units: KJ/m^2\nUnder “Select parameters”, choose “Check All”\n“Download Result as” CSV, call it bet-dagan-radiation.csv\n\n\npan evaporation data\n\n\nOn the navigation bar on the left, choose “Daily Observations”\nChoose the following date range: 01/01/2020 00:00 to 01/01/2021 00:00\nChoose station Bet Dagan Man\nSelect units: Celcius\nUnder “Select parameters”, choose “Check All”\n“Download Result as” CSV, call it bet-dagan-pan.csv\n\n\n\nbet-dagan-10min.csv\nbet-dagan-radiation.csv\nbet-dagan-pan.csv",
    "crumbs": [
      "Evapotranspiration",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "evapotranspiration/evapotranspiration-exercises.html#install-and-import-relevant-packages",
    "href": "evapotranspiration/evapotranspiration-exercises.html#install-and-import-relevant-packages",
    "title": "10  Exercises",
    "section": "10.2 Install and import relevant packages",
    "text": "10.2 Install and import relevant packages\nWe will need to use two new packages:\n\npyet: Estimation of Potential Evapotranspiration\nnoaa_ftp: Download data from NOAA\n\nIf you don’t have them installed yet, run this:\n!pip install pyet\n!pip install noaa_ftp\nOnce they are installed, import all the necessary packages for today’s exercises.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()  # datetime converter for a matplotlib\nimport seaborn as sns\nsns.set_theme(style=\"ticks\", font_scale=1.5)\nimport pyet\nfrom noaa_ftp import NOAA",
    "crumbs": [
      "Evapotranspiration",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "evapotranspiration/evapotranspiration-exercises.html#import-10-minute-data",
    "href": "evapotranspiration/evapotranspiration-exercises.html#import-10-minute-data",
    "title": "10  Exercises",
    "section": "10.3 import 10-minute data",
    "text": "10.3 import 10-minute data\n\ndf = pd.read_csv('bet-dagan-10min.csv',\n                #  encoding = \"ISO-8859-8\",  # this shows hebrew characters properly\n                 na_values=[\"-\"]           # substitute \"-\" for NaN\n                 )\ndf['timestamp'] = pd.to_datetime(df['Date & Time (Winter)'], dayfirst=True)\ndf = df.set_index('timestamp')\n# choose only relevant columns to us\n# if we don't do this the taking the mean will fail because not all columns are numeric. try df.dtypes to see why\ndf = df[[\"Temperature (°C)\",\n         \"Wind speed (m/s)\",\n         \"Pressure at station level (hPa)\",\n         \"Relative humidity (%)\"]]\n# resample to daily data according to \"mean\"\ndf = df.resample('D').mean()\n# convert hecto pascals (hPa) to kilo pascals (kPa)\ndf[\"Pressure (kPa)\"] = df[\"Pressure at station level (hPa)\"] / 10.0\ndf\n\n\n\n\n\n\n\n\nTemperature (°C)\nWind speed (m/s)\nPressure at station level (hPa)\nRelative humidity (%)\nPressure (kPa)\n\n\ntimestamp\n\n\n\n\n\n\n\n\n\n2020-01-01\n12.375000\n1.552083\n1013.263889\n80.590278\n101.326389\n\n\n2020-01-02\n12.020833\n2.207639\n1011.922917\n85.631944\n101.192292\n\n\n2020-01-03\n12.962500\n4.763194\n1013.757639\n60.756944\n101.375764\n\n\n2020-01-04\n10.849306\n5.439583\n1011.581250\n76.909722\n101.158125\n\n\n2020-01-05\n12.956250\n4.765278\n1012.361806\n79.583333\n101.236181\n\n\n...\n...\n...\n...\n...\n...\n\n\n2020-12-28\n14.797917\n2.631915\n1014.429861\n58.729167\n101.442986\n\n\n2020-12-29\n14.146528\n1.493750\n1015.031944\n71.215278\n101.503194\n\n\n2020-12-30\n14.186806\n1.776389\n1013.234028\n68.923611\n101.323403\n\n\n2020-12-31\n14.915278\n1.395833\n1011.840972\n75.465278\n101.184097\n\n\n2021-01-01\n11.600000\n0.700000\n1011.800000\n95.000000\n101.180000\n\n\n\n\n367 rows × 5 columns",
    "crumbs": [
      "Evapotranspiration",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "evapotranspiration/evapotranspiration-exercises.html#import-radiation-data",
    "href": "evapotranspiration/evapotranspiration-exercises.html#import-radiation-data",
    "title": "10  Exercises",
    "section": "10.4 import radiation data",
    "text": "10.4 import radiation data\n\ndf_rad = pd.read_csv('bet-dagan-radiation.csv',\n                     na_values=[\"-\"]\n                     )\ndf_rad['Date'] = pd.to_datetime(df_rad['Date'], dayfirst=True)\ndf_rad = df_rad.set_index('Date')\ndf_rad\n\n\n\n\n\n\n\n\nStation\nRadiation type\nHourly radiation 05-06 (KJ/m^2)\nHourly radiation 06-07 (KJ/m^2)\nHourly radiation 07-08 (KJ/m^2)\nHourly radiation 08-09 (KJ/m^2)\nHourly radiation 09-10 (KJ/m^2)\nHourly radiation 10-11 (KJ/m^2)\nHourly radiation 11-12 (KJ/m^2)\nHourly radiation 12-13 (KJ/m^2)\nHourly radiation 13-14 (KJ/m^2)\nHourly radiation 14-15 (KJ/m^2)\nHourly radiation 15-16 (KJ/m^2)\nHourly radiation 16-17 (KJ/m^2)\nHourly radiation 17-18 (KJ/m^2)\nHourly radiation 18-19 (KJ/m^2)\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2020-01-01\nBet Dagan Rad 01/1991-04/2024\nGlobal\n0.0\n10.8\n270.0\n594.0\n1252.8\n1407.6\n1800.0\n1587.6\n1443.6\n1123.2\n482.4\n57.6\n0.0\n0.0\n\n\n2020-01-01\nBet Dagan Rad 01/1991-04/2024\nDirect\n0.0\n3.6\n72.0\n428.4\n1393.2\n1281.6\n1911.6\n1414.8\n1112.4\n1083.6\n752.4\n0.0\n0.0\n0.0\n\n\n2020-01-01\nBet Dagan Rad 01/1991-04/2024\nDiffused\n0.0\n10.8\n216.0\n403.2\n543.6\n586.8\n590.4\n684.0\n770.4\n637.2\n252.0\n57.6\n0.0\n0.0\n\n\n2020-01-02\nBet Dagan Rad 01/1991-04/2024\nGlobal\n0.0\n10.8\n241.2\n518.4\n1018.8\n93.6\n129.6\n345.6\n720.0\n673.2\n478.8\n82.8\n0.0\n0.0\n\n\n2020-01-02\nBet Dagan Rad 01/1991-04/2024\nDirect\n0.0\n3.6\n57.6\n100.8\n471.6\n0.0\n0.0\n32.4\n140.4\n334.8\n680.4\n79.2\n0.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2020-12-31\nBet Dagan Rad 01/1991-04/2024\nDirect\n0.0\n0.0\n892.8\n1998.0\n2455.2\n2696.4\n2710.8\n2545.2\n2386.8\n2066.4\n1328.4\n169.2\n0.0\n0.0\n\n\n2020-12-31\nBet Dagan Rad 01/1991-04/2024\nDiffused\n0.0\n14.4\n158.4\n270.0\n320.4\n360.0\n388.8\n403.2\n378.0\n316.8\n219.6\n54.0\n0.0\n0.0\n\n\n2021-01-01\nBet Dagan Rad 01/1991-04/2024\nGlobal\n0.0\n14.4\n302.4\n882.0\n1432.8\n1814.4\n1962.0\n1897.2\n1602.0\n1170.0\n572.4\n75.6\n0.0\n0.0\n\n\n2021-01-01\nBet Dagan Rad 01/1991-04/2024\nDirect\n0.0\n0.0\n662.4\n1576.8\n2181.6\n2412.0\n2422.8\n2343.6\n2188.8\n1980.0\n1350.0\n126.0\n0.0\n0.0\n\n\n2021-01-01\nBet Dagan Rad 01/1991-04/2024\nDiffused\n0.0\n14.4\n172.8\n352.8\n421.2\n478.8\n525.6\n540.0\n478.8\n381.6\n237.6\n57.6\n0.0\n0.0\n\n\n\n\n1098 rows × 16 columns\n\n\n\nChoose only “Global” radiation. Then sum all hours of the day, and convert from kJ to MJ.\n\ndf_rad = df_rad[df_rad[\"Radiation type\"] == \"Global \"]\ndf_rad['daily_radiation_MJ_per_m2_per_day'] = (df_rad.iloc[:, 2:]    # take all rows, columns 2 to end\n                                                           .sum(axis=1) /  # sum all columns\n                                                           1000            # divide by 1000 to convert from kJ to MJ\n                                                    )\ndf_rad\n\n/var/folders/c3/7hp0d36n6vv8jc9hm2440__00000gn/T/ipykernel_93264/3322402408.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_rad['daily_radiation_MJ_per_m2_per_day'] = (df_rad.iloc[:, 2:]    # take all rows, columns 2 to end\n\n\n\n\n\n\n\n\n\nStation\nRadiation type\nHourly radiation 05-06 (KJ/m^2)\nHourly radiation 06-07 (KJ/m^2)\nHourly radiation 07-08 (KJ/m^2)\nHourly radiation 08-09 (KJ/m^2)\nHourly radiation 09-10 (KJ/m^2)\nHourly radiation 10-11 (KJ/m^2)\nHourly radiation 11-12 (KJ/m^2)\nHourly radiation 12-13 (KJ/m^2)\nHourly radiation 13-14 (KJ/m^2)\nHourly radiation 14-15 (KJ/m^2)\nHourly radiation 15-16 (KJ/m^2)\nHourly radiation 16-17 (KJ/m^2)\nHourly radiation 17-18 (KJ/m^2)\nHourly radiation 18-19 (KJ/m^2)\ndaily_radiation_MJ_per_m2_per_day\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2020-01-01\nBet Dagan Rad 01/1991-04/2024\nGlobal\n0.0\n10.8\n270.0\n594.0\n1252.8\n1407.6\n1800.0\n1587.6\n1443.6\n1123.2\n482.4\n57.6\n0.0\n0.0\n10.0296\n\n\n2020-01-02\nBet Dagan Rad 01/1991-04/2024\nGlobal\n0.0\n10.8\n241.2\n518.4\n1018.8\n93.6\n129.6\n345.6\n720.0\n673.2\n478.8\n82.8\n0.0\n0.0\n4.3128\n\n\n2020-01-03\nBet Dagan Rad 01/1991-04/2024\nGlobal\n0.0\n10.8\n334.8\n1040.4\n1612.8\n1846.8\n1904.4\n1947.6\n1296.0\n964.8\n669.6\n46.8\n0.0\n0.0\n11.6748\n\n\n2020-01-04\nBet Dagan Rad 01/1991-04/2024\nGlobal\n0.0\n3.6\n97.2\n237.6\n208.8\n208.8\n93.6\n79.2\n352.8\n144.0\n183.6\n36.0\n0.0\n0.0\n1.6452\n\n\n2020-01-05\nBet Dagan Rad 01/1991-04/2024\nGlobal\n0.0\n7.2\n118.8\n226.8\n421.2\n882.0\n1296.0\n1090.8\n1242.0\n1101.6\n388.8\n79.2\n0.0\n0.0\n6.8544\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2020-12-28\nBet Dagan Rad 01/1991-04/2024\nGlobal\n0.0\n14.4\n349.2\n1000.8\n1551.6\n1810.8\n2048.4\n1796.4\n1627.2\n993.6\n482.4\n68.4\n0.0\n0.0\n11.7432\n\n\n2020-12-29\nBet Dagan Rad 01/1991-04/2024\nGlobal\n0.0\n14.4\n342.0\n936.0\n1530.0\n1926.0\n2088.0\n1994.4\n1702.8\n1216.8\n604.8\n64.8\n0.0\n0.0\n12.4200\n\n\n2020-12-30\nBet Dagan Rad 01/1991-04/2024\nGlobal\n0.0\n21.6\n302.4\n986.4\n1526.4\n1922.4\n2080.8\n2019.6\n1720.8\n1238.4\n612.0\n68.4\n0.0\n0.0\n12.4992\n\n\n2020-12-31\nBet Dagan Rad 01/1991-04/2024\nGlobal\n0.0\n14.4\n324.0\n954.0\n1476.0\n1861.2\n2012.4\n1908.0\n1627.2\n1159.2\n565.2\n72.0\n0.0\n0.0\n11.9736\n\n\n2021-01-01\nBet Dagan Rad 01/1991-04/2024\nGlobal\n0.0\n14.4\n302.4\n882.0\n1432.8\n1814.4\n1962.0\n1897.2\n1602.0\n1170.0\n572.4\n75.6\n0.0\n0.0\n11.7252\n\n\n\n\n366 rows × 17 columns\n\n\n\nNow we can add the daily radiation we have just calculated to the first dataframe containing temperature, RH, etc.\n\ndf['daily_radiation_MJ_per_m2_per_day'] =  df_rad['daily_radiation_MJ_per_m2_per_day']\ndf\n\n\n\n\n\n\n\n\nTemperature (°C)\nWind speed (m/s)\nPressure at station level (hPa)\nRelative humidity (%)\nPressure (kPa)\ndaily_radiation_MJ_per_m2_per_day\n\n\ntimestamp\n\n\n\n\n\n\n\n\n\n\n2020-01-01\n12.375000\n1.552083\n1013.263889\n80.590278\n101.326389\n10.0296\n\n\n2020-01-02\n12.020833\n2.207639\n1011.922917\n85.631944\n101.192292\n4.3128\n\n\n2020-01-03\n12.962500\n4.763194\n1013.757639\n60.756944\n101.375764\n11.6748\n\n\n2020-01-04\n10.849306\n5.439583\n1011.581250\n76.909722\n101.158125\n1.6452\n\n\n2020-01-05\n12.956250\n4.765278\n1012.361806\n79.583333\n101.236181\n6.8544\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n2020-12-28\n14.797917\n2.631915\n1014.429861\n58.729167\n101.442986\n11.7432\n\n\n2020-12-29\n14.146528\n1.493750\n1015.031944\n71.215278\n101.503194\n12.4200\n\n\n2020-12-30\n14.186806\n1.776389\n1013.234028\n68.923611\n101.323403\n12.4992\n\n\n2020-12-31\n14.915278\n1.395833\n1011.840972\n75.465278\n101.184097\n11.9736\n\n\n2021-01-01\n11.600000\n0.700000\n1011.800000\n95.000000\n101.180000\n11.7252\n\n\n\n\n367 rows × 6 columns",
    "crumbs": [
      "Evapotranspiration",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "evapotranspiration/evapotranspiration-exercises.html#import-pan-evaporation-data",
    "href": "evapotranspiration/evapotranspiration-exercises.html#import-pan-evaporation-data",
    "title": "10  Exercises",
    "section": "10.5 import pan evaporation data",
    "text": "10.5 import pan evaporation data\n\ndf_pan = pd.read_csv('bet-dagan-pan.csv',\n                     na_values=[\"-\"]           # substitute \"-\" for NaN\n                    )\ndf_pan['Date'] = pd.to_datetime(df_pan['Date'], dayfirst=True)\ndf_pan = df_pan.set_index('Date')\ndf_pan\n\n\n\n\n\n\n\n\nStation\nMaximum Temperature (°C)\nMinimum Temperature (°C)\nGrass Temperature (°C)\nHail\nFrost\nSnow\nFog\nThunder\nLightening\nSand storm\nGale\nAccumulated 6 hr evaporation (mm)\nAccumulated 12 hr evaporation (mm)\nDaily evaporation type A (mm)\nDaily evaporation type A code (code)\nSunshine duration (minutes)\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2020-01-01\nBet Dagan Man 01/1964-04/2024\nNaN\nNaN\nNaN\n0\nNaN\n0\n0\n0\n0\n0\nNaN\nNaN\nNaN\n0.8\n0.0\nNaN\n\n\n2020-01-02\nBet Dagan Man 01/1964-04/2024\nNaN\nNaN\nNaN\n0\nNaN\n0\n0\n1\n0\n0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2020-01-03\nBet Dagan Man 01/1964-04/2024\nNaN\nNaN\nNaN\n0\nNaN\n0\n0\n0\n0\n0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2020-01-04\nBet Dagan Man 01/1964-04/2024\nNaN\nNaN\nNaN\n0\nNaN\n0\n0\n1\n0\n0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2020-01-05\nBet Dagan Man 01/1964-04/2024\nNaN\nNaN\nNaN\n0\nNaN\n0\n0\n1\n0\n0\nNaN\nNaN\nNaN\n2.4\n0.0\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2020-12-28\nBet Dagan Man 01/1964-04/2024\nNaN\nNaN\nNaN\n0\nNaN\n0\n0\n0\n0\n0\nNaN\nNaN\nNaN\n3.0\n0.0\nNaN\n\n\n2020-12-29\nBet Dagan Man 01/1964-04/2024\nNaN\nNaN\nNaN\n0\nNaN\n0\n0\n0\n0\n0\nNaN\nNaN\nNaN\n1.8\n0.0\nNaN\n\n\n2020-12-30\nBet Dagan Man 01/1964-04/2024\nNaN\nNaN\nNaN\n0\nNaN\n0\n0\n0\n0\n0\nNaN\nNaN\nNaN\n2.4\n0.0\nNaN\n\n\n2020-12-31\nBet Dagan Man 01/1964-04/2024\nNaN\nNaN\nNaN\n0\nNaN\n0\n0\n0\n0\n0\nNaN\nNaN\nNaN\n1.7\n0.0\nNaN\n\n\n2021-01-01\nBet Dagan Man 01/1964-04/2024\nNaN\nNaN\nNaN\n0\nNaN\n0\n0\n0\n0\n0\nNaN\nNaN\nNaN\n1.5\n0.0\nNaN\n\n\n\n\n367 rows × 17 columns",
    "crumbs": [
      "Evapotranspiration",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "evapotranspiration/evapotranspiration-exercises.html#calculate-penman",
    "href": "evapotranspiration/evapotranspiration-exercises.html#calculate-penman",
    "title": "10  Exercises",
    "section": "10.6 calculate penman",
    "text": "10.6 calculate penman\nWe need some data about the Bet Dagan Station. See here.\n\nLatitude: 32.0073°\nElevation: 31 m\n\n\n# the site elevation [m]\nelevation = 31.0\n# the site latitude [rad]\nlatitude = pyet.utils.deg_to_rad(32.0073)\npenm = pyet.combination.penman(tmean=df[\"Temperature (°C)\"],\n                               wind=df[\"Wind speed (m/s)\"],\n                               pressure=df[\"Pressure (kPa)\"],\n                               elevation=elevation,\n                               rh=df[\"Relative humidity (%)\"],\n                               rs=df[\"daily_radiation_MJ_per_m2_per_day\"],\n                               lat=latitude,\n                              )\n\n\nfig, ax = plt.subplots(1)\nax.plot(penm, label=\"penman\")\nax.plot(df_pan[\"Daily evaporation type A (mm)\"], label=\"pan\")\nax.legend()\nplt.gcf().autofmt_xdate()  # makes slanted dates\nax.set_ylabel(\"ET (mm)\");",
    "crumbs": [
      "Evapotranspiration",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "evapotranspiration/evapotranspiration-exercises.html#thornthwaite",
    "href": "evapotranspiration/evapotranspiration-exercises.html#thornthwaite",
    "title": "10  Exercises",
    "section": "10.7 Thornthwaite",
    "text": "10.7 Thornthwaite\n\nE = 16\\left[ \\frac{10\\,T^\\text{monthly mean}}{I} \\right]^a,\n\nwhere\n\nI = \\sum_{i=1}^{12} \\left[ \\frac{T_i^\\text{monthly mean}}{5} \\right]^{1.514},\n\nand\n\n\\begin{split}\na &= 6.75\\times 10^{-7}I^3 \\\\\n   &- 7.71\\times 10^{-5}I^2 \\\\\n   &+ 1.792\\times 10^{-2}I \\\\\n   &+ 0.49239 \\nonumber\n\\end{split}\n\n\nE is the monthly potential ET (mm)\nT_\\text{monthly mean} is the mean monthly temperature in °C\nI is a heat index\na is a location-dependent coefficient\n\nFrom df, make a new dataframe, df_th, that stores monthly temperatures means. Use resample function.\n\n# monthly data\ndf_th = (df['Temperature (°C)'].resample('MS')  # MS assigns mean to first day in the month\n                               .mean()\n                               .to_frame()\n        )\n        \n# we now add 14 days to the index, so that all monthly data is in the middle of the month\n# not really necessary, makes plot look better\ndf_th.index = df_th.index + pd.DateOffset(days=14)\ndf_th\n\n\n\n\n\n\n\n\nTemperature (°C)\n\n\ntimestamp\n\n\n\n\n\n2020-01-15\n12.484812\n\n\n2020-02-15\n14.044349\n\n\n2020-03-15\n16.371381\n\n\n2020-04-15\n18.476339\n\n\n2020-05-15\n23.177769\n\n\n2020-06-15\n24.666423\n\n\n2020-07-15\n27.380466\n\n\n2020-08-15\n28.099328\n\n\n2020-09-15\n28.421644\n\n\n2020-10-15\n25.058944\n\n\n2020-11-15\n19.266082\n\n\n2020-12-15\n15.915031\n\n\n2021-01-15\n11.600000\n\n\n\n\n\n\n\nCalculate I, then a, and finally E_p. Add E_p as a new column in df_th.\n\n# Preparing \"I\" for the Thornthwaite equation\nI = np.sum(\n             (\n               df_th['Temperature (°C)'] / 5\n             ) ** (1.514)\n          )\n\n# Preparing \"a\" for the Thornthwaite equation\na = (+6.75e-7 * I**3 \n     -7.71e-5 * I**2\n     +1.792e-2 * I\n     + 0.49239)\n\n# The final Thornthwaite model for monthly potential ET (mm)\ndf_th['Ep (mm/month)'] = 16*(\n                               (\n                                  10 * df_th['Temperature (°C)'] / I\n                               ) ** a\n                            )\ndf_th\n\n\n\n\n\n\n\n\nTemperature (°C)\nEp (mm/month)\n\n\ntimestamp\n\n\n\n\n\n\n2020-01-15\n12.484812\n20.695370\n\n\n2020-02-15\n14.044349\n27.765987\n\n\n2020-03-15\n16.371381\n40.716009\n\n\n2020-04-15\n18.476339\n55.071668\n\n\n2020-05-15\n23.177769\n96.997621\n\n\n2020-06-15\n24.666423\n113.308714\n\n\n2020-07-15\n27.380466\n147.047919\n\n\n2020-08-15\n28.099328\n156.877841\n\n\n2020-09-15\n28.421644\n161.409587\n\n\n2020-10-15\n25.058944\n117.864618\n\n\n2020-11-15\n19.266082\n61.138581\n\n\n2020-12-15\n15.915031\n37.941007\n\n\n2021-01-15\n11.600000\n17.225130\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(1)\nax.plot(penm, label=\"penman\")\nax.plot(df_pan[\"Daily evaporation type A (mm)\"], label=\"pan\")\nax.plot(df_th['Ep (mm/month)']/30, label=\"thornthwaite\")\n\nax.legend()\nplt.gcf().autofmt_xdate()  # makes slated dates\nax.set_ylabel(\"ET (mm/day)\")\n\nText(0, 0.5, 'ET (mm/day)')",
    "crumbs": [
      "Evapotranspiration",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "evapotranspiration/evapotranspiration-exercises.html#data-from-noaa",
    "href": "evapotranspiration/evapotranspiration-exercises.html#data-from-noaa",
    "title": "10  Exercises",
    "section": "10.8 Data from NOAA",
    "text": "10.8 Data from NOAA\nLet’s download data from a different repository. More specifically, we will retrieve sub-hourly data from the U.S. Climate Reference Network. We can see all the sites in this map. Besides the sub-hourly data, we can find other datasets (monthly, daily, etc).\nAs an example, we will choose the station near Austin, Texas.\n \nThe Austin 33 NW station has coordinates (30.62000, -98.08000) and an elevation of 1361 m above sea level. Its climate is classified as humid subtropical. Rainfall is evenly distributed rainfall throughout the year, averaging around 870 mm per year. The summer is hot and long, where average maximum temperatures reach 35 °C in July and August. The coldest month is January, with average maximum temperatures of 17 °C.\nThis station lies in the transition zone between the humid regions of the American Southwest and the dry deserts of the American Southwest.\nIn order to download, we will access the data from the FTP client using the python package noaa_ftp.\nThe dir command list everything in the folder:\n\nnoaa_dir = NOAA(\"ftp.ncdc.noaa.gov\", 'pub/data/uscrn/products/subhourly01').dir()\n\ndrwxrwsr-x   2 ftp      ftp          8192 Oct  7  2020 2006\ndrwxrwsr-x   2 ftp      ftp          8192 Nov 10  2021 2007\ndrwxrwsr-x   2 ftp      ftp          8192 Dec  1  2020 2008\ndrwxrwsr-x   2 ftp      ftp         12288 May 25  2021 2009\ndrwxrwsr-x   2 ftp      ftp         12288 Nov 10  2021 2010\ndrwxrwsr-x   2 ftp      ftp         12288 Nov 12  2021 2011\ndrwxrwsr-x   2 ftp      ftp         12288 Nov 12  2021 2012\ndrwxrwsr-x   2 ftp      ftp         12288 Nov 15  2021 2013\ndrwxrwsr-x   2 ftp      ftp         12288 Nov 15  2021 2014\ndrwxrwsr-x   2 ftp      ftp         12288 Nov 12  2021 2015\ndrwxrwsr-x   2 ftp      ftp         12288 Nov 12  2021 2016\ndrwxrwsr-x   2 ftp      ftp         12288 Nov 15  2021 2017\ndrwxrwsr-x   2 ftp      ftp         12288 Nov 12  2021 2018\ndrwxrwsr-x   2 ftp      ftp         12288 Nov 24  2021 2019\ndrwxrwsr-x   2 ftp      ftp         12288 Nov 30  2021 2020\ndrwxrwsr-x   2 ftp      ftp         12288 Jan 29  2022 2021\ndrwxrwsr-x   2 ftp      ftp         12288 Aug 23  2022 2022\ndrwxrwsr-x   2 ftp      ftp         12288 Nov 29  2023 2023\ndrwxrwsr-x   2 ftp      ftp         12288 Apr  9 16:53 2024\n-rw-rw-r-x   1 ftp      ftp          2157 Feb 18  2022 headers.txt\n-rw-rw-r-x   1 ftp      ftp           456 Oct  7  2020 HEADERS.txt\n-rw-rw-r-x   1 ftp      ftp         14892 Feb 18  2022 readme.txt\n-rw-rw-r-x   1 ftp      ftp         14936 Sep 21  2021 README.txt\ndrwxrwsr-x   2 ftp      ftp          8192 May 27 01:50 snapshots\n\n\nIt’s worth clicking here to see this directory with your own eyes. You can use your browser to explore this. Click on readme.txt and, well, read it.\nLet’s download two files:\n\nsub-hourly data for the year 2022 for Austin, TX.\nthe HEADERS.txt contains the names of the columns in the csv.\n\nType the following lines:\nnoaa = NOAA(\"ftp.ncdc.noaa.gov\", 'pub/data/uscrn/products/subhourly01').download('HEADERS.txt')\nnoaa = NOAA(\"ftp.ncdc.noaa.gov\", 'pub/data/uscrn/products/subhourly01/2022').download('CRNS0101-05-2022-TX_Austin_33_NW.txt')\nIf for some reason you can’t download directly from NOAA, click here to get the files:\n\nHEADERS.txt\nCRNS0101-05-2022-TX_Austin_33_NW.txt\n\n\n# Read column names from another file\ncolumn_names = pd.read_csv('HEADERS.txt',\n                           header=None,\n                           sep='\\s+',\n                           )\n# Read CSV file using column names from another file\ndf = pd.read_csv(\"CRNS0101-05-2022-TX_Austin_33_NW.txt\",  # file to read\n                 sep='\\s+',  # use (any number of) white spaces as delimiter between columns\n                 names=column_names.iloc[1],  # column names from row i=1 of \"column_names\"\n                 na_values=[-99, -9999, -99999],  # substitute these values by NaN\n                 )\n# make integer column LST_DATE as string\ndf['LST_DATE'] = df['LST_DATE'].astype(str)#.apply(lambda x: f'{x:0&gt;4}')\n# make integer column LST_DATE as string\n# pad numbers with 0 from the left, such that 15 becomes 0015\ndf['LST_TIME'] = df['LST_TIME'].apply(lambda x: f'{x:0&gt;4}')\n# combine both DATE and TIME \ndf['datetime'] = pd.to_datetime(df['LST_DATE'] + df['LST_TIME'], format='%Y%m%d%H%M')\ndf = df.set_index('datetime')\ndf\n\n\n\n\n\n\n\n\nWBANNO\nUTC_DATE\nUTC_TIME\nLST_DATE\nLST_TIME\nCRX_VN\nLONGITUDE\nLATITUDE\nAIR_TEMPERATURE\nPRECIPITATION\n...\nST_TYPE\nST_FLAG\nRELATIVE_HUMIDITY\nRH_FLAG\nSOIL_MOISTURE_5\nSOIL_TEMPERATURE_5\nWETNESS\nWET_FLAG\nWIND_1_5\nWIND_FLAG\n\n\ndatetime\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2021-12-31 18:05:00\n23907\n20220101\n5\n20211231\n1805\n2.623\n-98.08\n30.62\n23.3\n0.0\n...\nC\n0\n66.0\n0\nNaN\nNaN\n964.0\n0\n1.48\n0\n\n\n2021-12-31 18:10:00\n23907\n20220101\n10\n20211231\n1810\n2.623\n-98.08\n30.62\n23.3\n0.0\n...\nC\n0\n66.0\n0\nNaN\nNaN\n964.0\n0\n1.48\n0\n\n\n2021-12-31 18:15:00\n23907\n20220101\n15\n20211231\n1815\n2.623\n-98.08\n30.62\n23.2\n0.0\n...\nC\n0\n66.0\n0\nNaN\nNaN\n964.0\n0\n1.01\n0\n\n\n2021-12-31 18:20:00\n23907\n20220101\n20\n20211231\n1820\n2.623\n-98.08\n30.62\n23.1\n0.0\n...\nC\n0\n66.0\n0\nNaN\nNaN\n964.0\n0\n0.51\n0\n\n\n2021-12-31 18:25:00\n23907\n20220101\n25\n20211231\n1825\n2.623\n-98.08\n30.62\n22.7\n0.0\n...\nC\n0\n68.0\n0\nNaN\nNaN\n964.0\n0\n0.67\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2022-12-31 17:40:00\n23907\n20221231\n2340\n20221231\n1740\n2.623\n-98.08\n30.62\n20.8\n0.0\n...\nC\n0\n37.0\n0\nNaN\nNaN\n964.0\n0\n2.92\n0\n\n\n2022-12-31 17:45:00\n23907\n20221231\n2345\n20221231\n1745\n2.623\n-98.08\n30.62\n20.7\n0.0\n...\nC\n0\n37.0\n0\nNaN\nNaN\n963.0\n0\n2.94\n0\n\n\n2022-12-31 17:50:00\n23907\n20221231\n2350\n20221231\n1750\n2.623\n-98.08\n30.62\n20.6\n0.0\n...\nC\n0\n37.0\n0\nNaN\nNaN\n962.0\n0\n3.61\n0\n\n\n2022-12-31 17:55:00\n23907\n20221231\n2355\n20221231\n1755\n2.623\n-98.08\n30.62\n20.4\n0.0\n...\nC\n0\n38.0\n0\nNaN\nNaN\n962.0\n0\n3.03\n0\n\n\n2022-12-31 18:00:00\n23907\n20230101\n0\n20221231\n1800\n2.623\n-98.08\n30.62\n20.1\n0.0\n...\nC\n0\n39.0\n0\nNaN\nNaN\n961.0\n0\n2.32\n0\n\n\n\n\n105120 rows × 23 columns\n\n\n\nThe provided data is not the same as what is provided by the IMS.\n\nNow we don’t have air pressure values, so we need to provide elevation.\nWe do have R_n (net radiation), so there is no need to provide latitude.\n\nAttention! According to the headers file, net radiation provided by NOAA is in W m^{-2}, but pyet requires it to be MJ m^{-2} d^{-1}. We need to agreggate the downloaded data into daily radiation.\n\n10.8.1 method 1: averaging net radiation for the day\nWe can calculate the average of the net radiation for each day, and then just multiply it by the number of seconds in a day (86400 s). Finally, convert Joules to MJ by multiplying by 10^{-6}. This will give us the total energy received in 1 day, in J m^{-2}. Remember that you can easily compute daily averages using the resample function.\ndf_radiation = df['SOLAR_RADIATION'].resample('D').mean() \ndf_radiation = df_radiation  * (24*60*60) * 10**-6\n\n\n10.8.2 method 2: unit conversion\nData comes in 5-minute intervals, so if we have a value x W m^{-2} over a 5-minute interval, the total amount of energy is:\n\nx \\frac{W}{m^{-2}}\\times 5\\, min = x \\frac{J}{m^{-2}\\cdot s}\\times 5\\cdot 60\\, s = x\\cdot 5 \\cdot 60 \\frac{J}{m^{-2}}\n\nLet’s call X=\\sum_{day}x. Then, summing all energy in 1 day:\n\n\\sum_{day}x \\cdot 5 \\cdot 60 \\frac{J}{m^{-2}\\cdot day} = \\sum_{day}x \\cdot 5 \\cdot 60\\cdot 10^{-6} \\frac{MJ}{m^{-2}\\cdot day}\n\ndf_radiation = df['SOLAR_RADIATION'].resample('D').sum()\ndf_radiation = X * 5 * 60 * 1e-6\nBoth methods yield the same result, but I would recommend using method 1, as it is more intuitive and does not require prior knowledge of the data’s time interval.\n\n\n10.8.3 aggregate data into one dataframe of daily frequency\nMake a new dataframe with daily means for temperature, relative humidity and wind speed.\n\ndf_TX = df[['AIR_TEMPERATURE',\n            'RELATIVE_HUMIDITY',\n            'WIND_1_5']].resample('D').mean()\ndf_TX\n\n\n\n\n\n\n\n\nAIR_TEMPERATURE\nRELATIVE_HUMIDITY\nWIND_1_5\n\n\ndatetime\n\n\n\n\n\n\n\n2021-12-31\n21.721127\n79.985915\n2.113662\n\n\n2022-01-01\n18.336806\n65.833333\n2.586840\n\n\n2022-01-02\n-0.222222\n46.187500\n3.849757\n\n\n2022-01-03\n4.592708\n36.927083\n0.892778\n\n\n2022-01-04\n9.964583\n41.996528\n2.428924\n\n\n...\n...\n...\n...\n\n\n2022-12-27\n6.534375\n50.871528\n1.881597\n\n\n2022-12-28\n14.418056\n65.090278\n3.289167\n\n\n2022-12-29\n16.878125\n72.934028\n2.068750\n\n\n2022-12-30\n13.047917\n51.006944\n1.180729\n\n\n2022-12-31\n15.010138\n58.387097\n2.590276\n\n\n\n\n366 rows × 3 columns\n\n\n\n\n# method 1\nX = df['SOLAR_RADIATION'].resample('D').mean() \nX = X * (24*60*60) * 10**-6\n# method 2\n# X = df['SOLAR_RADIATION'].resample('D').sum()\n# X = X * 5 * 60 * 1e-6\ndf_TX['SOLAR_RADIATION'] = X\ndf_TX\n\n\n\n\n\n\n\n\nAIR_TEMPERATURE\nRELATIVE_HUMIDITY\nWIND_1_5\nSOLAR_RADIATION\n\n\ndatetime\n\n\n\n\n\n\n\n\n2021-12-31\n21.721127\n79.985915\n2.113662\n0.0000\n\n\n2022-01-01\n18.336806\n65.833333\n2.586840\n7.2870\n\n\n2022-01-02\n-0.222222\n46.187500\n3.849757\n14.2536\n\n\n2022-01-03\n4.592708\n36.927083\n0.892778\n14.4309\n\n\n2022-01-04\n9.964583\n41.996528\n2.428924\n14.2056\n\n\n...\n...\n...\n...\n...\n\n\n2022-12-27\n6.534375\n50.871528\n1.881597\n11.5200\n\n\n2022-12-28\n14.418056\n65.090278\n3.289167\n10.9917\n\n\n2022-12-29\n16.878125\n72.934028\n2.068750\n5.9829\n\n\n2022-12-30\n13.047917\n51.006944\n1.180729\n2.9967\n\n\n2022-12-31\n15.010138\n58.387097\n2.590276\n12.7248\n\n\n\n\n366 rows × 4 columns\n\n\n\n\n\n10.8.4 calculate PET and plot\nLet’s use PYET to calculate the potential ET. This is the time to go to the library’s GitHub page and read the functions: https://github.com/pyet-org/pyet/tree/master\n\nelevation = 358\npenm2 = pyet.combination.penman(tmean=df_TX[\"AIR_TEMPERATURE\"],\n                                wind=df_TX[\"WIND_1_5\"],\n                                elevation=elevation,\n                                rh=df_TX[\"RELATIVE_HUMIDITY\"],\n                                rn=df_TX[\"SOLAR_RADIATION\"],\n                                )\n\n\nfig, ax = plt.subplots(1)\nax.plot(penm2, label=\"penman\")\nplt.gcf().autofmt_xdate()  # makes slanted dates\nax.set_ylabel(\"ET (mm/day)\");\n\n\n\n\n\n\n\n\nDoes this make sense? How can we know?\nWhat happens if we download data from a station, and we’re missing Solar Radiation? What to do? The library PYET can infer solar ratiation given the station latitude and the number of daylight hours in the day.\n\nlat = 30.62  # degrees\nlat = pyet.utils.deg_to_rad(lat)\ndf_TX['daylight_hours'] = pyet.meteo_utils.daylight_hours(tmean.index, lat)\npenm3 = pyet.combination.penman(tmean=df_TX[\"AIR_TEMPERATURE\"],\n                                wind=df_TX[\"WIND_1_5\"],\n                                elevation=elevation,\n                                rh=df_TX[\"RELATIVE_HUMIDITY\"],\n                                lat=lat,\n                                n=df_TX['daylight_hours'],\n                                )\n\n\nfig, ax = plt.subplots(1)\nax.plot(penm2, label=\"with radiation data\")\nax.plot(penm3, label=\"without radiation data\")\nax.legend()\nplt.gcf().autofmt_xdate()  # makes slated dates\nax.set_ylabel(\"ET (mm/day)\")\n\nText(0, 0.5, 'ET (mm/day)')\n\n\n\n\n\n\n\n\n\n\nes = pyet.meteo_utils.calc_es(tmean=df_TX[\"AIR_TEMPERATURE\"])\nea = pyet.meteo_utils.calc_ea(tmean=df_TX[\"AIR_TEMPERATURE\"],\n                              rh=df_TX[\"RELATIVE_HUMIDITY\"])\nvpd = es - ea\n\n\nsns.set_theme(style=\"ticks\", font_scale=1.0)\nfig, ax = plt.subplots(6,1, figsize=(10,15), sharex=True)\nax[0].plot(penm2); ax[0].set_ylabel(\"potential ET (mm/day)\")\nax[1].plot(df_TX['AIR_TEMPERATURE']); ax[1].set_ylabel(\"temperature (°C)\")\nax[2].plot(df_TX['RELATIVE_HUMIDITY']); ax[2].set_ylabel(\"relative humidity (%)\")\nax[3].plot(df_TX['WIND_1_5']); ax[3].set_ylabel(\"wind speed (m/s)\")\nax[4].plot(df_TX['SOLAR_RADIATION']); ax[4].set_ylabel(\"solar radiation (MJ/m2/day)\")\nax[5].plot(vpd); ax[5].set_ylabel(\"VPD (kPa)\")\n\nText(0, 0.5, 'VPD (kPa)')\n\n\n\n\n\n\n\n\n\nCan you see some patterns from the graphs above? Let’s focus on the relationship between ET and solar radiation.\n\nsns.set_theme(style=\"ticks\", font_scale=1.0)\nfig, ax = plt.subplots(2,1, figsize=(10,8), sharex=True)\nax[0].plot(penm2); ax[0].set_ylabel(\"potential ET (mm/day)\")\nax[1].plot(df_TX['SOLAR_RADIATION']); ax[1].set_ylabel(\"solar radiation (MJ/m2/day)\")\n\nText(0, 0.5, 'solar radiation (MJ/m2/day)')",
    "crumbs": [
      "Evapotranspiration",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "infiltration/infiltration.html",
    "href": "infiltration/infiltration.html",
    "title": "Infiltration",
    "section": "",
    "text": "Here are some of the files we’ll use in this module, in case you can’t download them from their original repositories.\n\ninput rate 78 mm/h, 16% slope\ninput rate 156 mm/h, 16% slope\ninput rate 234 mm/h, 16% slope\ninput rate 312 mm/h, 16% slope",
    "crumbs": [
      "Infiltration"
    ]
  },
  {
    "objectID": "infiltration/infiltration-lecture.html",
    "href": "infiltration/infiltration-lecture.html",
    "title": "11  Infiltration",
    "section": "",
    "text": "11.1 Definitions\nHillel (2003), Introduction to Environmental Soil Physics, figure 14.6\nDingman (2015), figure 8.13\nDingman (2015), figure 8.14\nHillel (2003), Introduction to Soil Physics, figure 12.3\nSource: Dingman (2015), page 355\nSource: Ward and Trimble (2003), page 63, 64\nInfiltration capacity of absorbent paper is low, there is much runoff\nInfiltration capacity of sponge is high, there is little runoff\nInfiltration capacity of the sponge is limited by the overlying layer with low permeability\nInfiltration capacity of the sponge is limited by the underlying layer",
    "crumbs": [
      "Infiltration",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Infiltration</span>"
    ]
  },
  {
    "objectID": "infiltration/infiltration-lecture.html#definitions",
    "href": "infiltration/infiltration-lecture.html#definitions",
    "title": "11  Infiltration",
    "section": "",
    "text": "The water-input rate, w(t) [L T^{-1}], is the rate at which water arrives at the surface due to rain, snowmelt, or irrigation. A water-input event begins at time t=0 and ends at t=T_w.\nThe infiltration rate, f(t) [L T^{-1}], is the rate at which water enters the soil from the surface.\nThe infiltrability, also called infiltration capacity, f^*(t) [L T^{-1}], is the maximum rate at which infiltration could occur at any time; note that this changes during the infiltration event.\nThe depth of ponding, H(t) [L], is the depth of water standing on the surface.\n\n\n\n\n\n\n\n\n\n\nWard and Trimble (2003), page 65",
    "crumbs": [
      "Infiltration",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Infiltration</span>"
    ]
  },
  {
    "objectID": "infiltration/infiltration-lecture.html#darcy",
    "href": "infiltration/infiltration-lecture.html#darcy",
    "title": "11  Infiltration",
    "section": "11.2 Darcy",
    "text": "11.2 Darcy\nDarcy’s equation for vertical flow \nq = -K \\frac{\\partial H_\\text{total}}{\\partial z}\n\nwhere the total head H_\\text{total}=-H_\\text{suction}-z_\\text{depth}, and\n\nH_\\text{suction} is the suction head (negative pressure head)\nz_\\text{depth} is the depth, points downward.\n\nSubstituting:\n\nq = K \\frac{\\partial H_\\text{suction}}{\\partial z} + K\n\nSubstituting the above into the continuity equation\n\n\\frac{\\partial \\theta}{\\partial t} = \\frac{\\partial q}{\\partial z}\n\nyields the Richards equation.",
    "crumbs": [
      "Infiltration",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Infiltration</span>"
    ]
  },
  {
    "objectID": "infiltration/infiltration-lecture.html#richards",
    "href": "infiltration/infiltration-lecture.html#richards",
    "title": "11  Infiltration",
    "section": "11.3 Richards",
    "text": "11.3 Richards\nRichards equation:\n\n\\frac{\\partial \\theta}{\\partial t} = \\frac{\\partial}{\\partial z}\n\\left[\nK(\\theta)\n\\frac{\\partial H_\\text{total}}{\\partial z}\n\\right]\n\nSubstituting H_\\text{total}=-H_\\text{suction}-z_\\text{depth} yields:\n\n\\frac{\\partial \\theta}{\\partial t} = \\frac{\\partial}{\\partial z}\n\\left[\nK(\\theta)\n\\left(\n\\frac{\\partial(-H_\\text{suction} - z)}{\\partial z}\n\\right)\n\\right]\n\n\n\\frac{\\partial \\theta}{\\partial t} =\n-\n\\underbrace{\n\\frac{\\partial}{\\partial z}\n\\left(\nK(\\theta)\n\\frac{\\partial H_\\text{suction}}{\\partial z}\n\\right)\n}\n_{\\text{matric}}\n-\n\\underbrace{\n\\frac{\\partial K(\\theta)}{\\partial z}\n}\n_{\\text{gravitational}}\n\n\n11.3.1 short times\nAs the water starts to enter the relatively dry soil, the pressure differences in the water at the surface and in the soil are quite large and, as a result, the second term on the right is practically negligible compared to the first one.\n\n\\frac{\\partial \\theta}{\\partial t} =\n-\n\\frac{\\partial}{\\partial z}\n\\left(\nK(\\theta)\n\\frac{\\partial H}{\\partial z}\n\\right)\n\n\n\n11.3.2 long times\nAs illustrated in the figure below (Davidson et al., 1963), after longer times of infiltration, the water content profile near the surface gradually becomes more uniform and it eventually assumes the satiation value, or \\theta\\rightarrow \\theta_0; similarly, the pressure in the upper layers of the soil becomes gradually atmospheric, or H \\rightarrow 0. Hence, their vertical gradients \n\n\\frac{\\partial\\theta}{\\partial z} \\text{ and } \\frac{\\partial H_\\text{suction}}{\\partial z} \\longrightarrow 0\n\nFrom Darcy’s equation we have that\n\nq = K(\\theta_0) = K_\\text{sat}\n\n\n\n\n11.3.3 Rainfall infiltration\nInfiltration rate is equal to rainfal rate, at least at first. If rainfall rate w is lower than K_\\text{sat}, than everything enters the soil, i.e., f=K_\\text{sat}. However, if w&gt;K_\\text{sat}, water content \\theta will increase at the surface, until it reaches \\theta_0, and at that moment, called ponding time t_p, water will begin to accumulate at the surface.\nHillel (2003), figure 12.1 \nHillel (2003), figure 12.2",
    "crumbs": [
      "Infiltration",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Infiltration</span>"
    ]
  },
  {
    "objectID": "infiltration/infiltration-lecture.html#horton-equation",
    "href": "infiltration/infiltration-lecture.html#horton-equation",
    "title": "11  Infiltration",
    "section": "11.4 Horton equation",
    "text": "11.4 Horton equation\nOne of the most widely used models, developed by R.E. Horton (1939), considered to be the father of modern hydrology.\n\nf = f_c+(f_0-f_c)e^{-\\beta t}\n\n\nf: infiltration rate\nf_c: infiltration capacity at large t\nf_0: initial infiltration capacity\n\\beta: best fit empirical parameter\n\nAdvantages\n\nSimple equation\nUsually gives good fit to measured data because it is dependent on three parameters\n\nDisadvantages\n\nThis method has no physical significance, it is not based on any water transport mechanism\nDoes not describe infiltration prior to ponding",
    "crumbs": [
      "Infiltration",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Infiltration</span>"
    ]
  },
  {
    "objectID": "infiltration/infiltration-lecture.html#green-ampt",
    "href": "infiltration/infiltration-lecture.html#green-ampt",
    "title": "11  Infiltration",
    "section": "11.5 Green & Ampt",
    "text": "11.5 Green & Ampt\nDingman (2015), figure 8.11 \nAssumptions:\n\nhomogeneous soil, infinite depth (no water table)\nhorizontal surface\nconstant water head equal to zero is maintained at the surface\nuniform water content prior to wetting, \\theta(t=0,z)=\\theta_0\nmoving front is characterized by a constant matric suction, \\psi_f\n\nSource: Dingman (2015), page 370\nThis equation was developed under the scenario of constant rainfall or irrigation on an initially dry soil as a sharp wetting front (such as piston flow). Water penetrates a dry soil with a certain initial moisture content, and wets the layer to a saturated moisture content as it traverses deeper. The connection between soil moisture and infiltration rate is modeled in the Green-Ampt equation:\n\nf(t) = K_\\text{sat}\n\\left[\n1 + \\frac{|\\psi_f|\\cdot \\left( \\phi - \\theta_0 \\right)}{F(t)}\n\\right]\n\n\nf(t): infiltration rate\nF(t): cumulative infiltration rate, F=\\int\\! f \\text{ d}t\n\\psi_f: effective wetting-front suction\n\\phi: soil porosity\n\\theta_0: initial soil water content\n\nThe same equation can be simply be rewritten as\nf = \\frac{A}{F} + B\nwhere\n\nA = K_\\text{sat}\\cdot|\\psi_f|\\cdot \\left( \\phi - \\theta_0 \\right)\nB= K_\\text{sat}\n\nThe porosity \\phi and the saturated hydraulic conductivity K_\\text{sat} can be estimated from the soil texture. The wetting-front suction \\psi_f can be estimated using the Brooks-Corey parameters: \n\n|\\psi_f| = \\frac{2b+3}{2b+6}\\cdot |\\psi_{ae}|,\n\nwhere \\psi_{ae} is the air-entry pressure head. Values for the parameters above can be found in this table:",
    "crumbs": [
      "Infiltration",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Infiltration</span>"
    ]
  },
  {
    "objectID": "infiltration/infiltration-lecture.html#best-fit-least-squares-method",
    "href": "infiltration/infiltration-lecture.html#best-fit-least-squares-method",
    "title": "11  Infiltration",
    "section": "11.6 Best Fit, Least Squares Method",
    "text": "11.6 Best Fit, Least Squares Method\n\n\n\n\n\nDingman, S. L. 2015. Physical Hydrology. 3rd edition. Waveland Press, Incorporated.\n\n\nHillel, Daniel. 2003. Introduction to Environmental Soil Physics. Elsevier.\n\n\nWard, Andy D, and Stanley W Trimble. 2003. Environmental Hydrology. 2nd ed. CRC Press.",
    "crumbs": [
      "Infiltration",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Infiltration</span>"
    ]
  },
  {
    "objectID": "infiltration/infiltration-exercises.html",
    "href": "infiltration/infiltration-exercises.html",
    "title": "12  Exercises",
    "section": "",
    "text": "12.1 Tasks\nThe image is the second panel of Fig. 8, from the paper you downloaded.\nIf for any reason you’re having trouble digitizing the data from the graph, download here each csv file I have already prepared.\nImport relevant packages\nShow the code\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_theme(style=\"ticks\", font_scale=1.5)\nfrom scipy.optimize import curve_fit\nimport matplotlib.patches as patches\nLoad all four files you created. Use numpy’s function loadtxt. Make sure that the first point in each table corresponds to the appropriate rainfall rate. You can normalize the data if it is not.\nd1 = np.loadtxt(\"input_rate_078mm_per_h_16percent_slope.csv\", delimiter=',')\nd2 = np.loadtxt(\"input_rate_156mm_per_h_16percent_slope.csv\", delimiter=',')\nd3 = np.loadtxt(\"input_rate_234mm_per_h_16percent_slope.csv\", delimiter=',')\nd4 = np.loadtxt(\"input_rate_312mm_per_h_16percent_slope.csv\", delimiter=',')\n\n\"\"\"\nIn the digitization process, not all points are necessarily\nlocated in the \"correct\" location. Because we know the initial\ninfiltration rate for each data series, we can correct that and\nrescale the data so that the first point is exactly where we\nexpect it to be\n\"\"\"\nd1[:,1] = d1[:,1] * 78  / d1[:,1].max()\nd2[:,1] = d2[:,1] * 156 / d2[:,1].max()\nd3[:,1] = d3[:,1] * 234 / d3[:,1].max()\nd4[:,1] = d4[:,1] * 312 / d4[:,1].max()\nReproduce the original figure, make it look good, something like this:\nfig, ax = plt.subplots(figsize=(10,7))\nax.plot(d4[:,0], d4[:,1], 'o', markerfacecolor=\"None\", label=r\"water input = 312 mm h$^{-1}$\")\nax.plot(d3[:,0], d3[:,1], '^', label=r\"water input = 234 mm h$^{-1}$\")\nax.plot(d2[:,0], d2[:,1], 'x', label=r\"water input = 156 mm h$^{-1}$\")\nax.plot(d1[:,0], d1[:,1], 'o', label=r\"water input = 78 mm h$^{-1}$\")\nax.set(xlabel=\"time (min)\",\n       ylabel=r\"infiltration rate (mm h$^{-1}$)\")\nax.legend(loc=\"upper right\");",
    "crumbs": [
      "Infiltration",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "infiltration/infiltration-exercises.html#tasks",
    "href": "infiltration/infiltration-exercises.html#tasks",
    "title": "12  Exercises",
    "section": "",
    "text": "Download the paper\nNassif, S. H., and E. M. Wilson, 1975, “The influence of slope and rain intensity on runoff and infiltration”, Hydrological Sciences Journal.\nGoogle the following: plot digitizer\nLoad image “nassif-16percent-slope.png” (see below)\nDigitize data points from left to right. Create 4 csv files, one for each data set. Call them whatever you want.\nLegend:\n * white circle = 312 mm/h,\n * triangle = 234 mm/h,\n * x = 156 mm/h,\n * black circle = 78 mm/h.\n\n\n\n\n\ninput_rate_078mm_per_h_16percent_slope.csv\ninput_rate_156mm_per_h_16percent_slope.csv\ninput_rate_234mm_per_h_16percent_slope.csv\ninput_rate_312mm_per_h_16percent_slope.csv",
    "crumbs": [
      "Infiltration",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "infiltration/infiltration-exercises.html#hortons-equation",
    "href": "infiltration/infiltration-exercises.html#hortons-equation",
    "title": "12  Exercises",
    "section": "12.2 Horton’s equation",
    "text": "12.2 Horton’s equation\n\nf = f_c+(f_0-f_c)e^{-\\beta t}\n\n\nf: infiltration rate\nf_c: infiltration capacity at large t\nf_0: initial infiltration capacity\n\\beta: best fit empirical parameter\n\nWrite a function called horton, that receives time t and the three parameters, and returns the right-hand side of the equation above. Plot one of the data sets, together with a guess of the parameters that should roughly fit the data.\n\ndef horton(t, fc, f0, beta):\n    return fc + (f0 - fc) * np.exp(-beta*t)\n\nfig, ax = plt.subplots(figsize=(10,7))\nt = d1[:,0]\nt = t - t[0]\nf = d1[:,1]\nax.plot(t, f, 'o', label=\"data\")\nparam_guess = [35, 80, 0.5]\nax.plot(t, horton(t, *param_guess), '-', label=\"horton\")\nax.set(xlabel=\"time (min)\",\n       ylabel=\"infiltration rate (mm/h)\")\nax.legend(loc=\"upper right\");\n\n\n\n\n\n\n\n\nFind the best fit for the parameters f_c, f_0, \\beta. Calculate the R^2 for each data set.\nFor the best fit, use scipy’s curve_fit. Write a function to compute the R-squared of your fit.\n\ndef best_fit(data):\n    t = data[:,0]\n    t = t - t[0]\n    f = data[:,1]\n    # best fit\n    popt, pcov = curve_fit(f=horton,             # model function\n                           xdata=t,              # x data\n                           ydata=f,              # y data\n                           p0=(130, 800, 0.5),   # initial guess of the parameters\n                          )\n    return [popt, pcov]\n\ndef calculate_r_squared(data, popt):\n    t = data[:,0]\n    t = t - t[0]\n    f = data[:,1]\n    # Calculate residuals\n    residuals = f - horton(t, *popt)\n    # You can get the residual sum of squares (ss_res) with\n    ss_res = np.sum(residuals**2)\n    # You can get the total sum of squares (ss_tot) with\n    ss_tot = np.sum((f - np.mean(f))**2)\n    # And finally, the r_squared-value with,\n    r_squared = 1 - (ss_res / ss_tot)\n    return r_squared\n\ndef plot_best_fit(data, axis, marker, markercolor):\n    # calculate best fit parameters\n    popt, pcov = best_fit(data)\n    t = data[:,0]\n    f = data[:,1]\n    # plot data points\n    ax.plot(t, f, marker, markerfacecolor=markercolor, markeredgecolor=\"black\")\n    # plot best fit line\n    r_squared = calculate_r_squared(data, popt)\n    labeltext = r\"$f_c=$ {:.2f}, $f_0=$ {:.2f}, $\\beta=$ {:.2f}, $R^2=$ {:.2f}\".format(popt[0],popt[1],popt[2], r_squared)\n    ax.plot(t, horton(t-t[0], *popt), color=markercolor, label=labeltext)    \n\nfig, ax = plt.subplots(figsize=(10,7))\nplot_best_fit(d1, ax, 'o', \"tab:red\")\nplot_best_fit(d2, ax, 'x', \"tab:blue\")\nplot_best_fit(d3, ax, '^', \"tab:orange\")\nplot_best_fit(d4, ax, 'd', \"tab:green\")\nax.set(xlabel=\"time (min)\",\n       ylabel=\"infiltration rate (mm/h)\")\nax.legend();\n\n\n\n\n\n\n\n\nMake a graph of the infiltration rate and of the runoff, as a function of time. Use any of the four data sets you have.\n\nfig, ax = plt.subplots(figsize=(10,7))\ndata = d4\nt = data[:, 0]\nf = data[:, 1]\nt = np.concatenate([ [0], t])\nf = np.concatenate([ [f[0]], f])\nrunoff = f[0] - f\nax.plot(t, f*0 + f[0], ls=\"--\", color=\"black\", label=\"rainfall\")\nax.plot(t, f, color=\"tab:blue\", lw=3, label=r\"infiltration\")\nax.plot(t, runoff, color=\"tab:orange\", lw=3, label=r\"runoff\")\nax.set(xlabel=\"Time (min)\",\n       ylabel=r\"Rate (mm h$^{-1}$)\")\nax.legend(loc=\"lower right\");",
    "crumbs": [
      "Infiltration",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "infiltration/infiltration-exercises.html#what-does-fit-really-mean",
    "href": "infiltration/infiltration-exercises.html#what-does-fit-really-mean",
    "title": "12  Exercises",
    "section": "12.3 What does fit really mean?",
    "text": "12.3 What does fit really mean?\nLet’s take as an example data (x,y) that look to be organized in a linear trend.\n\n\nplot synthetic data\nN = 30\nx_data = np.arange(N)\na = 2.0\nb = 30.0\nnoise = 6 * (np.random.random(N)-0.5)\ny_data = a * x_data + b + noise\n\nfig, ax = plt.subplots(figsize=(10,7))\nax.plot(x_data, y_data, 'o', label=\"data\")\nax.plot(x_data, -0.5*x_data + 40, label=\"first guess of a linear model\")\n\nax.annotate(\"\",\n            xy=(x_data[20], y_data[20]), xycoords='data',\n            xytext=(x_data[20], 29), textcoords='data',\n            size=20,\n            arrowprops=dict(arrowstyle=\"&lt;-&gt;\",\n                            color=\"black\",\n                            connectionstyle=\"arc3\"),\n            )\nax.text(20.5, 50, \"error\")\nax.legend(frameon=False)\nax.set(xlabel=\"x\",\n       ylabel=\"y\",\n       ylim=[0,120]);\n\n\n\n\n\n\n\n\n\nOur guess doesn’t look good. We used the model\n\ny = ax + b\n\nwhere a=-0.5 and b=40.\nWe will adjust these two parameters by minimizing the mean error between each data point and the model (straight line). We need to minimize the following expression:\n\n\\begin{split}\nMSE &= \\text{mean}(\\text{error}^2) \\\\\nMSE &= \\frac{1}{N}\\sum_{i=1}^N\\text{error}^2 \\\\\nMSE &= \\frac{1}{N}\\sum_{i=1}^N\\large( \\text{measured} - \\text{modelled} \\large)^2 \\\\\nMSE &=  \\frac{1}{N}\\sum_{i=1}^N \\large[ y_i - (a\\cdot x_i +b) \\large]^2\n\\end{split}\n\nThe MSE is a function of a and b. For every set of values (a,b), MSE has value, so you can imagine a surface in the (a,b) plane.\n\n\ndefine useful funcitons\ndef compute_mse(y_measured, y_predicted):\n    MSE = np.mean(\n        (y_measured - y_predicted)**2\n    )\n    return MSE\n\ndef linear_model(x, a, b):\n    return a*x + b\n\ndef gradient_descent(x, y, a, b, learning_rate):\n    # linear model\n    y_predicted = a * x + b\n    error = y - y_predicted\n    # partial derivatives\n    da = np.mean(-2 * x * error)\n    db = np.mean(-2 * error)\n    # update a and b. minus sign because gradient points to direction\n    # of maximal growth, we want to minimize MSE, not maximize\n    a = a - da * learning_rate\n    b = b - db * learning_rate\n    mse = compute_mse(y, y_predicted)\n    return a, b, mse\n\n\n\n\ncompute MSE landscape\nA_vec = np.linspace(-1, 5, 100)\nB_vec = np.linspace(0, 60, 100)\nA_mesh, B_mesh = np.meshgrid(A_vec, B_vec)\nMSE_mesh = np.zeros_like(A_mesh)\nfor i in range(100):\n    for j in range(100):\n        Y_predicted_mesh = linear_model(x_data,\n                                        A_mesh[i, j],\n                                        B_mesh[i, j])\n        MSE_mesh[i, j] = compute_mse(y_data, Y_predicted_mesh)\n\nMSE_mesh_log = np.log(MSE_mesh)\n\n\n\n\nplot landscape\nfig, ax = plt.subplots(figsize=(10,7))\nA_min = A_vec[0]; A_max = A_vec[-1];\nB_min = B_vec[0]; B_max = B_vec[-1];\nasp = (A_max - A_min) / (B_max - B_min)\ncax = ax.imshow(MSE_mesh_log, extent=[A_min, A_max, B_min, B_max],\n                origin='lower', cmap='viridis', aspect = asp)\nfig.colorbar(cax)\nax.set(xlabel=r\"parameter $a$\",\n       ylabel=r\"parameter $b$\",\n       title=\"log(MSE)\");\n\n\n\n\n\n\n\n\n\nThe gradient of MSE is:\n\n\\nabla MSE = \\frac{\\partial}{\\partial a}MSE\\; \\widehat{a} + \\frac{\\partial}{\\partial b}MSE\\; \\widehat{b}\n\nTaking the partial derivatives:\n\n\\begin{split}\n\\frac{\\partial}{\\partial a}MSE &= \\frac{1}{N}\\sum_{i=1}^N (-2x_i)\\large[ y_i - (a\\cdot x_i +b)\\large] \\\\\n&= \\text{mean}\\large[ (-2x_i) \\cdot \\large( \\text{measured} - \\text{modelled} \\large) \\large]  \\\\\n\\frac{\\partial}{\\partial b}MSE &= \\frac{1}{N}\\sum_{i=1}^N (-2) \\large[y_i - (a\\cdot x_i +b)\\large] \\\\\n&= \\text{mean}\\large[ (-2) \\cdot \\large( \\text{measured} - \\text{modelled} \\large) \\large]\n\\end{split}\n\n\n\noptimize parameters using gradient descent\nlr = 1.0e-3\nn_iterations = 30000\na_fit = np.zeros(n_iterations)\nb_fit = np.zeros(n_iterations)\nmse_fit = np.zeros(n_iterations)\na_fit[0] = -0.5\nb_fit[0] = 40.0\nfor i in np.arange(1, n_iterations):\n    a_fit[i], b_fit[i], mse_fit[i] = gradient_descent(x=x_data, y=y_data, a=a_fit[i-1], b=b_fit[i-1], learning_rate=lr)\nprint(f\"best fit: a={a_fit[-1]:.2f}, b={b_fit[-1]:.2f}\")\n\n\nbest fit: a=2.03, b=29.60\n\n\n\n\nplot landscape and optimization path\nfig, ax = plt.subplots(figsize=(10,7))\nA_min = A_vec[0]; A_max = A_vec[-1];\nB_min = B_vec[0]; B_max = B_vec[-1];\nasp = (A_max - A_min) / (B_max - B_min)\ncax = ax.imshow(MSE_mesh_log, extent=[A_min, A_max, B_min, B_max],\n                origin='lower', cmap='viridis', aspect = asp)\nfig.colorbar(cax)\n\nax.plot(a_fit, b_fit, color=\"xkcd:hot pink\")\nax.plot(a_fit[0], b_fit[0], linestyle='None', marker='&gt;', markerfacecolor='none', markeredgecolor='xkcd:hot pink', markersize=12)\nax.plot(a_fit[-1], b_fit[-1], linestyle='None', marker='s', markerfacecolor='none', markeredgecolor='xkcd:hot pink', markersize=12)\n\nax.set(xlabel=r\"parameter $a$\",\n       ylabel=r\"parameter $b$\",\n       title=\"log(MSE)\");\n\n\n\n\n\n\n\n\n\n\n\nplot incremental improvement of the model\nfig, ax = plt.subplots(figsize=(10,7))\nax.plot(x_data, y_data, 'o', label=\"data\")\n\niter_list = [1, 2, 10, 1000, 30000]\ncolor_list = np.linspace(0.8, 0.1, len(iter_list))\n\nfor i in range(len(iter_list)):    \n    ax.plot(x_data, a_fit[iter_list[i]-1] * x_data + b_fit[iter_list[i]-1],\n            label=f\"iteration={iter_list[i]:d}\",\n            color=[color_list[i]]*3\n            )\nax.set(xlabel=\"x\",\n       ylabel=\"y\")\nax.legend(frameon=False, fontsize=12);\n\n\n\n\n\n\n\n\n\n\n12.3.1 learning rate\nThe learning rate multiplies the gradient (partial derivatives in each parameter direction), therefore by playing with its values, we can converge slower or faster to the optimal solution we are seeking. There is a tradeoff in play here. If the learning curve is too small, we will have to run a lot of simulations steps to converge to the desired solution. On the other hand, if the learning rate is too large, the algorithm might not be able to converge to the region of the parameter space with the lowest MSE.\n\n\noptimize parameters using gradient descent\nlr = 1.4e-3\nn_iterations = 5000\na_fit_2 = np.zeros(n_iterations)\nb_fit_2 = np.zeros(n_iterations)\nmse_fit_2 = np.zeros(n_iterations)\na_fit_2[0] = -0.5\nb_fit_2[0] = 40.0\nfor i in np.arange(1, n_iterations):\n    a_fit_2[i], b_fit_2[i], mse_fit_2[i] = gradient_descent(x=x_data, y=y_data, a=a_fit_2[i-1], b=b_fit_2[i-1], learning_rate=lr)\n# print(f\"best fit: a={a_fit_2[-1]:.2f}, b={b_fit_2[-1]:.2f}\")\n\n\nbest fit: a=2.01, b=29.87\n\n\n\n\noptimize parameters using gradient descent\nlr = 5e-4\nn_iterations = 5000\na_fit_3 = np.zeros(n_iterations)\nb_fit_3 = np.zeros(n_iterations)\nmse_fit_3 = np.zeros(n_iterations)\na_fit_3[0] = -0.5\nb_fit_3[0] = 40.0\nfor i in np.arange(1, n_iterations):\n    a_fit_3[i], b_fit_3[i], mse_fit_3[i] = gradient_descent(x=x_data, y=y_data, a=a_fit_3[i-1], b=b_fit_3[i-1], learning_rate=lr)\n# print(f\"best fit: a={a_fit_3[-1]:.2f}, b={b_fit_3[-1]:.2f}\")\n\n\nbest fit: a=1.88, b=32.44\n\n\n\n\noptimize parameters using gradient descent\nlr = 3.5e-3\nn_iterations = 5000\na_fit_4 = np.zeros(n_iterations)\nb_fit_4 = np.zeros(n_iterations)\nmse_fit_4 = np.zeros(n_iterations)\na_fit_4[0] = -0.5\nb_fit_4[0] = 40.0\nfor i in np.arange(1, n_iterations):\n    a_fit_4[i], b_fit_4[i], mse_fit_4[i] = gradient_descent(x=x_data, y=y_data, a=a_fit_4[i-1], b=b_fit_4[i-1], learning_rate=lr)\n# print(f\"best fit: a={a_fit_4[-1]:.2f}, b={b_fit_4[-1]:.2f}\")\n\n\nbest fit: a=1551.68, b=108.47\n\n\n\n\nShow the code\nfig, ax = plt.subplots(figsize=(10,7))\n\ncmap = plt.cm.Blues\ncolors = [cmap(0.9), cmap(0.6), cmap(0.3)]\n\nax.plot((mse_fit_3), label=f\"learning rate = {5e-4:.2e}\", color=colors[0])\nax.plot((mse_fit), label=f\"learning rate = {1.0e-3:.2e}\", color=colors[1])\nax.plot((mse_fit_2), label=f\"learning rate = {1.4e-3:.2e}\", color=colors[2])\nax.plot([], [], label=f\"learning rate = {3.5e-3:.2e}\", color=\"tab:red\")\n\nax.set_yscale('log')\nax.set(ylim=[0, 50],\n       xlim=[0, 5000],\n       xlabel=\"iteration\",\n       ylabel=\"MSE\",\n       title=\"larger learning rates converge faster!...\\nuntil they explode\")\n\nax2 = ax.twinx()\nax2.plot((mse_fit_4), color=\"red\")\nax2.set_yscale('log')\nax2.tick_params(axis='y', labelcolor='tab:red')\nax.legend(frameon=False);\n\n\n/var/folders/c3/7hp0d36n6vv8jc9hm2440__00000gn/T/ipykernel_86050/3729129073.py:12: UserWarning: Attempt to set non-positive ylim on a log-scaled axis will be ignored.\n  ax.set(ylim=[0, 50],\n\n\n\n\n\n\n\n\n\nThis way of finding the optimal set of parameters is the first and very simplest method. Much more sophisticated methods were developed throughout the years. This basic idea of finding the optimal values for a list of parameters is the basic idea behind machine learning methods.\n\n\n12.3.2 local and global minima\nThe landscape we saw in the example above was well behaved, and we easily converged to a reasonable solution. Sometimes the landscape is more convoluted, and we might get stuck on local minima, depending on the initial conditions for the parameters. In that case, we need to help the algorithm by providing it with other initial guesses for the parameters.",
    "crumbs": [
      "Infiltration",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "infiltration/infiltration-exercises.html#green-ampt",
    "href": "infiltration/infiltration-exercises.html#green-ampt",
    "title": "12  Exercises",
    "section": "12.4 Green & Ampt",
    "text": "12.4 Green & Ampt\nf = \\frac{A}{F} + B\nwhere\n\nA = K_\\text{sat}\\cdot|\\psi_f|\\cdot \\left( \\phi - \\theta_0 \\right)\nB= K_\\text{sat}\n\nWrite a function that calculates the cumulative of the infiltration rate.\n\nF(t) = \\int_0^t f(t) \\text{ d}t\n\nUse numpy’s trapz function, that implements the “trapezoidal rule”\n\n\ndef cumulative_F(t, f):\n    F = np.array([0])\n    t = t/60 # convert minute to hour\n    for i in np.arange(2,len(t)+1):\n        area = np.trapz(f[:i], t[:i])\n        F = np.concatenate([F, [area]])\n    return F\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,7))\nt, f = d1[:,0], d1[:,1]\nF = cumulative_F(t, f)\nax1.plot(t, f, label=\"f, rate\")\nax2.plot(t, F, label=\"F, cumulative\")\nax1.set(xlabel=\"t (min)\",\n        ylabel=\"f (mm/h)\")\nax2.set(xlabel=\"t (min)\",\n        ylabel=\"F (mm)\")\nax2.yaxis.set_label_position(\"right\")\n\n\n\n\n\n\n\n\nPlot f as a function of F. Try to guess A and B that give reasonable results.\n\nfig, ax = plt.subplots(figsize=(10,7))\nt, f = d1[:,0], d1[:,1]\nF = cumulative_F(t, f)\nax.plot(F, f)\nA=50; B=30;\nax.plot(F, A/F + B, 'o')\nax.set(xlabel=\"F\",\n       ylabel=\"f\");\n\n/var/folders/c3/7hp0d36n6vv8jc9hm2440__00000gn/T/ipykernel_86050/768544551.py:7: RuntimeWarning: divide by zero encountered in divide\n  ax.plot(F, A/F + B, 'o')\n\n\n\n\n\n\n\n\n\nUse the curve_fit to find the optimal values for A and B.\n\ndef G_and_A(F, A, B):\n    return A/F + B\n\npopt, pcov = curve_fit(f=G_and_A,     # model function\n                       xdata=F[1:],       # x data\n                       ydata=f[1:],       # y data\n                       p0=(50, 30),   # initial guess of the parameters\n                      )\n\n# popt, pcov = curve_fit(G_and_A, F[1:], f[1:], p0=(50, 30))  # p0 = initial guess\nprint(popt)\n\nfig, ax = plt.subplots(figsize=(10,7))\nax.plot(F, f)\nax.plot(F[1:], popt[0]/F[1:] + popt[1], 'o')\nax.set(xlabel=\"F\",\n       ylabel=\"f\");\n\n[24.12368526 36.34242813]",
    "crumbs": [
      "Infiltration",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "infiltration/infiltration-exercises.html#homework",
    "href": "infiltration/infiltration-exercises.html#homework",
    "title": "12  Exercises",
    "section": "12.5 Homework",
    "text": "12.5 Homework\nGo to Soil Texture Calculator, estimate the texture of “standard soil” in Nassif & Wilson, 1975.",
    "crumbs": [
      "Infiltration",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "streamflow/streamflow-lecture.html",
    "href": "streamflow/streamflow-lecture.html",
    "title": "13  Streamflow",
    "section": "",
    "text": "13.1 Watershed - אגן היקוות\nWatershed response:",
    "crumbs": [
      "Streamflow",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Streamflow</span>"
    ]
  },
  {
    "objectID": "streamflow/streamflow-lecture.html#watershed---אגן-היקוות",
    "href": "streamflow/streamflow-lecture.html#watershed---אגן-היקוות",
    "title": "13  Streamflow",
    "section": "",
    "text": "The volume of water appearing in the apparent response hydrograph for a given event is usually only a fraction (often a very small fraction) of the total input. The remainder of the water input ultimately leaves the watershed as:\n\nevapotranspiration;\nstreamflow that occurs so long after the event that it cannot be associated with that event; or\nground-water outflow from the watershed.\n\nThe water identified as the response to a given event may originate on only a fraction of the watershed; this fraction is called the contributing area.\nThe extent of the contributing area may vary from event to event and during an event.\nAt least some of the water identified as the response to a given event may be “old water” that entered the watershed in a previous event.",
    "crumbs": [
      "Streamflow",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Streamflow</span>"
    ]
  },
  {
    "objectID": "streamflow/streamflow-lecture.html#base-flow-separation",
    "href": "streamflow/streamflow-lecture.html#base-flow-separation",
    "title": "13  Streamflow",
    "section": "13.2 base flow separation",
    "text": "13.2 base flow separation\n\n\nBase flow\nBase flow is the portion of streamflow that is presumed to have entered the watershed in previous events and to be derived from persistent, slowly varying sources. (Ground water is usually assumed to be the main, if not the only, such source.)\n\n\nEvent flow\nEvent flow (also called direct runoff, storm runoff, quick flow, or storm flow) is considered to be the direct response to a given water-input event.\n\n\nTotal flow\nTotal flow rate at any instant q(t) is the sum of event-flow rate q^*(t) and base-flow rate q_{BF}(t):\n\nq(t) = q^*(t) + q_{BF}(t)\n\n\n\nAttention!\nGraphical flow separation techniques are heuristic and have no direct scientific basis.",
    "crumbs": [
      "Streamflow",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Streamflow</span>"
    ]
  },
  {
    "objectID": "streamflow/streamflow-lecture.html#urbana-il",
    "href": "streamflow/streamflow-lecture.html#urbana-il",
    "title": "13  Streamflow",
    "section": "13.3 Urbana, IL",
    "text": "13.3 Urbana, IL\n\n\n13.3.1 hyetograph, hydrograph\n\n\n\n13.3.2 notation\n\n\n\n13.3.3 base flow separation\n\n\n\n13.3.4 effective precipitation = effective discharge\n\nP^* = Q^*\n\n \n\n\n13.3.5 time lags\n  \nIt is commonly assumed that T_{LPC} \\simeq 0.60 \\cdot T_c, where T_c is the time of concentration, i.e., the time it takes water to travel from the hydraulically most distant part of the contributing area to the outlet.\n\nThe centroid is a weighted-average time, each time instant is multiplied by the amount of flow in that instant.\nTime of precipitation centroid:\n\nt_{pc} = \\frac{\\displaystyle \\sum_{i=1}^n p_i^* \\cdot t_i}{P^*}\n\nTime of streamflow centroid:\n\nt_{qc} = \\frac{\\displaystyle \\sum_{i=1}^n q_i^* \\cdot t_i}{Q^*}",
    "crumbs": [
      "Streamflow",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Streamflow</span>"
    ]
  },
  {
    "objectID": "streamflow/streamflow-exercises.html",
    "href": "streamflow/streamflow-exercises.html",
    "title": "14  Exercises",
    "section": "",
    "text": "Import relevant packages\nIf you have trouble downloading data from the USGS or from NOAA, click here:\n\nUSGS streamflow data\nNOAA atmospheric data\nNOAA headers file\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport seaborn as sns\nsns.set_theme(style=\"ticks\", font_scale=1.5)\nfrom ipywidgets import *\n\nImport streamflow data from USGS’s National Water Information System. We will be using data from Urbana, IL.\n\nChoose Discharge\nChange time span to year 2020\nSelect data to retrieve Primary time series\nClick on Download data button\n\n\n# Drainage area: 4.78 square miles   \ndata_file = \"USGS 03337100 BONEYARD CREEK AT LINCOLN AVE AT URBANA, IL.dat\"\ndf_q_2020 = pd.read_csv(data_file,\n                        header=31,                      # no headers needed, we'll do that later\n                        delim_whitespace=True,            # blank spaces separate between columns\n                        na_values=[\"Bkw\"]  # substitute these values for missing (NaN) values\n                )\ndf_q_2020.columns = ['agency_cd', 'site_no','datetime','tz_cd','EDT','discharge','code']                       # rename df columns with headers columns\ndf_q_2020['date_and_time'] = df_q_2020['datetime'] + ' ' + df_q_2020['tz_cd'] # combine date+time into datetime\ndf_q_2020['date_and_time'] = pd.to_datetime(df_q_2020['date_and_time'])        # interpret datetime\ndf_q_2020 = df_q_2020.set_index('date_and_time')                          # make datetime the index\ndf_q_2020['discharge'] = df_q_2020['discharge'].astype(float)\ndf_q_2020['discharge'] = df_q_2020['discharge'] * 0.0283168 # convert cubic feet to m3\n\nfig, ax = plt.subplots(figsize=(10,7))\nax.plot(df_q_2020['discharge'], '-o')\nplt.gcf().autofmt_xdate()\nax.set(xlabel=\"date\",\n       ylabel=r\"discharge (m$^3$/5min)\");\n\n/var/folders/c3/7hp0d36n6vv8jc9hm2440__00000gn/T/ipykernel_65624/154551529.py:3: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n  df_q_2020 = pd.read_csv(data_file,\n\n\n\n\n\n\n\n\n\nImport sub-hourly (5-min) rainfall data from NOAA’s Climate Reference Network Data website\n\ndata_file = \"CRNS0101-05-2020-IL_Champaign_9_SW.txt\"\ndf_p_2020 = pd.read_csv(data_file,\n                        header=None,                      # no headers needed, we'll do that later\n                        delim_whitespace=True,            # blank spaces separate between columns\n                        na_values=[\"-99.000\", \"-9999.0\"]  # substitute these values for missing (NaN) values\n                       )\nheaders = pd.read_csv(\"HEADERS.txt\",    # load headers file\n                      header=1,                    # skip the first [0] line\n                      delim_whitespace=True\n                     )\ndf_p_2020.columns = headers.columns                       # rename df columns with headers columns\n# LST = local standard time\ndf_p_2020[\"LST_TIME\"] = [f\"{x:04d}\" for x in df_p_2020[\"LST_TIME\"]]  # time needs padding of zeros, then convert to string\ndf_p_2020['LST_DATE'] = df_p_2020['LST_DATE'].astype(str)            # convert date into string\ndf_p_2020['datetime'] = df_p_2020['LST_DATE'] + ' ' + df_p_2020['LST_TIME'] # combine date+time into datetime\ndf_p_2020['datetime'] = pd.to_datetime(df_p_2020['datetime'])        # interpret datetime\ndf_p_2020 = df_p_2020.set_index('datetime')                          # make datetime the index\n\n/var/folders/c3/7hp0d36n6vv8jc9hm2440__00000gn/T/ipykernel_65624/3302633013.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n  df_p_2020 = pd.read_csv(data_file,\n/var/folders/c3/7hp0d36n6vv8jc9hm2440__00000gn/T/ipykernel_65624/3302633013.py:7: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n  headers = pd.read_csv(\"HEADERS.txt\",    # load headers file\n\n\nPlot rainfall and streamflow. Does this makes sense?\n\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,7))\nfig.subplots_adjust(hspace=0.05)\n\nstart = \"2020-10-18\"\nend = \"2020-10-25\"\nax1.plot(df_p_2020[start:end]['PRECIPITATION'])\nax2.plot(df_q_2020[start:end]['discharge'], color=\"tab:blue\", lw=2)\n\nax1.set(xticks=[],\n        ylabel=r\"precipitation (mm)\")\nax2.set(xlabel=\"date\",\n        ylabel=r\"discharge (m$^3$/5min)\")\n\nplt.gcf().autofmt_xdate()  # makes slanted dates\n\n\n\n\n\n\n\n\nDefine smaller dataframes for p(t) and q(t), between the dates:\nstart = \"2020-10-20 14:00:00\"\nend = \"2020-10-21 04:00:00\"\nDon’t forget to convert the units to SI!\nCalculate total rainfall P^* and total discharge Q^*, in m^3.\n\n# Drainage area: 4.78 square miles\narea = 4.78 / 0.00000038610  # squared miles to squared meters\nstart = \"2020-10-20 14:00:00\"\nend = \"2020-10-21 04:00:00\"\n\ndf_p = df_p_2020.loc[start:end]['PRECIPITATION'].to_frame()\ndf_p_mm = df_p_2020.loc[start:end]['PRECIPITATION'].to_frame()\ndf_q = df_q_2020.loc[start:end]['discharge'].to_frame()\n\ndf_p['PRECIPITATION'] = df_p['PRECIPITATION'].values * area / 1000  # mm to m3 in the whole watershed\ndf_p['PRECIPITATION'] = df_p['PRECIPITATION'] / 60 / 5 # convert m3 per 5 min to m3/s\n\nP = df_p['PRECIPITATION'].sum() * 60 * 5\nQ = df_q['discharge'].sum() * 60 * 5\n\nprint(\"total precipitation during event: P = {:.1e} m3\".format(P.sum()))\nprint(\"total streamflow during event: Q = {:.1e} m3\".format(Q.sum()))\n\ntotal precipitation during event: P = 2.6e+05 m3\ntotal streamflow during event: Q = 5.2e+04 m3\n\n\nMake another graph of p(t) and q(t), now with SI units.\n\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,7))\nfig.subplots_adjust(hspace=0.05)\n\nstart = \"2020-10-18\"\nend = \"2020-10-25\"\nax1.plot(df_p['PRECIPITATION'])\nax2.plot(df_q['discharge'], color=\"tab:blue\", lw=2)\n\nax1.set(xticks=[],\n        ylabel=r\"precipitation (m$^3$/s)\",\n        title=\"Precipitation and discharge, Boneyard Creek at Urbana, IL\\n 20-21 October 2020, 5-minute data\")\nax2.set(xlabel=\"date\",\n        ylabel=r\"discharge (m$^3$/s)\")\n\nplt.gcf().autofmt_xdate()  # makes slated dates\n\n\n\n\n\n\n\n\nIt’s time for base flow separation! Convert q(t) into q^*(t)\n\nfrom matplotlib.dates import HourLocator, DateFormatter\nimport matplotlib.dates as mdates\nimport matplotlib.ticker as ticker\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,7))\nfig.subplots_adjust(wspace=0.05)\n\nax1.plot(df_q['discharge'], color=\"black\", lw=2)\npoint1 = pd.to_datetime(\"2020-10-20 16:40:00\")\npoint2 = pd.to_datetime(\"2020-10-21 00:00:00\")\ntwo_points = df_q.loc[[point1, point2]]['discharge']\nax1.plot(two_points, 'o', color=\"tab:red\")\n\nnew = pd.DataFrame(data=two_points, index=two_points.index)\n\ndf_linear = (new.resample(\"5min\") #resample\n                .interpolate(method='time') #interpolate by time\n            )\n\nax1.plot(df_linear, color=\"tab:blue\")\n\ndf_between_2_points = df_q.loc[df_linear.index]\nax1.fill_between(df_between_2_points.index, df_between_2_points['discharge'],\n                 y2=df_linear['discharge'],\n                 color=\"tab:blue\", alpha=0.3)\n\nqstar = df_q.loc[df_linear.index]['discharge'] - df_linear['discharge']\nQstar = qstar.sum() * 60 * 5\n\nax2.plot(qstar, color=\"black\", lw=2)\nax2.fill_between(qstar.index, qstar,\n                 y2=0.0,\n                 color=\"tab:blue\", alpha=0.3)\n\nax1.set(xlim=[df_q.index[0],\n              df_q.index[-1]],\n        ylabel=r\"discharge (m$^3$/s)\",\n        ylim=[0, 5.5],\n        yticks=[0,1,2,3,4],\n        title=\"total discharge, q(t)\")\nax2.set(yticks=[],\n        ylim=[0, 5.5],\n        xlim=[df_q.index[0],\n              df_q.index[-1]],\n        title=\"effective discharge, q*(t)\"\n       )\n\nplt.gcf().autofmt_xdate()  # makes slated dates\n\n\n\n\n\n\n\n\nWe can calculate p^* now, using\n\nP^* = Q^*\n\nOne of the simplest methods is to multiply p(t) by a fixed constant (&lt;1) to obtain p^*, so that the equation above holds true.\n\nratio = Qstar/ P\npstar = df_p['PRECIPITATION'] * ratio\nPstar = pstar.sum() * 5 * 60\nprint(f\"Qstar / P = {ratio:.2f}\")\n\nQstar / P = 0.16\n\n\nCalculate now the centroid (t_pc) for effective precipitation p^* and centroid (t_{qc}) of effective discharge q^*. Calculate also the time of peak discharge (t_{pk}). Then, calculate the centroid lag (T_{LC}), the centroid lag-to-peak (T_{LPC}), and the time of concentration (T_c). Use the equations below:\nT_{LPC} \\simeq 0.60 \\cdot T_c\nTime of precipitation centroid:\n\nt_{pc} = \\frac{\\displaystyle \\sum_{i=1}^n p_i^* \\cdot t_i}{P^*}\n\nTime of streamflow centroid:\n\nt_{qc} = \\frac{\\displaystyle \\sum_{i=1}^n q_i^* \\cdot t_i}{Q^*}\n\nCentroid lag:\n\nT_{LC} = t_{qc} - t_{pc}\n\nCentroid lag-to-peak: \nT_{LPC} = t_{pk} - t_{pc}\n\nTime of concentration: \nT_{LPC} \\simeq 0.60 \\cdot T_c\n\n\n# pstar centroid\n# time of the first (nonzero) rainfall data point\nt0 = pstar[pstar != 0.0].index[0]\n# time of the last (nonzero) rainfall data point\ntf = pstar[pstar != 0.0].index[-1]\n# duration of the rainfall event, in minutes\ntd = (tf-t0) / pd.Timedelta('1 min')\n# make time array, add 2.5 minutes (half of dt)\ntime = np.arange(0, td+1, 5) + 2.5\n# create pi array, only with relevant data (during rainfall duration)\npi = pstar.loc[(pstar.index &gt;= t0) & (pstar.index &lt;= tf)]\n# convert from m3/5min to m3/s\npi = pi.values * 60 * 5\n# time of precipitation centroid\nt_pc = (pi * time).sum() / pi.sum()\n# add initial time\nt_pc = t0 + pd.Timedelta(minutes=t_pc)\nt_pc\n\n# qstar centroid\n# time of the first (nonzero) discharge data point\nt0 = qstar[qstar != 0.0].index[0]\n# time of the last (nonzero) discharge data point\ntf = qstar[pstar != 0.0].index[-1]\n# duration of the discharge event, in minutes\ntd = (tf-t0) / pd.Timedelta('1 min')\n# make time array, add 2.5 minutes (half of dt)\ntime = np.arange(0, td+1, 5) + 2.5\n# create qi array, only with relevant data (during discharge duration)\nqi = qstar.loc[(qstar.index &gt;= t0) & (qstar.index &lt;= tf)]\n# convert from m3/5min to m3/s\nqi = qi.values * 60 * 5\n# time of discharge centroid\nt_qc = (qi * time).sum() / qi.sum()\n# add initial time\nt_qc = t0 + pd.Timedelta(minutes=t_qc)\nt_qc\n\n# time of peak discharge\nmax_discharge = qstar.max()\nt_pk = qstar[qstar == max_discharge].index[0]\n\n# centroid lag\nT_LC = t_qc - t_pc\n\n# centroid lag-to-peak\nT_LPC = t_pk - t_pc\n\n# time of concentration\nT_c = T_LPC / 0.60\n\nprint(f\"T_LC = {T_LC}\")\nprint(f\"T_LPC = {T_LPC}\")\nprint(f\"T_c = {T_c}\")\n\nT_LC = 0 days 00:53:03.186594\nT_LPC = 0 days 01:22:59.857820\nT_c = 0 days 02:18:19.763033333",
    "crumbs": [
      "Streamflow",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "streamflow/unit-hydrograph-lecture.html",
    "href": "streamflow/unit-hydrograph-lecture.html",
    "title": "15  Unit Hydrograph",
    "section": "",
    "text": "15.1 Linear reservoir model",
    "crumbs": [
      "Streamflow",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Unit Hydrograph</span>"
    ]
  },
  {
    "objectID": "streamflow/unit-hydrograph-lecture.html#linear-reservoir-model",
    "href": "streamflow/unit-hydrograph-lecture.html#linear-reservoir-model",
    "title": "15  Unit Hydrograph",
    "section": "",
    "text": "Source: Dingman (2015), page 472",
    "crumbs": [
      "Streamflow",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Unit Hydrograph</span>"
    ]
  },
  {
    "objectID": "streamflow/unit-hydrograph-lecture.html#rainfall-runoff-models",
    "href": "streamflow/unit-hydrograph-lecture.html#rainfall-runoff-models",
    "title": "15  Unit Hydrograph",
    "section": "15.2 Rainfall-Runoff Models",
    "text": "15.2 Rainfall-Runoff Models\n\n15.2.1 The Rational Method\nThe rational method postulates a simple proportionality between peak discharge, q_{pk}, and rainfall intensity, p^*:\n\nq_{pk} = \\varepsilon_R \\cdot C_R \\cdot A_D \\cdot p^*\n\n\nq_{pk}: peak discharge (m^3/s)\n\\varepsilon_R=0.278: unit-conversion factor\nC_R: dimensionless runoff coefficient\nA_D: drainage area (km^2)\np^*: rainfall intensity (mm/h)\n\n\nObviously the results obtained with the method are highly sensitive to the value chosen for CR; values range from 0.05 for gently sloping lawns up to 0.95 for highly urbanized areas of roofs and pavement.\nThe rational method is widely used in urban drainage design, but Pilgrim and Cordery (1992) caution that there are typically few data available to guide the selection of CR, and that CR for a given watershed may vary widely from storm to storm due to differing antecedent conditions.\n\n\n\n15.2.2 The Soil Conservation Service Curve-Number Method (SCS-CN)\nAlso called NRCS curve number procedure. NRCS = Natural Resources Conservation Service - USDA\n\nQ^* = P^* = \\frac{\\left( P-S_{I} \\right)^2}{P-S_I+S_{max}},\n\nwhere\n\nQ^*: total volume of event flow in a storm event\nP^*: total volume of effective water input in a storm event\nP: total volume of water input in a storm event\nS_{I}: initial abstraction = amount of rainfall that is retained or absorbed by the land surface before runoff occurs\nS_{max}: potential maximum retention = maximum amount of water that the watershed can retain after runoff starts\n\nThe initial abstraction S_I is usually approximated as 0.2\\cdot S_{max}, therefore:\n\nQ^* = P^* = \\frac{\\left( P-0.2\\cdot S_{max} \\right)^2}{P+0.8\\cdot S_{max}}\n\n\nS_{max} = 25.4\\left(\\frac{1000}{CN}-10\\right)\n\nThe number 25.4 is a conversion factor from inches to millimeters.\n\n\n\n\n\nSource: United States Department of Agriculture (2004)\n\n\nThe curve number (CN) is a function of the ability of soils to infiltrate water, land use, and the soil water conditions at the start of a rainfall event (antecedent soil water condition). To account for the infiltration characteristics of soils, the NRCS has divided soils into four hydrologic soil groups, which are defined as follows (NRCS, 1984):\n\nGroup A (low runoff potential): Soils with high infiltration rates even when thoroughly wetted. These consist chiefly of deep, well-drained sands and gravels. These soils have a high rate of water transmission (final infiltration rate greater than 0.3 in./h).\nGroup B: Soils with moderate infiltration rates when thoroughly wetted. These consist chiefly of soils that are moderately deep to deep, moderately well drained to well drained with moderately fine to moderately coarse textures. These soils have a moderate rate of water transmission (final infil- tration rate 0.15 to 0.30 in./h).\nGroup C: Soils with slow infiltration rates when thoroughly wetted. These consist chiefly of soils with a layer that impedes downward movement of water or soils with moderately fine to fine texture. These soils have a slow rate of water transmission (final infiltration rate 0.05 to 0.15 in./h).\nGroup D (high runoff potential): Soils with very slow infiltration rates when thoroughly wetted. These consist chiefly of clay soils with a high swelling potential, soils with a permanent high water table, soils with a claypan or clay layer at or near the surface, and shallow soils over nearly impervious materials. These soils have a very slow rate of water transmission (final infiltration rate less than 0.05 in./h).\n\nThere are also three categories for Antecedent Soil Moisture Condition (AMC):\n\nAMC I: Dormant season antecedent soil moisture less than 0.5 in. Growing season antecedent soil moisture less than 1.4 in.\nAMC II: Dormant season antecedent soil moisture between 0.5 and 1.1 in. Growing season anteced- ent soil moisture between 1.4 and 2.1 in.\nAMC III: Dormant season antecedent soil mois- ture greater than 1.1 in. Growing season anteced- ent soil moisture greater than 2.1 in.\n\nSee the table below to find curve numbers for AMC II: \n\nP=21\nratio = 4.17e4/2.61e5\nCN=86\nSmax = 25.4 * (1000/CN - 10)\nPmin = 0.2 * Smax\nQstar = 0.0\nif P &gt; Pmin:\n    Qstar = (P - 0.2*Smax)**2 / (P+0.8*Smax)\nQstar/P\n\n0.14270006393832066\n\n\n\nratio\n\n0.15977011494252874\n\n\n\nQstar / P\n\n0.9148811393863234\n\n\n\n%matplotlib notebook\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef Qstar_f(pe, CN):\n#     Smax = 25.4*(1000/CN - 10)\n    Smax = (1000/CN - 10)\n#     Smax = (1000/CN - 10) / 25.4\n    Qstar = (pe - 0.2*Smax)**2 / (pe+0.8*Smax)\n    return Qstar\n\npe = np.linspace(0,8,101)\n# plt.plot(pe, Qstar_f(pe, 35))\nplt.plot(pe, Qstar_f(pe, 50))\n# plt.plot(pe, Qstar_f(pe, 85))\n\n\n\n\n\n\n\n\n\n\n\nDingman, S. L. 2015. Physical Hydrology. 3rd edition. Waveland Press, Incorporated.\n\n\nUnited States Department of Agriculture, Natural Resources Conservation Service. 2004. Estimation of Direct Runoff from Storm Rainfall. National Engineering Handbook, Part 630 Hydrology, Chapter 10. United States Department of Agriculture. https://directives.sc.egov.usda.gov/OpenNonWebContent.aspx?content=17752.wba.",
    "crumbs": [
      "Streamflow",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Unit Hydrograph</span>"
    ]
  },
  {
    "objectID": "summing-up/budyko-framework-lecture.html",
    "href": "summing-up/budyko-framework-lecture.html",
    "title": "16  Budyko framework",
    "section": "",
    "text": "16.1 Water and surface energy balances\nSources used:\nDaly et al. (2019), Sposito (2017), Jones et al. (2012), Krajewski et al. (2021), Berghuijs, Gnann, and Woods (2020), Creed and Spargo (2012)\nFor long-term averages:\nP = ET+Q\nR_n = \\lambda_w\\cdot ET + H",
    "crumbs": [
      "summing up",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Budyko framework</span>"
    ]
  },
  {
    "objectID": "summing-up/budyko-framework-lecture.html#water-and-surface-energy-balances",
    "href": "summing-up/budyko-framework-lecture.html#water-and-surface-energy-balances",
    "title": "16  Budyko framework",
    "section": "",
    "text": "P: precipitation (L T^{-1}, e.g.: mm/day)\nET: evapotranspiration (L T^{-1})\nQ: streamflow (L T^{-1})\nR_n: net energy available at soil surface (M T^{-3}, e.g.: W m^{-2})\n\\lambda_w: latent heat of vaporization of water (M L^{-1}T^{-2}, as defined here, the units will be weird)\nH: sensible heat flux from the surface into the atmosphere (M T^{-3})\n\\lambda_w \\cdot ET: latent heat flux (M T^{-3})",
    "crumbs": [
      "summing up",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Budyko framework</span>"
    ]
  },
  {
    "objectID": "summing-up/budyko-framework-lecture.html#assumptions",
    "href": "summing-up/budyko-framework-lecture.html#assumptions",
    "title": "16  Budyko framework",
    "section": "16.2 Assumptions",
    "text": "16.2 Assumptions\n\nbecause we are dealing with long-term averages, there are negligible changes of watershed stored water.\nnegligible energy is stored at the soil surface, and heat transfer from soil surface to deeper soil layers (G) averages zero.",
    "crumbs": [
      "summing up",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Budyko framework</span>"
    ]
  },
  {
    "objectID": "summing-up/budyko-framework-lecture.html#question",
    "href": "summing-up/budyko-framework-lecture.html#question",
    "title": "16  Budyko framework",
    "section": "16.3 Question",
    "text": "16.3 Question\nGiven measurements of rainfall and meteorological conditions, can we predict the partitioning of P between ET and Q?",
    "crumbs": [
      "summing up",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Budyko framework</span>"
    ]
  },
  {
    "objectID": "summing-up/budyko-framework-lecture.html#limits",
    "href": "summing-up/budyko-framework-lecture.html#limits",
    "title": "16  Budyko framework",
    "section": "16.4 Limits",
    "text": "16.4 Limits\nFor very dry watersheds (deserts, for example), almost all precipitation (P) is lost via evapotranspiration (ET). These watersheds are called water limited.\nIn wet watersheds, at the annual scale, the sensible heat (H) is directed from the surface to the atmosphere in almost all climatic zones on Earth (meaning: soil heats air). Therefore, H cannot supply much energy to the soil surface, and it is assumed that R_n provides entirely the energy required for evapotranspiration. Dividing the second equation by \\lambda_w, we get R_n/\\lambda_w = ET + H/\\lambda_w. It is clear that the maximum possible ET occurs when all incoming radiation energy R_n is consumed by evapotranspiration ET, and there is negligible sensible heat flux H. As a result, the upper limit of \\lambda_w E is R_n, in wet watersheds. In these watersheds, called energy limited, ET tends to the potential evapotranspiration (ET_0).\n\n16.4.1 Summary:\nFor energy-limited watersheds\n\n\nAs precipitation P\\rightarrow \\infty, evapotranspiration ET\\rightarrow ET_0\n\n\nFor water-limited watersheds\n\n\nAs potential evapotranspiration ET_0\\rightarrow \\infty, actual evaporation ET\\rightarrow P\n\n\nIn general, we can write\n\nET = f(P,ET_0)\n\nThe variables P and ET have the same dimenstions (L T^{-1}), and we can divide the equation above by P:\n\n\\frac{ET}{P} = f(D_I),\n\nwhere \nD_I = \\displaystyle\\frac{ET_0}{P}\n is called the dryness index. A useful classification is\n\n\n\nDryness Index\nClassification\n\n\n\n\nD_I &lt; 1.54\nHumid\n\n\n1.54 &lt; D_I &lt; 2\nDry Subhumid\n\n\n2 &lt; D_I &lt; 5\nSemi-arid\n\n\n5 &lt; D_I &lt; 20\nArid\n\n\n20 &lt; D_I\nHyper-arid\n\n\n\n\nATTENTION. The dryness index can also be called the “Aridity Index” (AI), however sometimes the AI means the inverse of D_I:\nAI = 1/D_I\nBe careful to check the definitions.\nThe summary (1) and (2) above can be now represented as:\n\n\nAs D_I\\rightarrow 0, \\displaystyle\\frac{ET}{P}\\rightarrow D_I\n\n\n\n\nAs D_I\\rightarrow \\infty, \\displaystyle\\frac{ET}{P}\\rightarrow 1\n\n\nBudyko (1974), proposed the following equation:\n\n\\frac{ET}{P} = \\left[ D_I \\tanh\\left( \\frac{1}{D_I} \\right)\\left( 1-e^{-D_I} \\right) \\right]^{1/2}\n\n\n\n\n\nSource: Jones et al. (2012)\n\n\n\n\n\nSource: Krajewski et al. (2021)\n\n\nThere are many alternatives to Budyko’s equation. Many equations have adjustable parameters, such as Fu’s equation:\n\n\\frac{ET}{P} = 1 + D_I - (1 + D_I^w)^{1/w},\n\nwhere w&gt;1. Each catchment has its own specific parameter w, that may represent biophysical/landscape features. There is no concensus regarding the interpretation of w, ranging from an effective empirical parameter, whose relationship to biophysical features can be discerned, to an arbitrary empirical constant with no a priori physical meaning. Source: {% cite reaver2020reinterpreting %}\n\n\n\nSource: Zhang et al. (2004)",
    "crumbs": [
      "summing up",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Budyko framework</span>"
    ]
  },
  {
    "objectID": "summing-up/budyko-framework-lecture.html#hypotheses-for-why-dryness-index-controls-so-much-the-partitioning-of-p-into-et-and-q",
    "href": "summing-up/budyko-framework-lecture.html#hypotheses-for-why-dryness-index-controls-so-much-the-partitioning-of-p-into-et-and-q",
    "title": "16  Budyko framework",
    "section": "16.5 Hypotheses for why dryness index controls so much the partitioning of P into ET and Q",
    "text": "16.5 Hypotheses for why dryness index controls so much the partitioning of P into ET and Q\nSource: Berghuijs, Gnann, and Woods (2020)\n\nThe first is that the Budyko curve is accurate because landscape features (e.g., soils and vegetation) coevolve with the local climate in such a manner that precipitation partitioning into streamflow and evapotranspiration converges towards the Budyko curve\nA second hypothesis is that catchments over time evolve towards the supply and demand limits (rather than towards a curve), because landscapes and their vegetation are unaware of the Budyko curve but do evolve to maximize their use of available resources (including water). However, because limiting factors such as climatic variability exist (which will reduce a catchment’s ability to use all water because it cannot fully buffer the highly variable precipitation input), catchments will tend to not reach these limits. This may lead to an (apparent) existence of the Budyko curve which falls relatively close to the demand and supply limits.\nA third hypothesis is that the existence of a strong universal relationship between aridity and catchment water balances might be explained by an underlying organizing principle such as maximum entropy production because the Budyko curve may be consistent with how hydrologic systems optimally partition water and energy\nA fourth hypothesis is that virtually any landscape and climate combination (also those in heavily disturbed landscapes: e.g., a city, agricultural lands, etc.) will fall near the Budyko curve because climate aridity will dominate precipitation partitioning largely independent of the climate-landscape configuration or any optimization principle.",
    "crumbs": [
      "summing up",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Budyko framework</span>"
    ]
  },
  {
    "objectID": "summing-up/budyko-framework-lecture.html#hypotheses-for-deviations-from-budyko-curve",
    "href": "summing-up/budyko-framework-lecture.html#hypotheses-for-deviations-from-budyko-curve",
    "title": "16  Budyko framework",
    "section": "16.6 Hypotheses for deviations from Budyko curve",
    "text": "16.6 Hypotheses for deviations from Budyko curve\nSource: Creed and Spargo (2012)\n\nUnder stationary conditions (naturally occurring oscillations), catchments will fall on the Budyko Curve\nUnder non-stationary conditions (anthropogenic climate change), catchments will deviate from the Budyko Curve in a predictable manner\n\n\n16.6.1 Reasons for falling off the Budyko Curve\n\nInadequate representation of P and T (Loch Vale)\nInadequate representation of ET (Andrews)\nInadequate representation of Q (Marcell)\nForest conversion (Coweeta)\nForest disturbance (Luquillo)\n\n\n\n16.6.2 Critique\nSource: Berghuijs, Gnann, and Woods (2020)\nThe (mathematical) specifics of such studies vary, but all approaches are founded on the assumption that catchments follow a (parametric) Budyko curve when aridity changes, and that consequently all other movements in the Budyko space are caused by other factors. The validity of this assumption remains mostly untested, which seems surprising given it underpins all of these studies’ findings.\n\n\n\n\nBerghuijs, Wouter R, Sebastian J Gnann, and Ross A Woods. 2020. “Unanswered Questions on the Budyko Framework.” Journal of Hydrology 265: 164–77.\n\n\nBudyko, Mikhail Ivanovich. 1974. “Climate and Life.” (No Title).\n\n\nCreed, Irena, and Adam Spargo. 2012. “Budyko Guide to Exploring Sustainability of Water Yields from Catchments Under Changing Environmental Conditions.” London, Ontario. Http://Www. Uwo. Ca/Biology/Faculty/Creed/PDFs/Presentations/PRE116. Pdf.\n\n\nDaly, Edoardo, Salvatore Calabrese, Jun Yin, and Amilcare Porporato. 2019. “Linking Parametric and Water-Balance Models of the Budyko and Turc Spaces.” Advances in Water Resources 134: 103435.\n\n\nJones, Julia A, Irena F Creed, Kendra L Hatcher, Robert J Warren, Mary Beth Adams, Melinda H Benson, Emery Boose, et al. 2012. “Ecosystem Processes and Human Influences Regulate Streamflow Response to Climate Change at Long-Term Ecological Research Sites.” BioScience 62 (4): 390–404.\n\n\nKrajewski, Adam, Anna E Sikorska-Senoner, Leszek Hejduk, and Kazimierz Banasik. 2021. “An Attempt to Decompose the Impact of Land Use and Climate Change on Annual Runoff in a Small Agricultural Catchment.” Water Resources Management 35 (3): 881–96.\n\n\nSposito, Garrison. 2017. “Understanding the Budyko Equation.” Water 9 (4): 236.\n\n\nZhang, Lu, Klaus Hickel, WR Dawes, Francis HS Chiew, AW Western, and PR Briggs. 2004. “A Rational Function Approach for Estimating Mean Annual Evapotranspiration.” Water Resources Research 40 (2).",
    "crumbs": [
      "summing up",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Budyko framework</span>"
    ]
  },
  {
    "objectID": "summing-up/spatial-distribution.html",
    "href": "summing-up/spatial-distribution.html",
    "title": "17  Spatial distribution - lecture",
    "section": "",
    "text": "17.1 The problem\nLet’s say we want to calculate the average rainfall on a watershed, and we have data available for 7 stations, as shown in the figure below [Dingman, figure 4.26]:\nThere are a number of methods for calculating the average precipitation.",
    "crumbs": [
      "summing up",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Spatial distribution - lecture</span>"
    ]
  },
  {
    "objectID": "summing-up/spatial-distribution.html#thiessen-method-voronoi-diagram",
    "href": "summing-up/spatial-distribution.html#thiessen-method-voronoi-diagram",
    "title": "17  Spatial distribution - lecture",
    "section": "17.2 Thiessen method [Voronoi diagram]",
    "text": "17.2 Thiessen method [Voronoi diagram]\nBrutsaert (2005), Figure 3.11 \nHow to compute the areas: \nAverage areal precipitation is a weighted sum:\n\n\\langle P \\rangle = \\frac{\\sum_i A_i P_i}{\\sum_i A_i}\n\nA nice way to understand the Thiessen method is depicted in this gif from Wikipedia.",
    "crumbs": [
      "summing up",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Spatial distribution - lecture</span>"
    ]
  },
  {
    "objectID": "summing-up/spatial-distribution.html#inverse-distance-method",
    "href": "summing-up/spatial-distribution.html#inverse-distance-method",
    "title": "17  Spatial distribution - lecture",
    "section": "17.3 Inverse distance method",
    "text": "17.3 Inverse distance method\nBrutsaert (2005), Figure 3.12 \nThe precipitation for square 17 is\n\nP_{17} =\n\\displaystyle\\frac\n{\\displaystyle\\sum_\\text{$i$ = all stations}\\frac{P_i}{d_{i,17}^2}}\n{\\displaystyle\\sum_\\text{$i$ = all stations}\\frac{1}{d_{i,17}^2}}\n\nThe average precipitation for the whole watershed is the weighted average of all squares, where the weight is their area:\n\n\\langle P \\rangle =\n\\displaystyle\\frac\n{\\displaystyle\\sum_\\text{$j$ = all squares} A_j P_j}\n{\\displaystyle\\sum_\\text{$j$ = all squares} A_j}\n\nBrutsaert (2005), page 93:\n\nDean and Snyder (1977) found that the exponent (for the distance d^{-b}) b = 2 yielded the best results in the Piedmont region of the southeastern United States, whereas Simanton and Osborn (1980) concluded from measurements in Arizona that b can range between 1 and 3 without significantly affecting the results.",
    "crumbs": [
      "summing up",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Spatial distribution - lecture</span>"
    ]
  },
  {
    "objectID": "summing-up/spatial-distribution.html#isohyetal-method",
    "href": "summing-up/spatial-distribution.html#isohyetal-method",
    "title": "17  Spatial distribution - lecture",
    "section": "17.4 Isohyetal method",
    "text": "17.4 Isohyetal method\nBrutsaert (2005), Figure 3.12 \nThe same equation of the Thiessen method can be used:\n\n\\langle P \\rangle = \\frac{\\sum_i A_i P_i}{\\sum_i A_i}",
    "crumbs": [
      "summing up",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Spatial distribution - lecture</span>"
    ]
  },
  {
    "objectID": "summing-up/spatial-distribution.html#how-it-is-actually-done",
    "href": "summing-up/spatial-distribution.html#how-it-is-actually-done",
    "title": "17  Spatial distribution - lecture",
    "section": "17.5 How it is actually done",
    "text": "17.5 How it is actually done\nMost often, Geographic Information System (GIS) software is used to analyze spatial data. Two of the most used programs are ArcGIS (proprietary) and QGIS (free).\nA good discussion of the different methods can be found on Manuel Gimond’s website, Intro to GIS and Spatial Analysis.\n\nAttention!\nDon’t mix precision with accuracy. There are many ways of interpolating, just because a result seems detailed, it does not imply that it is accurate! See below three interpolation methods.\n\n\nBelow you can find a simple Python code that exemplifies some of the methods, producing the following figure:\n\n\n\nShow the code\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.interpolate import griddata\nfrom scipy.spatial import Voronoi, voronoi_plot_2d, ConvexHull\n\nfig, ax = plt.subplots(1, 3, figsize=(10,7))\nfig.subplots_adjust(left=0.0, right=1.0, top=0.96, bottom=0.05,\n                    hspace=0.02, wspace=0.02)\n\nN = 6\nPI = '3141592653589793'\npoints = np.random.rand(N, 2)\npoints = np.vstack([points,[0,0], [0,1], [1,0], [1,1]])\nvalues = np.array([int(x) for x in list(PI)])[:(N+4)]\n# values = np.array([3, 1, 4, 1, 5, 9, 2, 6, 5, 3])\n\ngrid_x, grid_y = np.mgrid[0:1:100j, 0:1:200j]\n\ngrid_z_nearest = griddata(points, values, (grid_x, grid_y), method='nearest')\ngrid_z_cubic = griddata(points, values, (grid_x, grid_y), method='cubic')\n\nax[0].plot(points[:,0], points[:,1], 'o', ms=3, markerfacecolor=\"red\", markeredgecolor=\"red\")\nax[0].set_aspect('equal', 'box')\nax[0].set(xlim=[0,1], ylim=[0,1])\nax[0].set_title(\"the stations\")\nfor i, v in enumerate(values):\n    ax[0].text(points[i,0], points[i,1], str(v))\n\nax[1].imshow(grid_z_nearest.T, extent=(0,1,0,1), origin='lower')\nax[1].plot(points[:,0], points[:,1], 'o', ms=3, markerfacecolor=\"red\", markeredgecolor=\"red\")\nvor = Voronoi(points)\nvoronoi_plot_2d(vor, show_vertices=False, line_colors='cyan',\n                line_width=3, line_alpha=1, point_size=0, ax=ax[1])\nax[1].set_title(\"Thiessen Method\")\n\nax[2].plot(points[:,0], points[:,1], 'o', ms=3, markerfacecolor=\"red\", markeredgecolor=\"red\")\nnlines = int((values.max()-values.min()+1)/2)\nax[2].contourf(grid_x, grid_y, grid_z_cubic, nlines)\ncont = ax[2].contour(grid_x, grid_y, grid_z_cubic, nlines, colors=\"black\")\nax[2].clabel(cont, inline=1, colors='white', fmt='%.0f')\nax[2].set_title(\"Isohyetal Method\")\n\nfor i, a in enumerate(ax):\n    a.set(xlim=[-0.2,1.2], ylim=[-0.2,1.2])\n    a.axis('off')\n    a.set_aspect('equal', 'box')\n\nfig.savefig(\"spatial-distribution.png\", dpi=500)\n\n\n\n\n\n\n\n\n\n\n\n\n\nBrutsaert, Wilfried. 2005. Hydrology: An Introduction. Cambridge University Press.",
    "crumbs": [
      "summing up",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Spatial distribution - lecture</span>"
    ]
  },
  {
    "objectID": "assignments/assignments-instructions.html",
    "href": "assignments/assignments-instructions.html",
    "title": "18  Instructions",
    "section": "",
    "text": "18.1 🌅 Presentation\nThe guidelines below are valid for all the assignments.\nAll the assignment must be in one single Jupyter Notebook. Use markdown cells to discuss the analysis and results, and in code cells show all the code you used to produce the figures and data analysis. Leave only the code necessary for your analysis, delete unnecessary lines your wrote while analyzing your data. Don’t forget to comment your code, just like we did during exercise sessions. The assignment will be written in English.",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Instructions</span>"
    ]
  },
  {
    "objectID": "assignments/assignments-instructions.html#evaluation",
    "href": "assignments/assignments-instructions.html#evaluation",
    "title": "18  Instructions",
    "section": "18.2 💯 Evaluation",
    "text": "18.2 💯 Evaluation\nAll your assignments will be evaluated according to the following criteria:\n\n40% Presentation. How the graphs look, labels, general organization, markdown, clean code.\n30% Discussion. This is where you explain what you did, what you found out, etc.\n15% Depth of analysis. You can analyze/explore the data with different levels of complexity, this is where we take that into consideration.\n10% Replicability: Your code runs flawlessly.\n5%: Code commenting. Explain in your code what you are doing, this is good for everyone, especially for yourself!",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Instructions</span>"
    ]
  },
  {
    "objectID": "assignments/assignments-instructions.html#ai-policy",
    "href": "assignments/assignments-instructions.html#ai-policy",
    "title": "18  Instructions",
    "section": "18.3 🤖 AI Policy",
    "text": "18.3 🤖 AI Policy\nThe guidelines below are an adaptation of Ethan Mollick’s extremely useful ideas on AI as an assistant tool for teaching.\nI EXPECT YOU to use LLMs (large language models) such as ChatGPT, Gemini, Perplexity, Claude, or whatever else springs up since the time of this writing. You should familiarize yourself with the AI’s capabilities and limitations.\n\nGet GitHub Copilot Pro for free, using your university email.\nGetting free access to Copilot Pro as a student, teacher, or maintainer\n\nAt a minimum, you should use AI to check the quality of your English text, and make the text pleasant to read.\nConsider the following important points:\n\nUltimately, you, the student, are responsible for the assignment.\nDon’t trust anything the LLM says. Assume everything is wrong unless you either know the answer of can check with another source. You will be responsible for any errors or omissions provided by the tool.\nYou can use LLMs to help you write both the text and the code. If you provide minimum effort prompts to the model, you will probably get low quality results. You will need to refine your prompts in order to get good outcomes. Practice a lot.\nLLMs are great at producing lengthy, well-written text that may lack substance. Don’t submit this kind of content. I want you to think and learn, so use LLMs to help you do that.\nAcknowledge the use of AI in your assignment. Be transparent about your use of the tool and the extent of assistance it provided.\n\n\nThe text above was written with the assistance of ChatGPT. The content is mine, ChatGPT checked my English and suggested some improvements.",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Instructions</span>"
    ]
  },
  {
    "objectID": "assignments/assignment-return-period.html",
    "href": "assignments/assignment-return-period.html",
    "title": "19  Assignment - return period",
    "section": "",
    "text": "This assignment relates to the content learned in the lecture on return period.\nChoose a new location from NOAA’s National Centers for Environmental Information (NCEI) that we have not previously analyzed. It can be anywhere on Earth. Download daily precipitation data for a period longer than 60 years, or even longer if available.\nIn this assignment, you will analyze extreme precipitation events for the chosen location. The required analyses include:\n\nShow monthly precipitation averages and discuss which hydrological year definition makes the most sense.\nShow the distribution of annual daily maxima and comment on your observations.\nFit the GEV (Generalized Extreme Value) parameters to your data. Plot both the PDF (Probability Density Function) and CDF (Cumulative Distribution Function) for your data alongside the fitted GEV functions. Does the fit appear reasonable visually?\nShow a graph of annual daily maxima against the return times. Include dots for experimental data and a line for the calculated return times based on the GEV distribution. Do they agree everywhere? Describe your observations.\nProvide a table for the precipitation values corresponding to “one in X-years precipitation events”. Choose values that make sense to you and comment on these results.\n\nYou will have two weeks to submit this assignment from the date Yair mentioned it in class.\nBest of luck!",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Assignment - return period</span>"
    ]
  },
  {
    "objectID": "assignments/assignment-ET-NOAA.html",
    "href": "assignments/assignment-ET-NOAA.html",
    "title": "20  Assignment - ET",
    "section": "",
    "text": "This assignment relates to the content learned in the lecture on evapotranspiration.\nChoose a new location from NOAA, one we have not worked with yet. In this assignment, you will analyze meteorological data and produce estimates of potential evapotranspiration using Penman’s equation.\n\nWrite an introduction. Explain where is your station, what climate is has, mark it on a map, and give other general information relevant to this project.\nDownload three years of data for the station you chose.\nUse the library PYET to calculate potential ET for all the three years you chose.\nPlot graphs of the potential ET and of the other major variables related to the PET computation.\nDo you see interesting patterns in the data?\nDoes potential ET change across seasons and across years? Comment on that.\n\nYou will have three weeks to submit this assignment from the date Yair mentioned it in class.\nBest of luck!",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Assignment - ET</span>"
    ]
  },
  {
    "objectID": "assignments/assignment-streamflow.html",
    "href": "assignments/assignment-streamflow.html",
    "title": "21  Assignment - Streamflow",
    "section": "",
    "text": "21.1 📒 instructions\nThis is where learning happens, not during a lecture. You’ll learn a ton of things by doing them yourself. Much success! 😄\nCreate a Jupyter Notebook called assignment-03-IDNUMBER, where IDNUMBER is your 9-digit ID. This is the file only file we will check.",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Assignment - Streamflow</span>"
    ]
  },
  {
    "objectID": "assignments/assignment-streamflow.html#locations-and-data",
    "href": "assignments/assignment-streamflow.html#locations-and-data",
    "title": "21  Assignment - Streamflow",
    "section": "21.2 📌 locations and data",
    "text": "21.2 📌 locations and data\nChoose one location in the US.\n\nImport streamflow data from USGS’s National Water Information System. Choose on the map any measuring station you see fit. Make sure there is available discharge data (usually given in cubic feet per second) in small time intervals, e.g., every 15 minutes.\nIn the same map, find a nearby weather station that provides precipitation data. Try to find one that has a high temporal resolution (e.g., 5 minutes, 15 minutes). There are a lot more streamflow stations than weather stations, so you might have to look around a bit. A good strategy is to first find a weather station, and then look for a streamflow station nearby.\nMake sure both datasets look good.",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Assignment - Streamflow</span>"
    ]
  },
  {
    "objectID": "assignments/assignment-streamflow.html#tasks",
    "href": "assignments/assignment-streamflow.html#tasks",
    "title": "21  Assignment - Streamflow",
    "section": "21.3 🛠 tasks",
    "text": "21.3 🛠 tasks\nChoose a rain event of a few hours in your data set. Find the rate of effective water input (p) and the event flow rate (q). Analyze the data in a similar was as done during class (various graphs explaining what you see). Find also the characteristic times of the event (centroid lag T_{LC}, centroid lag-to-peak T_{LPC}, and time of concentration T_c).\nTry to find information on the climate, geography, soil, and land use of the watershed. Begin the assignment by explaining about the watershed you chose and characterizing it. When presenting the data and your analyses, discuss what you see based on the concepts learned in class (infiltration, runoff generation, and the factors that affect them). Does the information you found match what you see? What makes sense, and what doesn’t?\nUseful tool:\n\nhttps://mghydro.com/watersheds/\nPoint and click at any coordinate (latitude, longitude), and then choose “delineate”. On the left side of the screen you’ll find “Watershed Data Report”. You can type any coordinate under “Options &gt; Enter Coordinates”.\n\nYou will have two weeks to deliver your assignment. You should not hand in a dry document with only figures and code, I’m expecting text before and after each code/graph cell, explaining what you did, why you did it, and how it fits the story you are telling. Don’t forget to put labels on your plot axes, title, legend, etc.\nDiscussion is important!\nYour Jupyter Notebook should be fully functional: if we press Kernel &gt; Restart & Run All, all the code must work without any errors.",
    "crumbs": [
      "Assignments",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Assignment - Streamflow</span>"
    ]
  },
  {
    "objectID": "appendix/index.html",
    "href": "appendix/index.html",
    "title": "Appendix",
    "section": "",
    "text": "Welcome to extra stuff at the end of this book.",
    "crumbs": [
      "Appendix"
    ]
  },
  {
    "objectID": "appendix/date_formatting.html",
    "href": "appendix/date_formatting.html",
    "title": "22  Gain full control of date formatting",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport datetime\nfrom datetime import timedelta\nimport seaborn as sns\nsns.set(style=\"ticks\", font_scale=1.5)\nimport matplotlib.gridspec as gridspec\nfrom matplotlib.dates import DateFormatter\nimport matplotlib.dates as mdates\nimport matplotlib.ticker as ticker\n\n\nimport pandas as pd\n\nstart_date = '2018-01-01'\nend_date = '2018-04-30'\n\n# create date range with 1-hour intervals\ndates = pd.date_range(start_date, end_date, freq='1H')\n# create a random variable to plot\nvar = np.random.randint(low=-10, high=11, size=len(dates)).cumsum()\nvar = var - var.min()\n# create dataframe, make \"date\" the index\ndf = pd.DataFrame({'date': dates, 'variable': var})\ndf.set_index(df['date'], inplace=True)\ndf\n\n\n\n\n\n\n\n\ndate\nvariable\n\n\ndate\n\n\n\n\n\n\n2018-01-01 00:00:00\n2018-01-01 00:00:00\n856\n\n\n2018-01-01 01:00:00\n2018-01-01 01:00:00\n863\n\n\n2018-01-01 02:00:00\n2018-01-01 02:00:00\n867\n\n\n2018-01-01 03:00:00\n2018-01-01 03:00:00\n874\n\n\n2018-01-01 04:00:00\n2018-01-01 04:00:00\n864\n\n\n...\n...\n...\n\n\n2018-04-29 20:00:00\n2018-04-29 20:00:00\n20\n\n\n2018-04-29 21:00:00\n2018-04-29 21:00:00\n20\n\n\n2018-04-29 22:00:00\n2018-04-29 22:00:00\n27\n\n\n2018-04-29 23:00:00\n2018-04-29 23:00:00\n23\n\n\n2018-04-30 00:00:00\n2018-04-30 00:00:00\n32\n\n\n\n\n2857 rows × 2 columns\n\n\n\ndefine a useful function to plot the graphs below\n\ndef explanation(ax, text, letter):\n    ax.text(0.99, 0.97, text,\n            transform=ax.transAxes,\n            horizontalalignment='right', verticalalignment='top',\n            fontweight=\"bold\")\n    ax.text(0.01, 0.01, letter,\n            transform=ax.transAxes,\n            horizontalalignment='left', verticalalignment='bottom',\n            fontweight=\"bold\")\n    ax.set(ylabel=\"variable (units)\")\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n\n\nfig, ax = plt.subplots(1, 1, figsize=(8, 6))\nax.plot(df['variable'])\nplt.gcf().autofmt_xdate()  # makes slated dates\nexplanation(ax, \"slanted dates\", \"\")\nfig.savefig(\"dates1.png\")\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(4, 1, figsize=(10, 16),\n                       gridspec_kw={'hspace': 0.3})\n\n### plot a ###\nax[0].plot(df['variable'])\ndate_form = DateFormatter(\"%b\")\nax[0].xaxis.set_major_locator(mdates.MonthLocator(interval=2))\nax[0].xaxis.set_major_formatter(date_form)\n\n### plot b ###\nax[1].plot(df['variable'])\ndate_form = DateFormatter(\"%B\")\nax[1].xaxis.set_major_locator(mdates.MonthLocator(interval=1))\nax[1].xaxis.set_major_formatter(date_form)\n\n### plot c ###\nax[2].plot(df['variable'])\nax[2].xaxis.set_major_locator(mdates.MonthLocator())\n# 16 is a slight approximation for the center, since months differ in number of days.\nax[2].xaxis.set_minor_locator(mdates.MonthLocator(bymonthday=16))\nax[2].xaxis.set_major_formatter(ticker.NullFormatter())\nax[2].xaxis.set_minor_formatter(DateFormatter('%B'))\nfor tick in ax[2].xaxis.get_minor_ticks():\n    tick.tick1line.set_markersize(0)\n    tick.tick2line.set_markersize(0)\n    tick.label1.set_horizontalalignment('center')\n\n### plot d ###\nax[3].plot(df['variable'])\ndate_form = DateFormatter(\"%d %b\")\nax[3].xaxis.set_major_locator(mdates.DayLocator(interval=15))\nax[3].xaxis.set_major_formatter(date_form)\n\nexplanation(ax[0], \"month abbreviations, every 2 months\", \"a\")\nexplanation(ax[1], \"full month names\", \"b\")\nexplanation(ax[2], \"full month names centered between the 1st of the month\", \"c\")\nexplanation(ax[3], \"day + month abbr. --- every 15 days\", \"d\")\n\nfig.savefig(\"dates2.png\")\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(4, 1, figsize=(10, 16),\n                       gridspec_kw={'hspace': 0.3})\n\n### plot e ###\nax[0].plot(df['variable'])\ndate_form = DateFormatter(\"%d/%m\")\nax[0].xaxis.set_major_locator(mdates.DayLocator(bymonthday=[5, 20]))\nax[0].xaxis.set_major_formatter(date_form)\n\n### plot f ###\nax[1].plot(df['variable'])\nlocator = mdates.AutoDateLocator(minticks=11, maxticks=17)\nformatter = mdates.ConciseDateFormatter(locator)\nax[1].xaxis.set_major_locator(locator)\nax[1].xaxis.set_major_formatter(formatter)\n\n### plot g ###\nax[2].plot(df.loc['2018-01-01':'2018-03-01', 'variable'])\nlocator = mdates.AutoDateLocator(minticks=6, maxticks=14)\nformatter = mdates.ConciseDateFormatter(locator)\nax[2].xaxis.set_major_locator(locator)\nax[2].xaxis.set_major_formatter(formatter)\n\n### plot h ###\nax[3].plot(df.loc['2018-01-01':'2018-01-02', 'variable'])\nlocator = mdates.AutoDateLocator(minticks=6, maxticks=10)\nformatter = mdates.ConciseDateFormatter(locator)\nax[3].xaxis.set_major_locator(locator)\nax[3].xaxis.set_major_formatter(formatter)\n\nexplanation(ax[0], \"exactly on days 05 and 20 of each month\", \"e\")\nexplanation(ax[1], \"ConciseDateFormatter\", \"f\")\nexplanation(ax[2], \"ConciseDateFormatter\", \"g\")\nexplanation(ax[3], \"ConciseDateFormatter\", \"h\")\n\nfig.savefig(\"dates3.png\")\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(1, 1, figsize=(10, 4),\n                       gridspec_kw={'hspace': 0.3})\n\n# import constants for the days of the week\nfrom matplotlib.dates import MO, TU, WE, TH, FR, SA, SU\nax.plot(df['variable'])\n# tick on sundays every third week\nloc = mdates.WeekdayLocator(byweekday=SU, interval=3)\nax.xaxis.set_major_locator(loc)\ndate_form = DateFormatter(\"%a, %b %d\")\nax.xaxis.set_major_formatter(date_form)\nfig.autofmt_xdate(bottom=0.2, rotation=30, ha='right')\nexplanation(ax, \"every 3 Sundays, rotate labels\", \"\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nExplanation\n\n\n\n\n%Y\n4-digit year (e.g., 2022)\n\n\n%y\n2-digit year (e.g., 22)\n\n\n%m\n2-digit month (e.g., 12)\n\n\n%B\nFull month name (e.g., December)\n\n\n%b\nAbbreviated month name (e.g., Dec)\n\n\n%d\n2-digit day of the month (e.g., 09)\n\n\n%A\nFull weekday name (e.g., Tuesday)\n\n\n%a\nAbbreviated weekday name (e.g., Tue)\n\n\n%H\n24-hour clock hour (e.g., 23)\n\n\n%I\n12-hour clock hour (e.g., 11)\n\n\n%M\n2-digit minute (e.g., 59)\n\n\n%S\n2-digit second (e.g., 59)\n\n\n%p\n“AM” or “PM”\n\n\n%Z\nTime zone name\n\n\n%z\nTime zone offset from UTC (e.g., -0500)",
    "crumbs": [
      "Appendix",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Gain full control of date formatting</span>"
    ]
  },
  {
    "objectID": "appendix/plotting-guidelines.html",
    "href": "appendix/plotting-guidelines.html",
    "title": "23  Plotting guidelines",
    "section": "",
    "text": "23.1 increase fontsize to legible sizes\nimport stuff\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\nimport matplotlib\nimport numpy as np\nimport pandas as pd\nGraph with default matplotlib values:\nplot with default matplotlib values\nt = np.linspace(0, 10, 101)\ny = np.sin(2.0*np.pi*t/3) + np.random.random(len(t)) + 4.0\nfig, ax = plt.subplots()\nax.plot(t, y)\nax.set(title=\"This is a title\",\n       xlabel=\"time (days)\",\n       ylabel=\"price (US$)\"\n      );\nYou can use seaborn to easily change plot style and font size:\nimport seaborn as sns\nsns.set_theme(style=\"ticks\", font_scale=1.5)\nplot after seaborn theme changes\nt = np.linspace(0, 10, 101)\ny = np.sin(2.0*np.pi*t/3) + np.random.random(len(t)) + 4.0\nfig, ax = plt.subplots()\nax.plot(t, y)\nax.set(title=\"This is a title\",\n       xlabel=\"time (days)\",\n       ylabel=\"price (US$)\"\n      );\nI recommend that you read seaborn’s Controlling figure aesthetics.",
    "crumbs": [
      "Appendix",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Plotting guidelines</span>"
    ]
  },
  {
    "objectID": "appendix/plotting-guidelines.html#choose-colors-wisely",
    "href": "appendix/plotting-guidelines.html#choose-colors-wisely",
    "title": "23  Plotting guidelines",
    "section": "23.2 choose colors wisely",
    "text": "23.2 choose colors wisely\n\n\ndefine useful functions\nimport math\nimport matplotlib.colors as mcolors\nfrom matplotlib.patches import Rectangle\n\n\ndef plot_colortable(colors, *, ncols=4, sort_colors=True):\n\n    cell_width = 212\n    cell_height = 22\n    swatch_width = 48\n    margin = 12\n\n    # Sort colors by hue, saturation, value and name.\n    if sort_colors is True:\n        names = sorted(\n            colors, key=lambda c: tuple(mcolors.rgb_to_hsv(mcolors.to_rgb(c))))\n    else:\n        names = list(colors)\n\n    n = len(names)\n    nrows = math.ceil(n / ncols)\n\n    width = cell_width * ncols + 2 * margin\n    height = cell_height * nrows + 2 * margin\n    dpi = 72\n\n    fig, ax = plt.subplots(figsize=(width / dpi, height / dpi), dpi=dpi)\n    fig.subplots_adjust(margin/width, margin/height,\n                        (width-margin)/width, (height-margin)/height)\n    ax.set_xlim(0, cell_width * ncols)\n    ax.set_ylim(cell_height * (nrows-0.5), -cell_height/2.)\n    ax.yaxis.set_visible(False)\n    ax.xaxis.set_visible(False)\n    ax.set_axis_off()\n\n    for i, name in enumerate(names):\n        row = i % nrows\n        col = i // nrows\n        y = row * cell_height\n\n        swatch_start_x = cell_width * col\n        text_pos_x = cell_width * col + swatch_width + 7\n\n        ax.text(text_pos_x, y, name, fontsize=14,\n                horizontalalignment='left',\n                verticalalignment='center')\n\n        ax.add_patch(\n            Rectangle(xy=(swatch_start_x, y-9), width=swatch_width,\n                      height=18, facecolor=colors[name], edgecolor='0.7')\n        )\n\n    return fig\n\n\nWhen you plot with matplotlib, the default color order is the following. You can always specify a plot’s color by typing something like color=\"tab:red.\n\n\nShow the code\nplot_colortable(mcolors.TABLEAU_COLORS, ncols=2, sort_colors=False);\n\n\n\n\n\n\n\n\n\nYou can write other words as color names, see below.\n\n\nShow the code\nplot_colortable(mcolors.CSS4_COLORS)\nplt.show()\n\n\n\n\n\n\n\n\n\nThis reminds me of this cartoon:\n\nFor almost all purposes, all these colors should be more than enough.\nBe consistent!: if in one plot precipitation is blue and temperature is red, make sure you keep the same colors throughout your assignment.\nBe mindful of blind-color people: A good rule of thumb is to avoid red and green shades in the same graph.\nI’ll put a bunch of links below, this is for my own reference, but you are more than welcome to take a look.\n\nColorBrewer\nPalettable\nxkcd colors\nColormaps in Matplotlib",
    "crumbs": [
      "Appendix",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Plotting guidelines</span>"
    ]
  },
  {
    "objectID": "appendix/plotting-guidelines.html#the-best-legend-is-no-legend",
    "href": "appendix/plotting-guidelines.html#the-best-legend-is-no-legend",
    "title": "23  Plotting guidelines",
    "section": "23.3 the best legend is no legend",
    "text": "23.3 the best legend is no legend\n\n\nplot after seaborn theme changes\nt = np.linspace(0, 10, 101)\ny1 = np.sin(2.0*np.pi*t/3) + np.random.random(len(t)) + 5.0\ny2 = 0.7*np.sin(2.0*np.pi*t/1+1.0) + np.random.random(len(t)) + 2.0\ny3 = 0.2*np.sin(2.0*np.pi*t/5+2.0) + 0.2*np.random.random(len(t)) + 3.5\n\nfig, ax = plt.subplots(3, 1, figsize=(8,14))\nfig.subplots_adjust(hspace=0.7)\n\n# you can use legends\nax[0].plot(t, y1, color=\"darkblue\", label=\"signal A\")\nax[0].plot(t, y2, color=\"blue\", label=\"signal B\")\nax[0].plot(t, y3, color=\"xkcd:hot pink\", label=\"signal C\")\nax[0].set(title=\"you can have a legend\",\n          xlabel=\"time (days)\",\n          ylabel=\"signal (a.u.)\"\n         )\nax[0].legend()\n\n# you can use an extra y axes\np1, = ax[1].plot(t, y1, color=\"darkblue\")\nax[1].yaxis.label.set_color(p1.get_color())\nax[1].tick_params(axis='y', colors=p1.get_color())\nax[1].set(xlabel=\"time (days)\",\n          ylabel=\"signal A (a.u.)\",\n          title=\"you can have two y axes with different colors\"\n         )\nax1b = plt.twinx(ax[1])\np2, = ax1b.plot(t, y3, color=\"xkcd:hot pink\", label=\"signal C\")\nax1b.set(ylabel=\"signal B (a.u.)\"\n        )\nax1b.yaxis.label.set_color(p2.get_color())\nax1b.tick_params(axis='y', colors=p2.get_color())\n\n# you can write directly on the graph\nax[2].plot(t, y1, color=\"darkblue\", label=\"signal A\")\nax[2].plot(t, y2, color=\"blue\", label=\"signal B\")\nax[2].plot(t, y3, color=\"xkcd:hot pink\", label=\"signal C\")\nax[2].set(xlabel=\"time (days)\",\n          ylabel=\"signal (a.u.)\",\n          ylim=[0.5,7],\n          title=\"you can write directly on the graph\"\n         )\nax[2].text(-0.5, 5, \"signal A\", color=\"darkblue\", ha=\"left\")\nax[2].text(-0.5, 1, \"signal B\", color=\"blue\", ha=\"left\")\nax[2].text(-0.5, 4, \"signal C\", color=\"xkcd:hot pink\", ha=\"left\")\n\n\nText(-0.5, 4, 'signal C')\n\n\n\n\n\n\n\n\n\nYou can also make a colorbar to substitute a legend.\n\n\nmake a discrete colorbar\nnum_lines = 6\n\nt = np.linspace(0, 2, 101)\n\n# Get truncated colormap\ncmap = plt.colormaps.get_cmap('jet')\nbottom = 0.6; top = 1.0\ntruncated_cmap = mcolors.LinearSegmentedColormap.from_list(\"truncated_viridis\", cmap(np.linspace(bottom, top, num_lines)))\n\n# Create a figure and axis\nfig, ax = plt.subplots()\n\n# Plot the lines with increasing frequency\nfor i in range(num_lines):\n    freq = i + 1\n    y = np.sin(2.0 * np.pi * t * freq) + 2*freq\n    ax.plot(t, y, color=truncated_cmap(i / (num_lines - 1)), label=f'Slope {slope}')\n\nax.set(xlabel=\"time (s)\",\n       ylabel=\"signal\")\n\n# Create a discrete colorbar\nboundaries = np.linspace(0.5, num_lines + 0.5, num_lines + 1)\nticks = np.arange(num_lines) + 1\nnorm = mcolors.BoundaryNorm(boundaries, truncated_cmap.N)\nsm = plt.cm.ScalarMappable(cmap=truncated_cmap, norm=norm)\nsm.set_array([])  # fake up the array of the scalar mappable\ncbar = plt.colorbar(sm, ticks=ticks, boundaries=boundaries, label='frequency', ax=ax)\ncbar.ax.tick_params(which='both', size=0)\nfreq_list = [f\"{x+1} Hz\" for x in range(num_lines)]\ncbar.set_ticklabels(freq_list)",
    "crumbs": [
      "Appendix",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Plotting guidelines</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "24  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\nThis is Yair making changes to summary.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Allen, Richard G, Luis S Pereira, Dirk Raes, Martin Smith, et al. 1998.\n“Crop Evapotranspiration-Guidelines for Computing Crop Water\nRequirements-FAO Irrigation and Drainage Paper 56.” Fao,\nRome 300 (9): D05109.\n\n\nAndrew Amelinckx. 2015. “Even Without a Drought, We’re Depleting\nGroundwater at an Alarming Pace.” Modern Farmer. https://modernfarmer.com/2015/07/ogallala-aquifer-depletion/.\n\n\nBerghuijs, Wouter R, Sebastian J Gnann, and Ross A Woods. 2020.\n“Unanswered Questions on the Budyko Framework.” Journal\nof Hydrology 265: 164–77.\n\n\nBrutsaert, Wilfried. 2005. Hydrology: An Introduction.\nCambridge University Press.\n\n\nBudyko, Mikhail Ivanovich. 1974. “Climate and Life.”\n(No Title).\n\n\nCreed, Irena, and Adam Spargo. 2012. “Budyko Guide to Exploring\nSustainability of Water Yields from Catchments Under Changing\nEnvironmental Conditions.” London, Ontario. Http://Www. Uwo.\nCa/Biology/Faculty/Creed/PDFs/Presentations/PRE116. Pdf.\n\n\nDaly, Edoardo, Salvatore Calabrese, Jun Yin, and Amilcare Porporato.\n2019. “Linking Parametric and Water-Balance Models of the Budyko\nand Turc Spaces.” Advances in Water Resources 134:\n103435.\n\n\nDingman, S. L. 2015. Physical Hydrology. 3rd edition. Waveland\nPress, Incorporated.\n\n\ndreamstime. 2022. “World Map of AFRICA.”\nDreamstime. https://www.dreamstime.com/world-map-africa-egypt-libya-ethiopia-arabia-mauritania-nigeria-somalia-namibia-tanzania-madagascar-geographic-xxl-chart-image154799901.\n\n\nFiona Bruce. 2015. “A Family Holiday in Lake Malawi: Zen and the\nArt of Paddleboarding.” The Telegraph. https://twitter.com/hallaboutafrica/status/1203419359303159809?s=20&t=SkH17UkWrNcXzIqRF0ic_A.\n\n\nHillel, Daniel. 2003. Introduction to Environmental Soil\nPhysics. Elsevier.\n\n\nJones, Julia A, Irena F Creed, Kendra L Hatcher, Robert J Warren, Mary\nBeth Adams, Melinda H Benson, Emery Boose, et al. 2012. “Ecosystem\nProcesses and Human Influences Regulate Streamflow Response to Climate\nChange at Long-Term Ecological Research Sites.”\nBioScience 62 (4): 390–404.\n\n\nKbh3rd. 2009. “High Plains Fresh Groundwater Usage 2000.”\nWikimedia. https://commons.wikimedia.org/wiki/File:High_plains_fresh_groundwater_usage_2000.svg.\n\n\nKrajewski, Adam, Anna E Sikorska-Senoner, Leszek Hejduk, and Kazimierz\nBanasik. 2021. “An Attempt to Decompose the Impact of Land Use and\nClimate Change on Annual Runoff in a Small Agricultural\nCatchment.” Water Resources Management 35 (3): 881–96.\n\n\nleddris. 2010. “Rainfall Seasonality.” Land and\nEcosystem Degradation and Desertification Response Information\nSystem. http://leddris.aegean.gr/ses-parameters/293-rainfall-seasonality.html#:~:text=Rainfall%20seasonality%20index%20is%20a,in%20relation%20to%20water%20availability.\n\n\nMargulis, Steve. 2019. “Introduction to Hydrology. eBook.”\nhttps://margulis-group.github.io/textbook/.\n\n\nRaymond, Lyle S. Jr. 1988. “What Is Groundwater?”\nCornell eCommons. https://ecommons.cornell.edu/handle/1813/3408.\n\n\nSposito, Garrison. 2017. “Understanding the Budyko\nEquation.” Water 9 (4): 236.\n\n\nSuma Groulx. 2015. “Water Infiltration.” Suma\nGroulx. http://sumagroulx.com/water-infiltration/.\n\n\nUnited States Department of Agriculture, Natural Resources Conservation\nService. 2004. Estimation of Direct Runoff from Storm Rainfall.\nNational Engineering Handbook, Part 630 Hydrology, Chapter 10. United\nStates Department of Agriculture. https://directives.sc.egov.usda.gov/OpenNonWebContent.aspx?content=17752.wba.\n\n\nValentí Rodellas. 1988. “Evaluating Submarine Groundwater\nDischarge to the Mediterranean Sea by Using Radium Isotopes.”\nResearch Gate. https://www.researchgate.net/figure/Principal-pathways-for-submarine-groundwater-discharge-to-the-coastal-ocean-including_fig1_274590439.\n\n\nWalsh, RPD, and DM Lawler. 1981. “Rainfall Seasonality:\nDescription, Spatial Patterns and Change Through Time.”\nWeather 36 (7): 201–8. https://doi.org/10.1002/j.1477-8696.1981.tb05400.x.\n\n\nWard, Andy D, and Stanley W Trimble. 2003. Environmental\nHydrology. 2nd ed. CRC Press.\n\n\nWater Science School. 2018. “Where Is Earth’s Water?”\nU.S. Geological Survey. https://www.usgs.gov/special-topics/water-science-school/science/where-earths-water.\n\n\n———. 2019a. “Conceptual Groundwater-Flow Diagram.” U.S.\nGeological Survey. https://www.usgs.gov/media/images/conceptual-groundwater-flow-diagram.\n\n\n———. 2019b. “Groundwater Is the Area Underground Where Openings\nAre Full of Water.” U.S. Geological Survey. https://www.usgs.gov/media/images/groundwater-area-underground-where-openings-are-full-water.\n\n\n———. 2019c. “How Much Water Is There on Earth?” U.S.\nGeological Survey. https://www.usgs.gov/special-topics/water-science-school/science/how-much-water-there-earth.\n\n\n———. 2019d. “Ice, Snow, and Glaciers and the Water Cycle.”\nU.S. Geological Survey. https://www.usgs.gov/special-topics/water-science-school/science/ice-snow-and-glaciers-and-water-cycle.\n\n\n———. 2019e. “Precipitation and the Water Cycle.” U.S.\nGeological Survey. https://www.usgs.gov/special-topics/water-science-school/science/precipitation-and-water-cycle.\n\n\n———. 2019f. “Rain and Precipitation.” U.S. Geological\nSurvey. https://www.usgs.gov/special-topics/water-science-school/science/rain-and-precipitation.\n\n\n———. 2019g. “The Natural Water Cycle.” U.S. Geological\nSurvey. https://www.usgs.gov/media/images/natural-water-cycle-jpg.\n\n\n———. 2022. “The Water Cycle.” U.S. Geological\nSurvey. https://www.usgs.gov/media/images/water-cycle-png.\n\n\nZhang, Lu, Klaus Hickel, WR Dawes, Francis HS Chiew, AW Western, and PR\nBriggs. 2004. “A Rational Function Approach for Estimating Mean\nAnnual Evapotranspiration.” Water Resources Research 40\n(2).\n\n\nחדשות פתח תקווה. 2020. “אובך ומערכת גשמים כבדה נוספת.”\nMelabes. https://www.melabes.co.il/news/51773.",
    "crumbs": [
      "References"
    ]
  }
]